{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ddff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PYTHONPATH=\"${PYTHONPATH}:/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/CloudSat_ERA5_CMIP6_analysis/utils/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c8e52",
   "metadata": {},
   "source": [
    "# Example with CMIP6 models (100 - 500 km)\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77edda",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>\n",
    "Cloud feedbacks are a major contributor to the spread of climate sensitivity in global climate models (GCMs) [Zelinka et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019GL085782). Among the most poorly understood cloud feedbacks is the one associated with the cloud phase, which is expected to be modified with climate change [Bjordal et al. (2020)](https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1). Cloud phase bias, in addition, has significant implications for the simulation of radiative properties and glacier and ice sheet mass balances in climate models. \n",
    "\n",
    "In this context, this work aims to expand our knowledge on how the representation of the cloud phase affects snow formation in GCMs. Better understanding this aspect is necessary to develop climate models further and improve future climate predictions. \n",
    "\n",
    "* Retrieve CMIP6 data through [ESGF](https://esgf-node.llnl.gov/search/cmip6/)\n",
    "* Hybrid sigma-pressure coordinates to isobaric pressure levels of the European Centre for Medium-Range Weather Forecast Re-Analysis 5 (ERA5) with [GeoCAT-comb](https://geocat-comp.readthedocs.io/en/latest/index.html)\n",
    "* Regridd the CMIP6 variables to the exact horizontal resolution with [`xesmf`](https://xesmf.readthedocs.io/en/latest/)\n",
    "* Calculate an ensemble mean of all used models\n",
    "* Calculate and plot the seasonal mean of the ensemble mean\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall varying between 2007 and 2010?\n",
    "\n",
    "> **_NOTE:_** We answer questions related to the comparison of CMIP models to ERA5 in another [Jupyter Notebook](../CMIP6_ERA5_CloudSat/plt_seasonal_mean.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f939501",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "This study will compare surface snowfall, ice, and liquid water content from the Coupled Model Intercomparison Project Phase 6 ([CMIP6](https://esgf-node.llnl.gov/projects/cmip6/)) climate models to the European Centre for Medium-Range Weather Forecast Re-Analysis 5 ([ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)) data from **2006 to 2009**. We conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models and their potential connection between them. \n",
    "\n",
    "- Time period: 2006 to 2009\n",
    "- horizonal resolution: depending on model\n",
    "- time resolution: daily mean atmospheric data (CFday, day)\n",
    "- Variables:\n",
    "  \n",
    "| shortname     |             Long name                   |      Units    |  levels |\n",
    "| ------------- |:---------------------------------------:| -------------:|--------:|\n",
    "|  prsn         |    Snowfall Flux                        | [kg m-2 s-1]  | surface |\n",
    "| clw           |    Mass Fraction of Cloud Liquid Water  |  [kg kg-1]    |    ml   | \n",
    "|               |                                         | to calculate lwp use integral clw -dp/dg | |\n",
    "| tas           |    Near-Surface Air Temperature         |   [K]         | surface |\n",
    "| clivi         |    Ice Water Path                       | [kg m-2]      |         |\n",
    "| lwp           |    Liquid Water Path                    | [kg m-2]      |         |\n",
    "\n",
    "- CMIP6 models:\n",
    "\n",
    "| Institution                                            |     Model name    | Reference                                                     |\n",
    "| ------------------------------------------------------ |:-----------------:|--------------------------------------------------------------:|\n",
    "| [MIROC]() | MIROC6           | [Tatebe et al. (2019)]() |\n",
    "| [NCAR]()  | CESM2            | [Danabasoglu et al. (2020)]()  |\n",
    "| [CCCma]() | CanESM5          | [Swart et al. (2019)]()     |\n",
    "| [AWI]()   | AWI-ESM-1-1-LR   | []() |\n",
    "| [MOHC]()  | UKESM1-0-LL      | []() |\n",
    "| [MOHC]()  | HadGem3-GC31-LL  | [Roberts et al. (2019)]() |\n",
    "| [CNRM-CERFACS]() | CNRM-CM6-1 | [Voldoire et al. (2019)]() |\n",
    "| [CNRM-CERFACS]() | CNRM-ESM2-1| [Seferian et al. (2019)]() |\n",
    "| [IPSL]() | IPSL-CM6A-LR | [Boucher et al. (2020)]() |\n",
    "| [IPSL]() | IPSL-CM5A2-INCA | []()|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b693459",
   "metadata": {},
   "source": [
    "## Organize my data\n",
    "\n",
    "- Define a prefix for my project (you may need to adjust it for your own usage on your infrastructure).\n",
    "    - input folder where all the data used as input to my Jupyter Notebook is stored (and eventually shared)\n",
    "    - output folder where all the results to keep are stored\n",
    "    - tool folder where all the tools\n",
    "\n",
    "`/input/cmip6_hist/daily_means`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f298f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimi.uio.no\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "abs_path = str(pathlib.Path(hostname).parent.absolute())\n",
    "WORKDIR = abs_path[:- (len(abs_path.split('/')[-2] + abs_path.split('/')[-1])+1)]\n",
    "\n",
    "\n",
    "if \"mimi\" in hostname:\n",
    "    print(hostname)\n",
    "    DATA_DIR = \"/scratch/franzihe/\"\n",
    "    FIG_DIR = \"/uio/kant/geo-metos-u1/franzihe/Documents/Figures/CMIP6/\"\n",
    "elif \"glefsekaldt\" in hostname: \n",
    "    DATA_DIR = \"/home/franzihe/Data/\"\n",
    "    FIG_DIR = \"/home/franzihe/Documents/Figures/CMIP6/\"\n",
    "\n",
    "INPUT_DATA_DIR = os.path.join(DATA_DIR, 'input')\n",
    "OUTPUT_DATA_DIR = os.path.join(DATA_DIR, 'output')\n",
    "UTILS_DIR = os.path.join(WORKDIR, 'utils/')\n",
    "\n",
    "sys.path.append(UTILS_DIR)\n",
    "# make figure directory\n",
    "try:\n",
    "    os.mkdir(FIG_DIR)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652dc0b",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [requirements_globalsnow.txt](../../requirements_globalsnow.txt) \n",
    "- load `python` packages from [imports.py](../../utils/imports.py)\n",
    "- load `functions` from [functions.py](../../utils/functions.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4caa42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f3127ede590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "from imports import (xr, intake, cftime, xe, glob, np, cm, pd, fct,ccrs, cy, plt, da, gc, datetime, LogNorm)\n",
    "xr.set_options(display_style=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb920800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620cb825",
   "metadata": {},
   "source": [
    "## Open CMIP6 variables\n",
    "Get the data required for the analysis. Beforehand we downloaded the daily averaged data on single levels and model levels via."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ceedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip_in = os.path.join(INPUT_DATA_DIR, 'cmip6_hist/daily_means')\n",
    "cmip_out = os.path.join(OUTPUT_DATA_DIR, 'cmip6_hist/daily_means/common_grid')\n",
    "\n",
    "# make output data directory\n",
    "try:\n",
    "    os.mkdir(cmip_out)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994d8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_id = ['clw', 'cli', 'clivi', 'tas', 'prsn', 'pr', 'areacella']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "424276a6",
   "metadata": {},
   "source": [
    "At the moment we have downloaded the end of the historical simulations for CMIP6 models. We define start and end year to ensure to only extract the 4-year period between 2006 and 2009.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year\n",
    "\n",
    "We will load all available models into one dictonary, which includes an xarray dataset with `xarray.open_mfdataset(file)` and select the time range [by name](https://xarray.pydata.org/en/stable/user-guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598731dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_id\n",
    "list_models = [\n",
    "               'MIROC6', \n",
    "               'CESM2', \n",
    "               'CanESM5', \n",
    "               'AWI-ESM-1-1-LR', \n",
    "               'MPI-ESM1-2-LR', \n",
    "            # #    'UKESM1-0-LL', \n",
    "            # #    'HadGEM3-GC31-LL',\n",
    "               'CNRM-CM6-1',\n",
    "               'CNRM-ESM2-1',\n",
    "               'IPSL-CM6A-LR',\n",
    "               'IPSL-CM5A2-INCA'\n",
    "            ]\n",
    "\n",
    "## experiment\n",
    "experiment_id = ['historical']\n",
    "\n",
    "## time resolution\n",
    "t_res = ['day',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57e5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "starty = 2006; endy = 2009\n",
    "year_range = range(starty, endy+1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20590565",
   "metadata": {},
   "source": [
    "## Search corresponding data\n",
    "Get the data required for the analysis. Define variables, models, experiment, and time resolution as defined in <a href=\"#data_wrangling\">2. Data Wrangling</a>\n",
    ". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abadaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data(cmip_in, t_res, list_models, year_range):\n",
    "    dset_dict = dict()\n",
    "    for model in list_models:\n",
    "        # print(model)\n",
    "        cmip_file_in = glob('{}/*{}_{}_{}*'.format(cmip_in, t_res[0], model, experiment_id[0]))\n",
    "        if len(cmip_file_in) != 0:\n",
    "            dset_dict[model] = xr.open_mfdataset(sorted(cmip_file_in), combine='nested', compat='override', use_cftime=True, parallel =True)\n",
    "            # select only years needed for analysis\n",
    "            dset_dict[model] = dset_dict[model].sel(time = dset_dict[model]['time'].dt.year.isin(year_range)).squeeze()\n",
    "            # shift longitude to be from -180 to 180\n",
    "            dset_dict[model] = dset_dict[model].assign_coords(lon=(((dset_dict[model]['lon'] + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return dset_dict    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7303fd30",
   "metadata": {},
   "source": [
    "## Assign attributes to the variables\n",
    " \n",
    "We will assign the attributes to the variables as in ERA5 to make CMIP6 and ERA5 variables comperable.\n",
    " \n",
    "* [`pr`](http://clipc-services.ceda.ac.uk/dreq/u/62f26742cf240c1b5169a5cd511196b6.html) and [`prsn`](http://clipc-services.ceda.ac.uk/dreq/u/051919eddec810e292c883205c944ceb.html) in **kg m-2 s-1** $\\rightarrow$ Multiply by **3600** to get **mm h-1** $\\rightarrow$ Multiply by **24** to get **mm day-1**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb00b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_att(dset):\n",
    "    now = datetime.utcnow()\n",
    "    # \n",
    "    for var_id in dset.keys():\n",
    "            \n",
    "            if var_id == 'prsn':\n",
    "                dset[var_id] = dset[var_id]*3600*24\n",
    "                dset[var_id] = dset[var_id].assign_attrs({'standard_name': 'Total snowfall per day',\n",
    "        'comment': 'At surface; includes precipitation of all forms of water in the solid phase',\n",
    "        'units': 'mm day-1',\n",
    "        'original_units': 'kg m-2 s-1',\n",
    "        'history': \"{}Z altered by F. Hellmuth: Converted units from 'kg m-2 s-1' to 'kg m-2 day-1'.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\")),\n",
    "        'cell_methods': 'area: time: mean',\n",
    "        'cell_measures': 'area: areacella'})\n",
    "                \n",
    "                \n",
    "    return dset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c56a1256",
   "metadata": {},
   "source": [
    "## Interpolate from CMIP6 hybrid sigma-pressure levels to isobaric pressure levels\n",
    "\n",
    "The vertical variables in the CMIP6 models are in hybrid sigma-pressure levels. Hence the vertical variable in the xarray datasets in `dset_dict` will be calculated by using the formula:\n",
    "$$ P(i,j,k) = hyam(k) p0 + hybm(k) ps(i,j)$$\n",
    "to calculate the pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3f633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_hybrid_plev(dset, model):\n",
    "# Rename datasets with different naming convention for constant hyam\n",
    "    if ('a' in list(dset.keys())) == True:\n",
    "        dset = dset.rename({'a':'ap', 'a_bnds': 'ap_bnds'})\n",
    "    if ('nbnd' in list(dset.dims)) == True:\n",
    "        dset = dset.rename({'nbnd':'bnds', })\n",
    "\n",
    "    if model == 'IPSL-CM6A-LR':\n",
    "        dset = dset.rename({'presnivs':'plev'})\n",
    "    if model == 'IPSL-CM5A2-INCA':\n",
    "        dset = dset.rename({'lev':'plev'})  \n",
    "        \n",
    "    if ('klevp1' in list(dset.dims)) == True:\n",
    "        dset = dset.rename({'klevp1':'lev', })\n",
    "        \n",
    "    for var_id in dset.keys():#['clw', 'cli']:\n",
    "        if var_id == 'clw' or var_id == 'cli':\n",
    "            # Convert the model level to isobaric levels\n",
    "            #### ap, b, ps, p0\n",
    "            if ('ap' in list(dset.keys())) == True and \\\n",
    "                ('ps' in list(dset.keys())) == True and \\\n",
    "                ('p0' in list(dset.keys())) == True:\n",
    "                if ('lev' in list(dset[var_id].coords)) == True and \\\n",
    "                    ('lev' in list(dset['ap'].coords)) == True and \\\n",
    "                    ('lev' in list(dset['b'].coords)) == True:\n",
    "                        print(model, var_id, 'lev, ap, ps, p0')\n",
    "                        # dset[var_id] = gc.interpolation.interp_hybrid_to_pressure(data = dset[var_id],\n",
    "                        #                                                                                 ps   = dset['ps'], \n",
    "                        #                                                                                 hyam = dset['ap'], \n",
    "                        #                                                                                 hybm = dset['b'], \n",
    "                        #                                                                                 p0   = dset['p0'], \n",
    "                        #                                                                                 new_levels=new_levels,\n",
    "                        #                                                                                 lev_dim='lev')\n",
    "                        dset['plev'] = dset['ap']*dset['p0'] + dset['b']*dset['ps']\n",
    "                        dset['plev'] = dset['plev'].transpose('time', 'lev','lat','lon')\n",
    "                        \n",
    "                        dset['plev_bnds'] = dset['ap_bnds']*dset['p0'] + dset['b_bnds']*dset['ps']\n",
    "                        dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "                \n",
    "                if ('plev' in list(dset[var_id].coords)) == True:\n",
    "                    print(model, var_id, 'variable on pressure levels', )\n",
    "                    dset['plev_bnds'] = dset['ap_bnds']*dset['p0'] + dset['b_bnds']*dset['ps']\n",
    "                    dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "                # if ('lev' in list(dset[var_id].coords)) == True and \\\n",
    "                #     ('lev' in list(dset['ap'].coords)) == False and \\\n",
    "                #     ('lev' in list(dset['b'].coords)) == False:\n",
    "                #         print(model, 'variable on pressure levels', 'lev, ap, ps,')\n",
    "            # Convert the model level to isobaric levels\n",
    "            #### ap, b, p0\n",
    "            if ('ap' in list(dset.keys())) == True and \\\n",
    "                ('ps' in list(dset.keys())) == True and \\\n",
    "                ('p0' in list(dset.keys())) == False:\n",
    "                if ('lev' in list(dset[var_id].coords)) == True and \\\n",
    "                    ('lev' in list(dset['ap'].coords)) == True and \\\n",
    "                    ('lev' in list(dset['b'].coords)) == True:\n",
    "                        print(model,var_id, 'lev, ap, ps,')\n",
    "                        # dset[var_id] = gc.interpolation.interp_hybrid_to_pressure(data = dset[var_id],\n",
    "                        #                                                                                 ps   = dset['ps'], \n",
    "                        #                                                                                 hyam = dset['ap'], \n",
    "                        #                                                                                 hybm = dset['b'], \n",
    "                        #                                                                                 new_levels=new_levels,\n",
    "                        #                                                                                 lev_dim='lev')\n",
    "                        dset['plev'] = dset['ap'] + dset['b']*dset['ps']\n",
    "                        dset['plev'] = dset['plev'].transpose('time', 'lev','lat','lon')\n",
    "                        \n",
    "                        dset['plev_bnds'] = dset['ap_bnds'] + dset['b_bnds']*dset['ps']\n",
    "                        dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "                        \n",
    "                        \n",
    "                \n",
    "                if ('plev' in list(dset[var_id].coords)) == True:\n",
    "                    print(model, var_id, 'variable on pressure levels', )\n",
    "                    dset['plev_bnds'] = dset['ap_bnds'] + dset['b_bnds']*dset['ps']\n",
    "                    dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "                \n",
    "            if ('b' in list(dset.keys())) == True and \\\n",
    "                ('orog' in list(dset.keys())) == True:\n",
    "                if ('lev' in list(dset[var_id].coords)) == True and \\\n",
    "                    ('lev' in list(dset['pfull'].coords)) == True:\n",
    "                        print(model, 'hybrid height coordinate')\n",
    "                        \n",
    "    dset = dset.transpose('time', 'lat', 'lon', 'plev', 'lev', 'bnds','axis_nbounds' , missing_dims=\"ignore\" )\n",
    "    \n",
    "                \n",
    "        \n",
    "    return dset  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8057c788",
   "metadata": {},
   "source": [
    "## Calculate liquid water path from content\n",
    "\n",
    "Once the pressure levels are calculated the daily average LWP (IWP) is calculated for each CMIP6 model.\n",
    "\\begin{equation}\n",
    "        LWP = \\rho_{air} \\cdot \\Delta clw \\cdot \\Delta Z \n",
    "\\end{equation}\n",
    "\n",
    "with hydrostatic equation\n",
    "\n",
    "\\begin{equation}\n",
    "         \\frac{\\Delta p}{\\Delta Z}  = -\\rho_{air} \\cdot g  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "         \\leftrightarrow LWP = - \\frac{\\rho_{air}}{\\rho_{air} g} \\cdot \\Delta clw \\Delta p\n",
    "\\end{equation}\n",
    "\n",
    "with $\\Delta clw = clw(NLEV-k)$ and $\\Delta p = p(NLEV-k + 1/2) - p(NLEV-k - 1/2)$ follows for the total liquid water path in the column:\n",
    "\n",
    "\\begin{equation}\n",
    "         -\\frac{1}{g} \\sum_{k=0}^{NLEV+1} LWP(k) = -\\frac{1}{g} \\sum_{k=0}^{NLEV+1} clw(NLEV-k) \\cdot [p(NLEV-k + 1/2) - p(NLEV-k - 1/2)]\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac05a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_water_path(dset, model):\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    if ('plev' in list(dset.keys())) == True:\n",
    "        print(model, 'plev')\n",
    "        _lwp = xr.DataArray(data=da.full(shape=dset['clw'].shape,fill_value=np.nan),\n",
    "                                dims=dset['clw'].dims,\n",
    "                                coords=dset['clw'].coords)\n",
    "        # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "        for i in range(len(dset['lev'])):\n",
    "                        \n",
    "            # calculate pressure difference between two levels, where the hight of the two layers is given in lev_bnds\n",
    "            dp = (dset['plev_bnds'].isel(lev=i).diff(dim='bnds'))\n",
    "            # use liquid water content between two layers, meaning at lev\n",
    "            dlwc = (dset['clw'].isel(lev=i))\n",
    "            # calculate liquid water path between two layers\n",
    "            _lwp[:,:,:,i] = - dp[:,:,:,0]/9.81 * dlwc[:,:,:]\n",
    "                \n",
    "            # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "            dset['lwp'] = _lwp.sum(dim='lev',skipna=True)\n",
    "            \n",
    "            \n",
    "            # assign attributes to data array\n",
    "            dset['lwp'] = dset['lwp'].assign_attrs(dset['clw'].attrs)\n",
    "            dset['lwp'] = dset['lwp'].assign_attrs({'long_name':'Daily average Liquid Water Path', \n",
    "                                                                            'units' : 'kg m-2',\n",
    "                                                                                'mipTable':'', 'out_name': 'lwp',\n",
    "                                                                                'standard_name': 'atmosphere_mass_content_of_cloud_liquid_water',\n",
    "                                                                                'title': 'Liquid Water Path',\n",
    "                                                                                'variable_id': 'lwp', 'original_units': 'kg/kg',\n",
    "                                                                                'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate lwp with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "        # when ice water path does not exist\n",
    "        if ('clivi' in list(dset.keys())) == False:\n",
    "        # if ('clivi' in list(dset.keys())) == True:\n",
    "            _iwp = xr.DataArray(data=da.full(shape=dset['cli'].shape,fill_value=np.nan),\n",
    "                                    dims=dset['cli'].dims,\n",
    "                                    coords=dset['cli'].coords)\n",
    "            # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "            for i in range(len(dset['lev'])):\n",
    "                                \n",
    "                # calculate pressure difference between two levels, where the hight of the two layers is given in lev_bnds\n",
    "                dp = (dset['plev_bnds'].isel(lev=i).diff(dim='bnds'))\n",
    "                # use liquid water content between two layers, meaning at lev\n",
    "                diwc = (dset['cli'].isel(lev=i))\n",
    "                # calculate liquid water path between two layers\n",
    "                _lwp[:,:,:,i] = - dp[:,:,:,0]/9.81 * dlwc[:,:,:]\n",
    "                    \n",
    "                # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "                dset['clivi'] = _iwp.sum(dim='lev',skipna=True)\n",
    "                \n",
    "                # assign attributes to data array\n",
    "                dset['clivi'] = dset['clivi'].assign_attrs(dset['cli'].attrs)\n",
    "                dset['clivi'] = dset['clivi'].assign_attrs({'long_name':'Daily average Ice Water Path', \n",
    "                                                                                'units' : 'kg m-2',\n",
    "                                                                                    'mipTable':'', 'out_name': 'clivi',\n",
    "                                                                                    'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "                                                                                    'title': 'Ice Water Path',\n",
    "                                                                                    'variable_id': 'clivi', 'original_units': 'kg/kg',\n",
    "                                                                                    'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate clivi with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "        if ('clivi' in list(dset.keys())) == True:\n",
    "            dset['clivi'] = dset['clivi'].assign_attrs({'long_name':'Daily average Ice Water Path', \n",
    "                                                                                'units' : 'kg m-2',\n",
    "                                                                                    'mipTable':'', 'out_name': 'clivi',\n",
    "                                                                                    'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "                                                                                    'title': 'Ice Water Path',\n",
    "                                                                                    'variable_id': 'clivi', 'original_units': 'kg/m2',\n",
    "                                                                                    'history': \"{}Z altered by F. Hellmuth: Rename attributes to daily average ice water path\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "            \n",
    "            \n",
    "    if ('plev' in list(dset.coords)) == True:\n",
    "        print(model, 'plev coord')\n",
    "        _lwp = xr.DataArray(data=da.full(shape=dset['clw'].shape,fill_value=np.nan),\n",
    "                                dims=dset['clw'].dims,\n",
    "                                coords=dset['clw'].coords)\n",
    "        # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "        for i in range(len(dset['plev'])):\n",
    "                        \n",
    "            # calculate pressure difference between two levels, where the hight of the two layers is given in lev_bnds\n",
    "            dp = (dset['plev_bnds'].isel(lev=i).diff(dim='bnds'))\n",
    "            # use liquid water content between two layers, meaning at lev\n",
    "            dlwc = (dset['clw'].isel(plev=i))\n",
    "            # calculate liquid water path between two layers\n",
    "            _lwp[:,:,:,i] = - dp[:,:,:,0]/9.81 * dlwc[:,:,:]\n",
    "                \n",
    "            # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "            dset['lwp'] = _lwp.sum(dim='plev',skipna=True)\n",
    "            \n",
    "            # assign attributes to data array\n",
    "            dset['lwp'] = dset['lwp'].assign_attrs(dset['clw'].attrs)\n",
    "            dset['lwp'] = dset['lwp'].assign_attrs({'long_name':'Daily average Liquid Water Path', \n",
    "                                                                            'units' : 'kg m-2',\n",
    "                                                                                'mipTable':'', 'out_name': 'lwp',\n",
    "                                                                                'standard_name': 'atmosphere_mass_content_of_cloud_liquid_water',\n",
    "                                                                                'title': 'Liquid Water Path',\n",
    "                                                                                'variable_id': 'lwp', 'original_units': 'kg/kg',\n",
    "                                                                                'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate lwp with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "        # when ice water path does not exist\n",
    "        if ('clivi' in list(dset.keys())) == False:\n",
    "        # if ('clivi' in list(dset.keys())) == True:\n",
    "            _iwp = xr.DataArray(data=da.full(shape=dset['cli'].shape,fill_value=np.nan),\n",
    "                                    dims=dset['cli'].dims,\n",
    "                                    coords=dset['cli'].coords)\n",
    "            # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "            for i in range(len(dset['plev'])):\n",
    "                                \n",
    "                # calculate pressure difference between two levels, where the hight of the two layers is given in lev_bnds\n",
    "                dp = (dset['plev_bnds'].isel(lev=i).diff(dim='bnds'))\n",
    "                # use liquid water content between two layers, meaning at lev\n",
    "                diwc = (dset['cli'].isel(lev=i))\n",
    "                # calculate liquid water path between two layers\n",
    "                _lwp[:,:,:,i] = - dp[:,:,:,0]/9.81 * dlwc[:,:,:]\n",
    "                    \n",
    "                # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "                dset['clivi'] = _iwp.sum(dim='lev',skipna=True)\n",
    "                \n",
    "                # assign attributes to data array\n",
    "                dset['clivi'] = dset['clivi'].assign_attrs(dset['clw'].attrs)\n",
    "                dset['clivi'] = dset['clivi'].assign_attrs({'long_name':'Daily average Ice Water Path', \n",
    "                                                                                'units' : 'kg m-2',\n",
    "                                                                                    'mipTable':'', 'out_name': 'clivi',\n",
    "                                                                                    'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "                                                                                    'title': 'Ice Water Path',\n",
    "                                                                                    'variable_id': 'clivi', 'original_units': 'kg/kg',\n",
    "                                                                                    'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate clivi with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "            \n",
    "        \n",
    "        if ('clivi' in list(dset.keys())) == True:\n",
    "            dset['clivi'] = dset['clivi'].assign_attrs({'long_name':'Daily average Ice Water Path', \n",
    "                                                                                'units' : 'kg m-2',\n",
    "                                                                                    'mipTable':'', 'out_name': 'clivi',\n",
    "                                                                                    'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "                                                                                    'title': 'Ice Water Path',\n",
    "                                                                                    'variable_id': 'clivi', 'original_units': 'kg/m2',\n",
    "                                                                                    'history': \"{}Z altered by F. Hellmuth: Rename attributes to daily average ice water path\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "               \n",
    "    return dset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f0bbd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(cmip_in, t_res, list_models, year_range):\n",
    "    \n",
    "    dset_dict = search_data(cmip_in, t_res, list_models, year_range)\n",
    "    for model in dset_dict.keys():\n",
    "        dset_dict[model] = assign_att(dset_dict[model])\n",
    "        dset_dict[model] = interp_hybrid_plev(dset_dict[model],model)\n",
    "        dset_dict[model] = calc_water_path(dset_dict[model], model)\n",
    "        \n",
    "        dset_dict[model] = dset_dict[model][['prsn', 'tas', 'clivi', 'lwp',]]\n",
    "    \n",
    "    return dset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1900f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR clw variable on pressure levels\n",
      "IPSL-CM6A-LR plev coord\n",
      "IPSL-CM5A2-INCA clw variable on pressure levels\n",
      "IPSL-CM5A2-INCA plev coord\n"
     ]
    }
   ],
   "source": [
    "dset_dict = process(cmip_in, t_res, list_models, year_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740f4fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files: var: prsn, year: 2006, model: IPSL-CM6A-LR\n",
      "Writing files: var: prsn, year: 2007, model: IPSL-CM6A-LR\n",
      "Writing files: var: prsn, year: 2008, model: IPSL-CM6A-LR\n",
      "Writing files: var: prsn, year: 2009, model: IPSL-CM6A-LR\n",
      "Writing files: var: tas, year: 2006, model: IPSL-CM6A-LR\n",
      "Writing files: var: tas, year: 2007, model: IPSL-CM6A-LR\n",
      "Writing files: var: tas, year: 2008, model: IPSL-CM6A-LR\n",
      "Writing files: var: tas, year: 2009, model: IPSL-CM6A-LR\n",
      "Writing files: var: clivi, year: 2006, model: IPSL-CM6A-LR\n",
      "Writing files: var: clivi, year: 2007, model: IPSL-CM6A-LR\n",
      "Writing files: var: clivi, year: 2008, model: IPSL-CM6A-LR\n",
      "Writing files: var: clivi, year: 2009, model: IPSL-CM6A-LR\n",
      "Writing files: var: lwp, year: 2006, model: IPSL-CM6A-LR\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 365. GiB for an array with shape (60265, 79, 143, 144) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m year \u001b[39min\u001b[39;00m year_range:\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mWriting files: var: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, year: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, model: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(var, year, model))\n\u001b[0;32m----> 5\u001b[0m     (dset_dict[model][var]\u001b[39m.\u001b[39;49msel(time\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(\u001b[39mstr\u001b[39;49m(year)), lat\u001b[39m=\u001b[39;49m\u001b[39mslice\u001b[39;49m(\u001b[39m45\u001b[39;49m,\u001b[39m90\u001b[39;49m)))\u001b[39m.\u001b[39;49mto_netcdf(\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_45_90_historical_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_gn_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m0101-\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m1231.nc\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(cmip_in,var, model, dset_dict[model]\u001b[39m.\u001b[39;49mattrs[\u001b[39m'\u001b[39;49m\u001b[39mvariant_label\u001b[39;49m\u001b[39m'\u001b[39;49m],year, year))\n\u001b[1;32m      6\u001b[0m     (dset_dict[model][var]\u001b[39m.\u001b[39msel(time\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(\u001b[39mstr\u001b[39m(year)), lat\u001b[39m=\u001b[39m\u001b[39mslice\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m90\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m45\u001b[39m)))\u001b[39m.\u001b[39mto_netcdf(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_-90_-45_historical_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_gn_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m0101-\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m1231.nc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(cmip_in,var, model, dset_dict[model]\u001b[39m.\u001b[39mattrs[\u001b[39m'\u001b[39m\u001b[39mvariant_label\u001b[39m\u001b[39m'\u001b[39m],year, year))\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/xarray/core/dataarray.py:3739\u001b[0m, in \u001b[0;36mDataArray.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   3735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3736\u001b[0m     \u001b[39m# No problems with the name - so we're fine!\u001b[39;00m\n\u001b[1;32m   3737\u001b[0m     dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dataset()\n\u001b[0;32m-> 3739\u001b[0m \u001b[39mreturn\u001b[39;00m to_netcdf(  \u001b[39m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   3740\u001b[0m     dataset,\n\u001b[1;32m   3741\u001b[0m     path,\n\u001b[1;32m   3742\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3743\u001b[0m     \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m   3744\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   3745\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m   3746\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3747\u001b[0m     unlimited_dims\u001b[39m=\u001b[39;49munlimited_dims,\n\u001b[1;32m   3748\u001b[0m     compute\u001b[39m=\u001b[39;49mcompute,\n\u001b[1;32m   3749\u001b[0m     multifile\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   3750\u001b[0m     invalid_netcdf\u001b[39m=\u001b[39;49minvalid_netcdf,\n\u001b[1;32m   3751\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/xarray/backends/api.py:1235\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39mif\u001b[39;00m multifile:\n\u001b[1;32m   1233\u001b[0m     \u001b[39mreturn\u001b[39;00m writer, store\n\u001b[0;32m-> 1235\u001b[0m writes \u001b[39m=\u001b[39m writer\u001b[39m.\u001b[39;49msync(compute\u001b[39m=\u001b[39;49mcompute)\n\u001b[1;32m   1237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, BytesIO):\n\u001b[1;32m   1238\u001b[0m     store\u001b[39m.\u001b[39msync()\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/xarray/backends/common.py:168\u001b[0m, in \u001b[0;36mArrayWriter.sync\u001b[0;34m(self, compute)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mda\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m# TODO: consider wrapping targets with dask.delayed, if this makes\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39m# for any discernible difference in perforance, e.g.,\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m# targets = [dask.delayed(t) for t in self.targets]\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m delayed_store \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39;49mstore(\n\u001b[1;32m    169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msources,\n\u001b[1;32m    170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargets,\n\u001b[1;32m    171\u001b[0m     lock\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlock,\n\u001b[1;32m    172\u001b[0m     compute\u001b[39m=\u001b[39;49mcompute,\n\u001b[1;32m    173\u001b[0m     flush\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     regions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregions,\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources \u001b[39m=\u001b[39m []\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/array/core.py:1237\u001b[0m, in \u001b[0;36mstore\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[39melif\u001b[39;00m compute:\n\u001b[1;32m   1236\u001b[0m     store_dsk \u001b[39m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[0;32m-> 1237\u001b[0m     compute_as_if_collection(Array, store_dsk, map_keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m schedule \u001b[39m=\u001b[39m get_scheduler(scheduler\u001b[39m=\u001b[39mscheduler, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m, get\u001b[39m=\u001b[39mget)\n\u001b[1;32m    341\u001b[0m dsk2 \u001b[39m=\u001b[39m optimization_function(\u001b[39mcls\u001b[39m)(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 342\u001b[0m \u001b[39mreturn\u001b[39;00m schedule(dsk2, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     92\u001b[0m     dsk,\n\u001b[1;32m     93\u001b[0m     keys,\n\u001b[1;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[39m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         raise_exception(exc, tb)\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[39m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m][key] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[39m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, data)\n\u001b[1;32m    225\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[39m=\u001b[39m dumps((result, \u001b[39mid\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "    \u001b[0;31m[... skipping similar frames: _execute_task at line 119 (3 times), <genexpr> at line 119 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m(_execute_task(a, cache) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/optimization.py:990\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys):\n\u001b[1;32m    989\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m args, got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minkeys), \u001b[39mlen\u001b[39m(args)))\n\u001b[0;32m--> 990\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49mget(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdsk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutkey, \u001b[39mdict\u001b[39;49m(\u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minkeys, args)))\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[39m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[39m=\u001b[39m _execute_task(task, cache)\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[39m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[39m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m~/miniconda3/envs/globalsnow/lib/python3.10/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[39m=\u001b[39m arg[\u001b[39m0\u001b[39m], arg[\u001b[39m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[39m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m(_execute_task(a, cache) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 365. GiB for an array with shape (60265, 79, 143, 144) and data type float32"
     ]
    }
   ],
   "source": [
    "for model in dset_dict.keys():\n",
    "    for var in ['prsn', 'tas', 'clivi', 'lwp',]:\n",
    "        for year in year_range:\n",
    "            print('Writing files: var: {}, year: {}, model: {}'.format(var, year, model))\n",
    "            (dset_dict[model][var].sel(time=slice(str(year)), lat=slice(45,90))).to_netcdf('{}/{}_{}_45_90_historical_{}_gn_{}0101-{}1231.nc'.format(cmip_in,var, model, dset_dict[model].attrs['variant_label'],year, year))\n",
    "            (dset_dict[model][var].sel(time=slice(str(year)), lat=slice(-90,-45))).to_netcdf('{}/{}_{}_-90_-45_historical_{}_gn_{}0101-{}1231.nc'.format(cmip_in,var, model, dset_dict[model].attrs['variant_label'],year, year))\n",
    "            \n",
    "            # (dset_dict[model][var].sel(time=slice(str(year)), lat=slice(-90,-45))).to_netcdf('{}/{}_{}_-90_-45_historical_{}_gn_{}0101-{}1231.nc'.format(cmip_in,var, model, dset_dict[model].attrs['variant_label'],year, year))\n",
    "            # (dset_dict[model][var].sel(time=slice(str(year)), lat=slice(45,90))).to_netcdf('{}/{}_{}_45_90_historical_{}_gn_{}0101-{}1231.nc'.format(cmip_in,var, model, dset_dict[model].attrs['variant_label'],year, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset_dict = search_data(cmip_in, t_res, list_models, year_range)\n",
    "# dset_dict = dict()\n",
    "# for model in list_models:\n",
    "#     cmip_file_in = glob('{}/*{}_{}_{}*'.format(cmip_in, t_res[0], model, experiment_id[0]))\n",
    "#     if len(cmip_file_in) != 0:\n",
    "#         dset_dict[model] = xr.open_mfdataset(sorted(cmip_file_in), combine='nested', compat='override', use_cftime=True)\n",
    "#         # select only years needed for analysis\n",
    "#         dset_dict[model] = dset_dict[model].sel(time = dset_dict[model]['time'].dt.year.isin(year_range)).squeeze()\n",
    "#         # shift longitude to be from -180 to 180\n",
    "#         dset_dict[model] = dset_dict[model].assign_coords(lon=(((dset_dict[model]['lon'] + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "#     else:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a5ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now = datetime.utcnow()\n",
    "# for model in dset_dict.keys():\n",
    "# # \n",
    "#     for var_id in dset_dict[model].keys():\n",
    "         \n",
    "#         if var_id == 'prsn':\n",
    "#             dset_dict[model][var_id] = dset_dict[model][var_id]*3600\n",
    "#             dset_dict[model][var_id] = dset_dict[model][var_id].assign_attrs({'standard_name': 'snowfall_flux',\n",
    "#     'long_name': 'Snowfall Flux',\n",
    "#     'comment': 'At surface; includes precipitation of all forms of water in the solid phase',\n",
    "#     'units': 'mm h-1',\n",
    "#     'original_units': 'kg m-2 s-1',\n",
    "#     'history': \"{}Z altered by F. Hellmuth: Converted units from 'kg m-2 s-1' to 'mm h-1'.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\")),\n",
    "#     'cell_methods': 'area: time: mean',\n",
    "#     'cell_measures': 'area: areacella'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rename datasets with different naming convention for constant hyam\n",
    "# for model in dset_dict.keys():\n",
    "#     if ('a' in list(dset_dict[model].keys())) == True:\n",
    "#         dset_dict[model] = dset_dict[model].rename({'a':'ap', 'a_bnds': 'ap_bnds'})\n",
    "#     if model == 'IPSL-CM6A-LR':\n",
    "#         dset_dict[model] = dset_dict[model].rename({'presnivs':'plev'})\n",
    "#     if model == 'IPSL-CM5A2-INCA':\n",
    "#         dset_dict[model] = dset_dict[model].rename({'lev':'plev'})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65936cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in dset_dict.keys():\n",
    "#     for var_id in dset_dict[model].keys():#['clw', 'cli']:\n",
    "#         if var_id == 'clw' or var_id == 'cli':\n",
    "#             # Convert the model level to isobaric levels\n",
    "#             #### ap, b, ps, p0\n",
    "#             if ('ap' in list(dset_dict[model].keys())) == True and \\\n",
    "#                 ('ps' in list(dset_dict[model].keys())) == True and \\\n",
    "#                 ('p0' in list(dset_dict[model].keys())) == True:\n",
    "#                 if ('lev' in list(dset_dict[model][var_id].coords)) == True and \\\n",
    "#                     ('lev' in list(dset_dict[model]['ap'].coords)) == True and \\\n",
    "#                     ('lev' in list(dset_dict[model]['b'].coords)) == True:\n",
    "#                         print(model, var_id, 'lev, ap, ps, p0')\n",
    "#                         # dset_dict[model][var_id] = gc.interpolation.interp_hybrid_to_pressure(data = dset_dict[model][var_id],\n",
    "#                         #                                                                                 ps   = dset_dict[model]['ps'], \n",
    "#                         #                                                                                 hyam = dset_dict[model]['ap'], \n",
    "#                         #                                                                                 hybm = dset_dict[model]['b'], \n",
    "#                         #                                                                                 p0   = dset_dict[model]['p0'], \n",
    "#                         #                                                                                 new_levels=new_levels,\n",
    "#                         #                                                                                 lev_dim='lev')\n",
    "#                         dset_dict[model]['plev'] = dset_dict[model]['ap']*dset_dict[model]['p0'] + dset_dict[model]['b']*dset_dict[model]['ps']\n",
    "#                         dset_dict[model]['plev'] = dset_dict[model]['plev'].transpose('time', 'lev','lat','lon')\n",
    "                \n",
    "#                 if ('plev' in list(dset_dict[model][var_id].coords)) == True:\n",
    "#                     print(model, var_id, 'variable on pressure levels', )\n",
    "#                 # if ('lev' in list(dset_dict[model][var_id].coords)) == True and \\\n",
    "#                 #     ('lev' in list(dset_dict[model]['ap'].coords)) == False and \\\n",
    "#                 #     ('lev' in list(dset_dict[model]['b'].coords)) == False:\n",
    "#                 #         print(model, 'variable on pressure levels', 'lev, ap, ps,')\n",
    "#             # Convert the model level to isobaric levels\n",
    "#             #### ap, b, p0\n",
    "#             if ('ap' in list(dset_dict[model].keys())) == True and \\\n",
    "#                 ('ps' in list(dset_dict[model].keys())) == True and \\\n",
    "#                 ('p0' in list(dset_dict[model].keys())) == False:\n",
    "#                 if ('lev' in list(dset_dict[model][var_id].coords)) == True and \\\n",
    "#                     ('lev' in list(dset_dict[model]['ap'].coords)) == True and \\\n",
    "#                     ('lev' in list(dset_dict[model]['b'].coords)) == True:\n",
    "#                         print(model,var_id, 'lev, ap, ps,')\n",
    "#                         # dset_dict[model][var_id] = gc.interpolation.interp_hybrid_to_pressure(data = dset_dict[model][var_id],\n",
    "#                         #                                                                                 ps   = dset_dict[model]['ps'], \n",
    "#                         #                                                                                 hyam = dset_dict[model]['ap'], \n",
    "#                         #                                                                                 hybm = dset_dict[model]['b'], \n",
    "#                         #                                                                                 new_levels=new_levels,\n",
    "#                         #                                                                                 lev_dim='lev')\n",
    "#                         dset_dict[model]['plev'] = dset_dict[model]['ap'] + dset_dict[model]['b']*dset_dict[model]['ps']\n",
    "#                         dset_dict[model]['plev'] = dset_dict[model]['plev'].transpose('time', 'lev','lat','lon')\n",
    "                \n",
    "#                 if ('plev' in list(dset_dict[model][var_id].coords)) == True:\n",
    "#                     print(model, var_id, 'variable on pressure levels', )\n",
    "                \n",
    "#             if ('b' in list(dset_dict[model].keys())) == True and \\\n",
    "#                 ('orog' in list(dset_dict[model].keys())) == True:\n",
    "#                 if ('lev' in list(dset_dict[model][var_id].coords)) == True and \\\n",
    "#                     ('lev' in list(dset_dict[model]['pfull'].coords)) == True:\n",
    "#                         print(model, 'hybrid height coordinate')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1523e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for model in dset_dict.keys():\n",
    "    \n",
    "#     if ('plev' in list(dset_dict[model].keys())) == True:\n",
    "#         print(model, 'plev')\n",
    "#         _lwp = xr.DataArray(data=da.full(shape=dset_dict[model]['clw'].shape,fill_value=np.nan),\n",
    "#                                 dims=dset_dict[model]['clw'].dims,\n",
    "#                                 coords=dset_dict[model]['clw'].coords)\n",
    "#         # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "#         for i in range(len(dset_dict[model]['lev'])-1):\n",
    "#             # calculate pressure difference between two levels\n",
    "#             dp = (dset_dict[model]['plev'].isel(lev=i) - dset_dict[model]['plev'].isel(lev=i+1))\n",
    "#             # calculate mean liquid water content between two layers\n",
    "#             dlwc = (dset_dict[model]['clw'].isel(lev=i) + dset_dict[model]['clw'].isel(lev=i+1))/2\n",
    "#             # calculate liquid water path between two layers\n",
    "#             _lwp[:,i,:,:] = dp[:,:,:]/9.81 * dlwc[:,:,:]\n",
    "        \n",
    "#             # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "#             dset_dict[model]['lwp'] = _lwp.sum(dim='lev',skipna=True)\n",
    "            \n",
    "#             # assign attributes to data array\n",
    "#             dset_dict[model]['lwp'] = dset_dict[model]['lwp'].assign_attrs(dset_dict[model]['clw'].attrs)\n",
    "#             dset_dict[model]['lwp'] = dset_dict[model]['lwp'].assign_attrs({'long_name':'Liquid Water Path', \n",
    "#                                                                             'units' : 'kg m-2',\n",
    "#                                                                                 'mipTable':'', 'out_name': 'lwp',\n",
    "#                                                                                 'standard_name': 'atmosphere_mass_content_of_cloud_liquid_water',\n",
    "#                                                                                 'title': 'Liquid Water Path',\n",
    "#                                                                                 'variable_id': 'lwp', 'original_units': 'kg/kg',\n",
    "#                                                                                 'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate lwp with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "#         # when ice water path does not exist\n",
    "#         if ('clivi' in list(dset_dict[model].keys())) == False:\n",
    "#             _iwp = xr.DataArray(data=da.full(shape=dset_dict[model]['cli'].shape,fill_value=np.nan),\n",
    "#                                     dims=dset_dict[model]['cli'].dims,\n",
    "#                                     coords=dset_dict[model]['cli'].coords)\n",
    "#             # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "#             for i in range(len(dset_dict[model]['lev'])-1):\n",
    "#                 # calculate pressure difference between two levels\n",
    "#                 dp = (dset_dict[model]['plev'].isel(lev=i) - dset_dict[model]['plev'].isel(lev=i+1))\n",
    "#                 # calculate mean liquid water content between two layers\n",
    "#                 diwc = (dset_dict[model]['cli'].isel(lev=i) + dset_dict[model]['cli'].isel(lev=i+1))/2\n",
    "#                 # calculate liquid water path between two layers\n",
    "#                 _iwp[:,i,:,:] = dp[:,:,:]/9.81 * diwc[:,:,:]\n",
    "            \n",
    "                \n",
    "#                 # sum over all layers to ge the Ice water path in the atmospheric column\n",
    "#                 dset_dict[model]['clivi'] = _iwp.sum(dim='lev',skipna=True)\n",
    "                \n",
    "#                 # assign attributes to data array\n",
    "#                 dset_dict[model]['clivi'] = dset_dict[model]['clivi'].assign_attrs(dset_dict[model]['cli'].attrs)\n",
    "#                 dset_dict[model]['clivi'] = dset_dict[model]['clivi'].assign_attrs({'long_name':'Ice Water Path', \n",
    "#                                                                                 'units' : 'kg m-2',\n",
    "#                                                                                     'mipTable':'', 'out_name': 'clivi',\n",
    "#                                                                                     'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "#                                                                                     'title': 'Ice Water Path',\n",
    "#                                                                                     'variable_id': 'clivi', 'original_units': 'kg/kg',\n",
    "#                                                                                     'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate clivi with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "            \n",
    "#     if ('plev' in list(dset_dict[model].coords)) == True:\n",
    "#         print(model, 'plev coord')\n",
    "#         _lwp = xr.DataArray(data=da.full(shape=dset_dict[model]['clw'].shape,fill_value=np.nan),\n",
    "#                                 dims=dset_dict[model]['clw'].dims,\n",
    "#                                 coords=dset_dict[model]['clw'].coords)\n",
    "#         # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "#         for i in range(len(dset_dict[model]['plev'])-1):\n",
    "#             # calculate pressure difference between two levels\n",
    "#             dp = (dset_dict[model]['plev'].isel(plev=i) - dset_dict[model]['plev'].isel(plev=i+1))\n",
    "#             # calculate mean liquid water content between two layers\n",
    "#             dlwc = (dset_dict[model]['clw'].isel(plev=i) + dset_dict[model]['clw'].isel(plev=i+1))/2\n",
    "#             # calculate liquid water path between two layers\n",
    "#             _lwp[:,i,:,:] = dp/9.81 * dlwc[:,:,:]\n",
    "        \n",
    "#             # sum over all layers to ge the liquid water path in the atmospheric column\n",
    "#             dset_dict[model]['lwp'] = _lwp.sum(dim='plev',skipna=True)\n",
    "            \n",
    "#             # assign attributes to data array\n",
    "#             dset_dict[model]['lwp'] = dset_dict[model]['lwp'].assign_attrs(dset_dict[model]['clw'].attrs)\n",
    "#             dset_dict[model]['lwp'] = dset_dict[model]['lwp'].assign_attrs({'long_name':'Liquid Water Path', \n",
    "#                                                                             'units' : 'kg m-2',\n",
    "#                                                                                 'mipTable':'', 'out_name': 'lwp',\n",
    "#                                                                                 'standard_name': 'atmosphere_mass_content_of_cloud_liquid_water',\n",
    "#                                                                                 'title': 'Liquid Water Path',\n",
    "#                                                                                 'variable_id': 'lwp', 'original_units': 'kg/kg',\n",
    "#                                                                                 'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate lwp with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "#         # when ice water path does not exist\n",
    "#         if ('clivi' in list(dset_dict[model].keys())) == False:\n",
    "#             _iwp = xr.DataArray(data=da.full(shape=dset_dict[model]['cli'].shape,fill_value=np.nan),\n",
    "#                                     dims=dset_dict[model]['cli'].dims,\n",
    "#                                     coords=dset_dict[model]['cli'].coords)\n",
    "#             # lev2 is the atmospheric pressure, lower in the atmosphere than lev. Sigma-pressure coordinates are from 1 to 0, with 1 at the surface\n",
    "#             for i in range(len(dset_dict[model]['plev'])-1):\n",
    "#                 # calculate pressure difference between two levels\n",
    "#                 dp = (dset_dict[model]['plev'].isel(plev=i) - dset_dict[model]['plev'].isel(plev=i+1))\n",
    "#                 # calculate mean liquid water content between two layers\n",
    "#                 diwc = (dset_dict[model]['cli'].isel(plev=i) + dset_dict[model]['cli'].isel(plev=i+1))/2\n",
    "#                 # calculate liquid water path between two layers\n",
    "#                 _iwp[:,i,:,:] = dp/9.81 * diwc[:,:,:]\n",
    "            \n",
    "                \n",
    "#                 # sum over all layers to ge the Ice water path in the atmospheric column\n",
    "#                 dset_dict[model]['clivi'] = _iwp.sum(dim='plev',skipna=True)\n",
    "                \n",
    "#                 # assign attributes to data array\n",
    "#                 dset_dict[model]['clivi'] = dset_dict[model]['clivi'].assign_attrs(dset_dict[model]['clw'].attrs)\n",
    "#                 dset_dict[model]['clivi'] = dset_dict[model]['clivi'].assign_attrs({'long_name':'Ice Water Path', \n",
    "#                                                                                 'units' : 'kg m-2',\n",
    "#                                                                                     'mipTable':'', 'out_name': 'clivi',\n",
    "#                                                                                     'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "#                                                                                     'title': 'Ice Water Path',\n",
    "#                                                                                     'variable_id': 'clivi', 'original_units': 'kg/kg',\n",
    "#                                                                                     'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate clivi with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ada7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9188a63c",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1zb0LHvipx8JOXLLrCxzYToJM7eNK4eaw\"  height=\"100\" />\n",
    "<img src=\"https://reliance.rohub.org/static/media/Reliance-logo.433dc2e9.png\"  height=\"100\" />\n",
    "\n",
    "<img src=\"https://www.uio.no/vrtx/decorating/resources/dist/src2/images/footer/uio-logo-en.svg\"  height=\"100\" />\n",
    "<img src=\"https://erc.europa.eu/sites/default/files/logo_0.png\"  height=\"100\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfbcf9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('globalsnow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
