{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117ddff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PYTHONPATH=\"${PYTHONPATH}:/uio/kant/geo-geofag-u1/franzihe/Documents/Python/globalsnow/CloudSat_ERA5_CMIP6_analysis/utils/\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "709c8e52",
   "metadata": {},
   "source": [
    "# Example with CMIP6 models (100 - 500 km)\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f77edda",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>\n",
    "Cloud feedbacks are a major contributor to the spread of climate sensitivity in global climate models (GCMs) [Zelinka et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019GL085782). Among the most poorly understood cloud feedbacks is the one associated with the cloud phase, which is expected to be modified with climate change [Bjordal et al. (2020)](https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1). Cloud phase bias, in addition, has significant implications for the simulation of radiative properties and glacier and ice sheet mass balances in climate models. \n",
    "\n",
    "In this context, this work aims to expand our knowledge on how the representation of the cloud phase affects snow formation in GCMs. Better understanding this aspect is necessary to develop climate models further and improve future climate predictions. \n",
    "\n",
    "* Retrieve CMIP6 data through [ESGF](https://esgf-node.llnl.gov/search/cmip6/)\n",
    "* Hybrid sigma-pressure coordinates to isobaric pressure levels of the European Centre for Medium-Range Weather Forecast Re-Analysis 5 (ERA5) with [GeoCAT-comb](https://geocat-comp.readthedocs.io/en/latest/index.html)\n",
    "* Regridd the CMIP6 variables to the exact horizontal resolution with [`xesmf`](https://xesmf.readthedocs.io/en/latest/)\n",
    "* Calculate an ensemble mean of all used models\n",
    "* Calculate and plot the seasonal mean of the ensemble mean\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall varying between 2007 and 2010?\n",
    "\n",
    "> **_NOTE:_** We answer questions related to the comparison of CMIP models to ERA5 in another [Jupyter Notebook](../CMIP6_ERA5_CloudSat/plt_seasonal_mean.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f939501",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "This study will compare surface snowfall, ice, and liquid water content from the Coupled Model Intercomparison Project Phase 6 ([CMIP6](https://esgf-node.llnl.gov/projects/cmip6/)) climate models to the European Centre for Medium-Range Weather Forecast Re-Analysis 5 ([ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)) data from **2006 to 2009**. We conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models and their potential connection between them. \n",
    "\n",
    "- Time period: 2006 to 2009\n",
    "- horizonal resolution: depending on model\n",
    "- time resolution: daily mean atmospheric data (CFday, day)\n",
    "- Variables:\n",
    "  \n",
    "| shortname     |             Long name                   |      Units    |  levels |\n",
    "| ------------- |:---------------------------------------:| -------------:|--------:|\n",
    "|  prsn         |    Snowfall Flux                        | [kg m-2 s-1]  | surface |\n",
    "| clw           |    Mass Fraction of Cloud Liquid Water  |  [kg kg-1]    |    ml   | \n",
    "|               |                                         | to calculate lwp use integral clw -dp/dg | |\n",
    "| tas           |    Near-Surface Air Temperature         |   [K]         | surface |\n",
    "| clivi         |    Ice Water Path                       | [kg m-2]      |         |\n",
    "| lwp           |    Liquid Water Path                    | [kg m-2]      |         |\n",
    "\n",
    "- CMIP6 models:\n",
    "\n",
    "| Institution                                            |     Model name    | Reference                                                     |\n",
    "| ------------------------------------------------------ |:-----------------:|--------------------------------------------------------------:|\n",
    "| [MIROC]() | MIROC6           | [Tatebe et al. (2019)]() |\n",
    "| [NCAR]()  | CESM2            | [Danabasoglu et al. (2020)]()  |\n",
    "| [CCCma]() | CanESM5          | [Swart et al. (2019)]()     |\n",
    "| [AWI]()   | AWI-ESM-1-1-LR   | []() |\n",
    "| []()      | MPI-ESM1-2-LR    | []() |\n",
    "| [MOHC]()  | UKESM1-0-LL      | []() |\n",
    "| [MOHC]()  | HadGem3-GC31-LL  | [Roberts et al. (2019)]() |\n",
    "| [CNRM-CERFACS]() | CNRM-CM6-1 | [Voldoire et al. (2019)]() |\n",
    "| [CNRM-CERFACS]() | CNRM-ESM2-1| [Seferian et al. (2019)]() |\n",
    "| [IPSL]() | IPSL-CM6A-LR | [Boucher et al. (2020)]() |\n",
    "| [IPSL]() | IPSL-CM5A2-INCA | []()|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b693459",
   "metadata": {},
   "source": [
    "## Organize my data\n",
    "\n",
    "- Define a prefix for my project (you may need to adjust it for your own usage on your infrastructure).\n",
    "    - input folder where all the data used as input to my Jupyter Notebook is stored (and eventually shared)\n",
    "    - output folder where all the results to keep are stored\n",
    "    - tool folder where all the tools\n",
    "\n",
    "`/input/cmip6_hist/daily_means`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f298f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimi.uio.no\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "abs_path = str(pathlib.Path(hostname).parent.absolute())\n",
    "WORKDIR = abs_path[:- (len(abs_path.split('/')[-2] + abs_path.split('/')[-1])+1)]\n",
    "\n",
    "\n",
    "if \"mimi\" in hostname:\n",
    "    print(hostname)\n",
    "    DATA_DIR = \"/scratch/franzihe/\"\n",
    "elif \"glefsekaldt\" in hostname: \n",
    "    DATA_DIR = \"/home/franzihe/Data/\"\n",
    "\n",
    "INPUT_DATA_DIR = os.path.join(DATA_DIR, 'input')\n",
    "OUTPUT_DATA_DIR = os.path.join(DATA_DIR, 'output')\n",
    "UTILS_DIR = os.path.join(WORKDIR, 'utils/')\n",
    "\n",
    "sys.path.append(UTILS_DIR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c652dc0b",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [requirements_globalsnow.txt](../../requirements_globalsnow.txt) \n",
    "- load `python` packages from [imports.py](../../utils/imports.py)\n",
    "- load `functions` from [functions.py](../../utils/functions.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4caa42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7fddcc379f60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "from imports import (xr, intake, cftime, xe, glob, np, cm, pd, fct,ccrs, cy, plt, da, gc, datetime, LogNorm, distributed,)# dask)\n",
    "xr.set_options(display_style=\"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb920800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dad501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client for distributed computing with dask\n",
    "# client = dask.distributed.Client()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "620cb825",
   "metadata": {},
   "source": [
    "## Open CMIP6 variables\n",
    "Get the data required for the analysis. Beforehand we downloaded the daily averaged data on single levels and model levels via."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ceedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip_in = os.path.join(INPUT_DATA_DIR, 'cmip6_hist/')\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(os.path.join(cmip_in, 'common_grid'))\n",
    "    os.mkdir(os.path.join(cmip_in, 'single_model'))\n",
    "except OSError:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994d8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_id = ['clw', 'cli', 'clivi', 'tas', 'prsn', 'pr', 'pfull', 'phalf',  'areacella']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "424276a6",
   "metadata": {},
   "source": [
    "At the moment we have downloaded the end of the historical simulations for CMIP6 models. We define start and end year to ensure to only extract the 4-year period between 2006 and 2009.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year\n",
    "\n",
    "We will load all available models into one dictonary, which includes an xarray dataset with `xarray.open_mfdataset(file)` and select the time range [by name](https://xarray.pydata.org/en/stable/user-guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598731dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_id\n",
    "list_models = [\n",
    "               'MIROC6', #area\n",
    "               # 'CESM2', #area # this model has snowfall only over land\n",
    "               'CanESM5', # area\n",
    "               'AWI-ESM-1-1-LR', # area\n",
    "               'MPI-ESM1-2-LR', # area\n",
    "               'UKESM1-0-LL', \n",
    "               'HadGEM3-GC31-LL',\n",
    "               'CNRM-CM6-1', #area\n",
    "               'CNRM-ESM2-1', #area\n",
    "               'IPSL-CM6A-LR', #area\n",
    "               'IPSL-CM5A2-INCA' #area\n",
    "            ]\n",
    "\n",
    "## experiment\n",
    "experiment_id = ['historical']\n",
    "\n",
    "## time resolution\n",
    "t_res = ['day',]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20590565",
   "metadata": {},
   "source": [
    "## Search corresponding data\n",
    "Get the data required for the analysis. Define variables, models, experiment, and time resolution as defined in <a href=\"#data_wrangling\">2. Data Wrangling</a>\n",
    ". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39590c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ds_var_id(files, year_range, var_id,model):\n",
    "    if len(files) > 0:\n",
    "        if var_id == 'pr':\n",
    "            ds_var_id = xr.open_mfdataset(files,drop_variables=['prsn'])\n",
    "            \n",
    "        elif var_id == 'ta':\n",
    "            ds_var_id = xr.open_mfdataset(files,drop_variables=['tas', 'height'])\n",
    "        elif var_id == 'phalf':\n",
    "            ds_var_id = xr.open_mfdataset(files,drop_variables=['b','orog','b_bnds', 'ps','ap','ap_bnds',])\n",
    "            # if model == 'IPSL-CM6A-LR':\n",
    "            #     ds_var_id = ds_var_id.assign_coords({'presnivs': ds_var_id['klev'].data})\n",
    "            #     ds_var_id = ds_var_id.drop_dims({'klev'}).rename({'presnivs':'klev'})\n",
    "                \n",
    "            #     # ds_var_id = ds_var_id.rename({'presnivs':'half_lev',})\n",
    "            # #     \n",
    "            # else:\n",
    "            ds_var_id = ds_var_id.rename({'lev':'half_lev','lev_bnds':'half_lev_bnds'})\n",
    "        \n",
    "           \n",
    "        else:\n",
    "            ds_var_id = xr.open_mfdataset(files)\n",
    "        # select only years needed for analysis\n",
    "        ds_var_id = ds_var_id.sel(time=ds_var_id['time'].dt.year.isin(year_range)).squeeze()\n",
    "        \n",
    "        \n",
    "            \n",
    "        if var_id not in list(ds_var_id.keys()):\n",
    "            print(f'{var_id} do not exists in {model}')\n",
    "            return(xr.Dataset())\n",
    "        else:\n",
    "            # ds_var_id[var_id] = ds_var_id[var_id].where(ds_var_id[var_id] >= 0.)\n",
    "            return(ds_var_id)\n",
    "    else:\n",
    "        print(f'no files found for {var_id} in {model}')\n",
    "        return(xr.Dataset())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d372e68",
   "metadata": {},
   "source": [
    "We can call dask.delayed on our funtions to make them lazy. Rather than compute their results immediately, they record what we want to compute as a task into a graph that we’ll run later on parallel hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7a0e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def search_data(cmip_in, t_res,model,experiment_id,variable_id, year_range, variant_label=None):\n",
    "    if model == 'CNRM-CM6-1':\n",
    "        file_paths = [\n",
    "        os.path.join(\n",
    "            cmip_in, f\"single_model/{model}/{var}_*{t_res[0]}_{model}_{experiment_id[0]}_{variant_label}*\"\n",
    "        ) for var in variable_id[:-1]\n",
    "    ]\n",
    "    else:\n",
    "        file_paths = [\n",
    "        os.path.join(\n",
    "            cmip_in, f\"single_model/{model}/{var}_*{t_res[0]}_{model}_{experiment_id[0]}*\"\n",
    "        ) for var in variable_id[:-1]\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # file_paths = (dask.delayed(glob)(file_path) for file_path in file_paths)\n",
    "    file_paths = [glob(file_path) for file_path in file_paths]\n",
    "    \n",
    "    # ds_clw, ds_cli, ds_clivi, ds_tas, ds_prsn, ds_pr, ds_pfull, ds_ta = ([\n",
    "    #     dask.delayed(open_ds_var_id)(files, year_range, var_id)\n",
    "    #     for files, var_id in zip(file_paths, variable_id)\n",
    "    # ])\n",
    "    ds_clw, ds_cli, ds_clivi, ds_tas, ds_prsn, ds_pr, ds_pfull, ds_phalf = ([\n",
    "        open_ds_var_id(files, year_range, var_id, model)\n",
    "        for files, var_id in zip(file_paths, variable_id)\n",
    "    ])\n",
    "    \n",
    "    dsets = [ds_clw, ds_cli, ds_clivi, ds_tas, ds_prsn, ds_pr, ds_pfull, ds_phalf]\n",
    "    \n",
    "        \n",
    "    \n",
    "    # Combine datasets by coordinates\n",
    "    # dset = dask.delayed(xr.combine_by_coords)([ds for ds in dsets])\n",
    "    dset = xr.combine_by_coords([ds for ds in dsets if not (len(ds.dims) == 0)], combine_attrs ='drop_conflicts')\n",
    "    \n",
    "    if not len(ds_pfull) == 0: # sort to start at the top of the atmosphere\n",
    "        dset = dset.reindex(lev= dset.lev[::-1])\n",
    "        dset = dset.reindex(half_lev= dset.half_lev[::-1])\n",
    "    \n",
    "    try:\n",
    "        ds_areacella = xr.open_dataset(\n",
    "            glob(f\"{cmip_in}/single_model/{model}/areacella_fx_*{model}_{experiment_id[0]}*.nc\")[0],\n",
    "            drop_variables=[\"lat_bnds\", \"lon_bnds\"],\n",
    "        )\n",
    "        dset = xr.merge([dset, ds_areacella])\n",
    "    except IndexError:\n",
    "        print(f'areacella does not exist in {model}')\n",
    "        \n",
    "    # shift longitude to be from -180 to 180\n",
    "    dset = dset.assign_coords(lon=(((dset['lon'] + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "    dset = dset.drop({'height'})\n",
    "    \n",
    "    return dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55296859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no files found for clivi in MIROC6\n",
      "no files found for pfull in MIROC6\n",
      "no files found for phalf in MIROC6\n",
      "no files found for pfull in CanESM5\n",
      "no files found for phalf in CanESM5\n",
      "no files found for cli in AWI-ESM-1-1-LR\n",
      "no files found for pfull in AWI-ESM-1-1-LR\n",
      "no files found for phalf in AWI-ESM-1-1-LR\n",
      "no files found for cli in MPI-ESM1-2-LR\n",
      "no files found for pfull in MPI-ESM1-2-LR\n",
      "no files found for phalf in MPI-ESM1-2-LR\n",
      "no files found for cli in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "no files found for cli in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "no files found for cli in CNRM-CM6-1\n",
      "no files found for pfull in CNRM-CM6-1\n",
      "no files found for phalf in CNRM-CM6-1\n",
      "no files found for cli in CNRM-ESM2-1\n",
      "no files found for pfull in CNRM-ESM2-1\n",
      "no files found for phalf in CNRM-ESM2-1\n",
      "no files found for cli in IPSL-CM6A-LR\n",
      "no files found for pfull in IPSL-CM6A-LR\n",
      "no files found for phalf in IPSL-CM6A-LR\n",
      "no files found for cli in IPSL-CM5A2-INCA\n",
      "no files found for pfull in IPSL-CM5A2-INCA\n",
      "no files found for phalf in IPSL-CM5A2-INCA\n"
     ]
    }
   ],
   "source": [
    "year=2006\n",
    "dset = dict()\n",
    "for model in list_models:\n",
    "        if model == 'CNRM-CM6-1':\n",
    "                dset[model] = search_data(cmip_in, t_res,model,experiment_id,variable_id, range(year, year+1), variant_label='r1i1p1f2')\n",
    "        else:\n",
    "                dset[model] = search_data(cmip_in, t_res,model,experiment_id,variable_id, range(year, year+1), )\n",
    "                \n",
    "# dset[model]#.attrs['references']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7303fd30",
   "metadata": {},
   "source": [
    "## Assign attributes to the variables\n",
    " \n",
    "We will assign the attributes to the variables as in ERA5 to make CMIP6 and ERA5 variables comperable.\n",
    " \n",
    "* [`pr`](http://clipc-services.ceda.ac.uk/dreq/u/62f26742cf240c1b5169a5cd511196b6.html) and [`prsn`](http://clipc-services.ceda.ac.uk/dreq/u/051919eddec810e292c883205c944ceb.html) in **kg m-2 s-1** $\\rightarrow$ Multiply by **3600** to get **mm h-1** $\\rightarrow$ Multiply by **24** to get **mm day-1**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb00b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_att(dset):\n",
    "    now = datetime.utcnow()\n",
    "    # \n",
    "    for var_id in dset.keys():\n",
    "            \n",
    "            if var_id == 'prsn':\n",
    "                dset[var_id] = dset[var_id]*3600\n",
    "                dset[var_id] = dset[var_id].assign_attrs({'standard_name': 'snowfall_flux',\n",
    "                                                            'comment': 'At surface; includes precipitation of all forms of water in the solid phase',\n",
    "                                                            'units': 'kg m-2 h-1',\n",
    "                                                            'original_units': 'kg m-2 s-1',\n",
    "                                                            'history': \"{}Z altered by F. Hellmuth: Converted units from 'kg m-2 s-1' to 'kg m-2 h-1'.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\")),\n",
    "                                                            'cell_methods': 'area: time: mean',\n",
    "                                                            'cell_measures': 'area: areacella'})\n",
    "                \n",
    "            if var_id == 'pr':\n",
    "                dset[var_id] = dset[var_id]*3600\n",
    "                dset[var_id] = dset[var_id].assign_attrs({'standard_name': 'precipitation_flux',\n",
    "                                                          'comment': 'includes both liquid and solid phases',\n",
    "                                                          'units': 'kg m-2 h-1',\n",
    "                                                          'original_units': 'kg m-2 s-1',\n",
    "                                                          'history':\"{}Z altered by F. Hellmuth: Converted units from 'kg m-2 s-1' to 'kg m-2 h-1'.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\")),\n",
    "                                                          'cell_methods': 'area: time: mean',\n",
    "                                                          'cell_measures': 'area: areacella'})\n",
    "                \n",
    "                \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8fbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in list_models:\n",
    "#     dset[model] = assign_att(dset[model])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c56a1256",
   "metadata": {},
   "source": [
    "## Interpolate from CMIP6 hybrid sigma-pressure levels to isobaric pressure levels\n",
    "\n",
    "The vertical variables in the CMIP6 models are in hybrid sigma-pressure levels. Hence the vertical variable in the xarray datasets in `dset_dict` will be calculated by using the formula:\n",
    "$$ P(i,j,k) = hyam(k) p0 + hybm(k) ps(i,j)$$\n",
    "to calculate the pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2459b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_hybrid_plev(dset, model):\n",
    "    \n",
    "    # You can simplify the if conditions by using the \"in\" operator to check if the required keys are present in the dictionary.\n",
    "    # Rename datasets with different naming convention for constant hyam\n",
    "    if 'a' in dset and 'a_bnds' in dset:\n",
    "        dset = dset.rename({'a':'ap', 'a_bnds': 'ap_bnds'})\n",
    "    if 'nbnd' in dset.dims:\n",
    "        dset = dset.rename({'nbnd':'bnds'})\n",
    "    if 'presnivs' in dset.dims:\n",
    "        dset = dset.rename({'presnivs':'plev'})\n",
    " \n",
    "    if model == 'IPSL-CM5A2-INCA' and 'lev' in dset.dims:\n",
    "        dset = dset.rename({'lev':'plev'})\n",
    "        \n",
    "    \n",
    "    \n",
    "    # if all the necessary variables are present in the dataset before performing any calculations. If any of the \n",
    "    # variables are missing, the function can simply move on to the next variable. This will reduce the number of \n",
    "    # unnecessary calculations that are performed.\n",
    "    for var_id in ['clw', 'cli']:\n",
    "        \n",
    "        # Convert the model level to isobaric levels\n",
    "        # Instead of checking if a key is present in the list of keys returned by dset.keys(), it would be faster \n",
    "        # to use the in operator to check if the key is present in the dictionary. For example, instead of \n",
    "        # if ('a' in list(dset.keys())) == True:, it would be faster to use if 'a' in dset:.\n",
    "        if 'ap' in dset and 'ps' in dset and 'p0' in dset:\n",
    "            if 'lev' in dset[var_id].coords and 'lev' in dset['ap'].coords and 'lev' in dset['b'].coords:\n",
    "                # Convert to pressure levels\n",
    "                dset['plev'] = dset['ap']*dset['p0'] + dset['b']*dset['ps']\n",
    "                # dset['plev'] = dset['plev'].transpose('time', 'lev','lat','lon')\n",
    "                \n",
    "            # Create plev_bnds array\n",
    "            dset['plev_bnds'] = dset['ap_bnds']*dset['p0'] + dset['b_bnds']*dset['ps']\n",
    "            # Instead of using the transpose method on the entire array, you can specify the dimensions you want to transpose\n",
    "            # dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "                \n",
    "        elif 'ap' in dset and 'ps' in dset and 'p0' not in dset:\n",
    "            if 'lev' in dset[var_id].coords and 'lev' in dset['ap'].coords and 'lev' in dset['b'].coords:\n",
    "                dset['plev'] = dset['ap'] + dset['b']*dset['ps']\n",
    "                # dset['plev'] = dset['plev'].transpose('time', 'lev','lat','lon')\n",
    "                \n",
    "            dset['plev_bnds'] = dset['ap_bnds'] + dset['b_bnds']*dset['ps']\n",
    "            # dset['plev_bnds'] = dset['plev_bnds'].transpose('time', 'lev','lat','lon', 'bnds')\n",
    "        \n",
    "        \n",
    "        dset = dset.transpose('time', 'lat', 'lon', 'plev', 'lev', 'bnds','axis_nbounds', 'half_lev', 'klevp1', missing_dims=\"ignore\" )\n",
    "\n",
    "        # Remove unnecessary variables\n",
    "        dset = dset.drop_vars(['ap', 'b', 'ps', 'p0', 'ap_bnds', 'b_bnds', 'lev_bnds', 'orog'], errors='ignore')\n",
    "        \n",
    "        \n",
    "                \n",
    "                \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fe93f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in list_models:\n",
    "#     dset[model] = interp_hybrid_plev(dset[model], model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8057c788",
   "metadata": {},
   "source": [
    "## Calculate liquid water path from content\n",
    "\n",
    "Once the pressure levels are calculated the daily average LWP (IWP) is calculated for each CMIP6 model.\n",
    "\\begin{equation}\n",
    "        LWP = \\rho_{air} \\cdot \\Delta clw \\cdot \\Delta Z \n",
    "\\end{equation}\n",
    "\n",
    "with hydrostatic equation\n",
    "\n",
    "\\begin{equation}\n",
    "         \\frac{\\Delta p}{\\Delta Z}  = -\\rho_{air} \\cdot g  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "         \\leftrightarrow LWP = - \\frac{\\rho_{air}}{\\rho_{air} g} \\cdot \\Delta clw \\Delta p\n",
    "\\end{equation}\n",
    "\n",
    "with $\\Delta clw = clw(NLEV-k)$ and $\\Delta p = p(NLEV-k + 1/2) - p(NLEV-k - 1/2)$ follows for the total liquid water path in the column:\n",
    "\n",
    "\\begin{equation}\n",
    "         -\\frac{1}{g} \\sum_{k=0}^{NLEV+1} LWP(k) = -\\frac{1}{g} \\sum_{k=0}^{NLEV+1} clw(NLEV-k) \\cdot [p(NLEV-k + 1/2) - p(NLEV-k - 1/2)]\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "985d3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_water_path(dset,model, g=9.81, now = datetime.utcnow()):\n",
    "    \n",
    "    \n",
    "    if 'plev' in dset:\n",
    "        dp = (dset['plev_bnds'].diff(dim='bnds')).squeeze()\n",
    "        if model == 'IPSL-CM6A-LR' or model == 'IPSL-CM5A2-INCA':\n",
    "            dp = dp.sel(klevp1=slice(0,len(dset['klevp1'])-1)).assign_coords({'klevp1': dset['clw'].plev.data})\n",
    "            dp = dp.rename({'klevp1':'lev'})\n",
    "            dset = dset.rename({'plev':'lev'})\n",
    "    elif 'phalf' in dset:\n",
    "        dp = (dset['phalf'].diff(dim='half_lev')).squeeze()\n",
    "        dp = dp.assign_coords({'half_lev': dset['clw'].lev.data})\n",
    "        dp = dp.rename({'half_lev':'lev'})\n",
    "    else:\n",
    "        return dset\n",
    "    \n",
    "    _lwp = - dp / g * dset['clw']\n",
    "    lwp_sum = np.sum(_lwp, axis=_lwp.get_axis_num('lev'), keepdims=True).squeeze()\n",
    "    dset['lwp'] = xr.DataArray(lwp_sum, coords=dset['prsn'].coords, dims=dset['prsn'].dims)\n",
    "    \n",
    "    dset['lwp'] = dset['lwp'].assign_attrs(dset['clw'].attrs)\n",
    "    dset['lwp'] = dset['lwp'].assign_attrs({\n",
    "            'long_name': 'Daily average Liquid Water Path',\n",
    "            'units': 'kg m-2',\n",
    "            'mipTable': '',\n",
    "            'out_name': 'lwp',\n",
    "            'standard_name': 'atmosphere_mass_content_of_cloud_liquid_water',\n",
    "            'title': 'Liquid Water Path',\n",
    "            'variable_id': 'lwp',\n",
    "            'original_units': 'kg/kg',\n",
    "            'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate lwp with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "        })\n",
    "        \n",
    "    dset = dset.drop_vars(['clw'])\n",
    "    \n",
    "    if 'cli' in dset:\n",
    "        _iwp = - dp / g * dset['cli']\n",
    "        iwp_sum = np.sum(_iwp, axis=_iwp.get_axis_num('lev'), keepdims=True).squeeze()\n",
    "        dset['clivi'] = xr.DataArray(iwp_sum, coords=dset['prsn'].coords, dims=dset['prsn'].dims)\n",
    "        \n",
    "        dset['clivi'] = dset['clivi'].assign_attrs(dset['cli'].attrs)\n",
    "        dset['clivi'] = dset['clivi'].assign_attrs({\n",
    "                'long_name':'Daily average Ice Water Path', \n",
    "                'units' : 'kg m-2',\n",
    "                'mipTable':'', \n",
    "                'out_name': 'clivi',\n",
    "                'standard_name': 'atmosphere_mass_content_of_cloud_ice_water',\n",
    "                'title': 'Ice Water Path',\n",
    "                'variable_id': 'clivi', \n",
    "                'original_units': 'kg/kg',\n",
    "                'history': \"{}Z altered by F. Hellmuth: Interpolate data from hybrid-sigma levels to isobaric levels with P=a*p0 + b*psfc. Calculate clivi with hydrostatic equation.\".format(now.strftime(\"%d/%m/%Y %H:%M:%S\"))})\n",
    "            \n",
    "        dset = dset.drop_vars(['cli'])\n",
    "        \n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41dad6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in list_models:\n",
    "#     dset[model] = calc_water_path(dse[model],model, g=9.81, now = datetime.utcnow())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75cf732a",
   "metadata": {},
   "source": [
    "## Regrid CMIP6 data to IPSL-CM6A-LR and IPSL-CM5A2_INCA grid <a id='regrid_hz'></a>\n",
    "\n",
    "We want to conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models. At the moment we have all historical data from the CMIP6 models. For this, we will have to extract the 4-year period between 2006 and 2009.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year.\n",
    "\n",
    "The CMIP6 high resolution models have approximately a nominal resolution of 250km. But not all have identical grid spacing. Hence we will make use of the python package `xesmf` and the documentation on [decreasing resolution](https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html#Decreasing-resolution), [Limitations and warnings](https://xesmf.readthedocs.io/en/latest/notebooks/Masking.html?highlight=conservative#Limitations-and-warnings). \n",
    "\n",
    "IPSL-CM6A-LR will be the reference grid for models with 250km resolution.\n",
    "\n",
    "$\\rightarrow$ Define IPSL-CM6A-LR as the reference grid `ds_out`.\n",
    "\n",
    "Create a new Python dictionary (`dset_gridded`) with the regridded CMIP6 `xarray` datasets between 2006 an 2009. Save each regridded model to a `netcdf`, locally. \n",
    "\n",
    "> **_NOTE:_** This step may take several minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eea6df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_and_save(dset, ds_out, grid_model, model, cmip_in, year):\n",
    "\n",
    "    if 'lat_bnds' in dset or 'lon_bnds' in dset:\n",
    "        dset = dset.drop_vars({'lat_bnds', 'lon_bnds'})\n",
    "    \n",
    "    regridder = xe.Regridder(ds_in=dset, ds_out=ds_out, method=\"conservative\")\n",
    "    dset_regrid = regridder(dset)\n",
    "    if 'areacella' not in list(dset_regrid.keys()):\n",
    "        dset_regrid['areacella'] = ds_out['areacella']\n",
    "\n",
    "    # var_ids = ['clivi', 'lwp', 'pr', 'prsn', 'tas', 'areacella']\n",
    "    var_ids = ['areacella']\n",
    "\n",
    "    for var_id in var_ids:\n",
    "        if var_id in list(dset_regrid.keys()):\n",
    "            print(f'Writing regrid files: var_id: {var_id}, year: {year}, model: {model}')\n",
    "\n",
    "            variant_label = dset.attrs['variant_label']\n",
    "            NH_file_grid = f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_40_90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "            SH_file_grid = f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_-40_-90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "            (dset_regrid[var_id].sel(lat=slice(40, 90))).to_netcdf(NH_file_grid)\n",
    "            (dset_regrid[var_id].sel(lat=slice(-90, -40))).to_netcdf(SH_file_grid)\n",
    "        else:\n",
    "                print(f'{var_id} does not exist in {model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bedc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2678168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create a memory object with a cache directory\n",
    "# cache_dir = '/scratch/franzihe/cache_dir/'\n",
    "# memory = Memory(location=cache_dir)\n",
    "\n",
    "# # Decorate the search_data function with the cache memory\n",
    "# @memory.cache\n",
    "# def search_data_cached(t_res, model, experiment_id, variable_id, year_range):\n",
    "#     return search_data(t_res, model, experiment_id, variable_id, year_range)\n",
    "\n",
    "def process_year(year, list_models,cmip_in, t_res, experiment_id,variable_id):\n",
    "    for model in list_models:\n",
    "        if model == 'CNRM-CM6-1':\n",
    "                dset = search_data(cmip_in, t_res,model,experiment_id,variable_id, range(year, year+1), variant_label='r1i1p1f2')\n",
    "        else:\n",
    "                dset = search_data(cmip_in, t_res,model,experiment_id,variable_id, range(year, year+1), )\n",
    "        dset = assign_att(dset)\n",
    "        dset = interp_hybrid_plev(dset,model)\n",
    "        dset = calc_water_path(dset,model, g=9.81, now = datetime.utcnow())\n",
    "        \n",
    "       \n",
    "        # for var_id in ['clivi', 'lwp', 'pr', 'prsn', 'tas', 'areacella']:\n",
    "        for var_id in ['areacella',]:\n",
    "            if var_id in list(dset.keys()):\n",
    "                print(f'Writing files: var_id: {var_id}, year: {year}, model: {model}')\n",
    "                variant_label = dset.attrs['variant_label']\n",
    "                NH_file = f'{cmip_in}/single_model/{model}/{var_id}_{model}_40_90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "                SH_file = f'{cmip_in}/single_model/{model}/{var_id}_{model}_-40_-90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "                \n",
    "                (dset[var_id].sel(lat=slice(40,90))).to_netcdf(NH_file)\n",
    "                (dset[var_id].sel(lat=slice(-90,-40))).to_netcdf(SH_file)\n",
    "            \n",
    "            else:\n",
    "                print(f'{var_id} does not exist in {model}')\n",
    "            \n",
    "        for grid_model in ['IPSL-CM6A-LR', 'IPSL-CM5A2-INCA']:\n",
    "                ds_out = xr.open_dataset(glob(f\"{cmip_in}/single_model/{grid_model}/areacella_*{grid_model}_{experiment_id[0]}*.nc\")[0],)\n",
    "                # Shift longitude to be from -180 to 180\n",
    "                ds_out = ds_out.assign_coords(lon=(((ds_out['lon'] + 180) % 360) - 180)).sortby('lon')\n",
    "                if grid_model == 'IPSL-CM6A-LR':\n",
    "                        if model == 'CanESM5' or model == 'IPSL-CM5A2-INCA':\n",
    "                                continue\n",
    "                        else:\n",
    "                                regrid_and_save(dset, ds_out, grid_model, model, cmip_in, year)\n",
    "                elif grid_model == 'IPSL-CM5A2-INCA':\n",
    "                        regrid_and_save(dset, ds_out, grid_model, model, cmip_in, year)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7441eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no files found for clivi in MIROC6\n",
      "no files found for pfull in MIROC6\n",
      "no files found for phalf in MIROC6\n",
      "Writing files: var_id: areacella, year: 2006, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: MIROC6\n",
      "no files found for pfull in CanESM5\n",
      "no files found for phalf in CanESM5\n",
      "Writing files: var_id: areacella, year: 2006, model: CanESM5\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: CanESM5\n",
      "no files found for cli in AWI-ESM-1-1-LR\n",
      "no files found for pfull in AWI-ESM-1-1-LR\n",
      "no files found for phalf in AWI-ESM-1-1-LR\n",
      "Writing files: var_id: areacella, year: 2006, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: AWI-ESM-1-1-LR\n",
      "no files found for cli in MPI-ESM1-2-LR\n",
      "no files found for pfull in MPI-ESM1-2-LR\n",
      "no files found for phalf in MPI-ESM1-2-LR\n",
      "Writing files: var_id: areacella, year: 2006, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: MPI-ESM1-2-LR\n",
      "no files found for cli in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: UKESM1-0-LL\n",
      "no files found for cli in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: HadGEM3-GC31-LL\n",
      "no files found for cli in CNRM-CM6-1\n",
      "no files found for pfull in CNRM-CM6-1\n",
      "no files found for phalf in CNRM-CM6-1\n",
      "Writing files: var_id: areacella, year: 2006, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: CNRM-CM6-1\n",
      "no files found for cli in CNRM-ESM2-1\n",
      "no files found for pfull in CNRM-ESM2-1\n",
      "no files found for phalf in CNRM-ESM2-1\n",
      "Writing files: var_id: areacella, year: 2006, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: CNRM-ESM2-1\n",
      "no files found for cli in IPSL-CM6A-LR\n",
      "no files found for pfull in IPSL-CM6A-LR\n",
      "no files found for phalf in IPSL-CM6A-LR\n",
      "Writing files: var_id: areacella, year: 2006, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: IPSL-CM6A-LR\n",
      "no files found for cli in IPSL-CM5A2-INCA\n",
      "no files found for pfull in IPSL-CM5A2-INCA\n",
      "no files found for phalf in IPSL-CM5A2-INCA\n",
      "Writing files: var_id: areacella, year: 2006, model: IPSL-CM5A2-INCA\n",
      "Writing regrid files: var_id: areacella, year: 2006, model: IPSL-CM5A2-INCA\n",
      "no files found for clivi in MIROC6\n",
      "no files found for pfull in MIROC6\n",
      "no files found for phalf in MIROC6\n",
      "Writing files: var_id: areacella, year: 2007, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: MIROC6\n",
      "no files found for pfull in CanESM5\n",
      "no files found for phalf in CanESM5\n",
      "Writing files: var_id: areacella, year: 2007, model: CanESM5\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: CanESM5\n",
      "no files found for cli in AWI-ESM-1-1-LR\n",
      "no files found for pfull in AWI-ESM-1-1-LR\n",
      "no files found for phalf in AWI-ESM-1-1-LR\n",
      "Writing files: var_id: areacella, year: 2007, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: AWI-ESM-1-1-LR\n",
      "no files found for cli in MPI-ESM1-2-LR\n",
      "no files found for pfull in MPI-ESM1-2-LR\n",
      "no files found for phalf in MPI-ESM1-2-LR\n",
      "Writing files: var_id: areacella, year: 2007, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: MPI-ESM1-2-LR\n",
      "no files found for cli in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: UKESM1-0-LL\n",
      "no files found for cli in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: HadGEM3-GC31-LL\n",
      "no files found for cli in CNRM-CM6-1\n",
      "no files found for pfull in CNRM-CM6-1\n",
      "no files found for phalf in CNRM-CM6-1\n",
      "Writing files: var_id: areacella, year: 2007, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: CNRM-CM6-1\n",
      "no files found for cli in CNRM-ESM2-1\n",
      "no files found for pfull in CNRM-ESM2-1\n",
      "no files found for phalf in CNRM-ESM2-1\n",
      "Writing files: var_id: areacella, year: 2007, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: CNRM-ESM2-1\n",
      "no files found for cli in IPSL-CM6A-LR\n",
      "no files found for pfull in IPSL-CM6A-LR\n",
      "no files found for phalf in IPSL-CM6A-LR\n",
      "Writing files: var_id: areacella, year: 2007, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: IPSL-CM6A-LR\n",
      "no files found for cli in IPSL-CM5A2-INCA\n",
      "no files found for pfull in IPSL-CM5A2-INCA\n",
      "no files found for phalf in IPSL-CM5A2-INCA\n",
      "Writing files: var_id: areacella, year: 2007, model: IPSL-CM5A2-INCA\n",
      "Writing regrid files: var_id: areacella, year: 2007, model: IPSL-CM5A2-INCA\n",
      "no files found for clivi in MIROC6\n",
      "no files found for pfull in MIROC6\n",
      "no files found for phalf in MIROC6\n",
      "Writing files: var_id: areacella, year: 2008, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: MIROC6\n",
      "no files found for pfull in CanESM5\n",
      "no files found for phalf in CanESM5\n",
      "Writing files: var_id: areacella, year: 2008, model: CanESM5\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: CanESM5\n",
      "no files found for cli in AWI-ESM-1-1-LR\n",
      "no files found for pfull in AWI-ESM-1-1-LR\n",
      "no files found for phalf in AWI-ESM-1-1-LR\n",
      "Writing files: var_id: areacella, year: 2008, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: AWI-ESM-1-1-LR\n",
      "no files found for cli in MPI-ESM1-2-LR\n",
      "no files found for pfull in MPI-ESM1-2-LR\n",
      "no files found for phalf in MPI-ESM1-2-LR\n",
      "Writing files: var_id: areacella, year: 2008, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: MPI-ESM1-2-LR\n",
      "no files found for cli in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: UKESM1-0-LL\n",
      "no files found for cli in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: HadGEM3-GC31-LL\n",
      "no files found for cli in CNRM-CM6-1\n",
      "no files found for pfull in CNRM-CM6-1\n",
      "no files found for phalf in CNRM-CM6-1\n",
      "Writing files: var_id: areacella, year: 2008, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: CNRM-CM6-1\n",
      "no files found for cli in CNRM-ESM2-1\n",
      "no files found for pfull in CNRM-ESM2-1\n",
      "no files found for phalf in CNRM-ESM2-1\n",
      "Writing files: var_id: areacella, year: 2008, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: CNRM-ESM2-1\n",
      "no files found for cli in IPSL-CM6A-LR\n",
      "no files found for pfull in IPSL-CM6A-LR\n",
      "no files found for phalf in IPSL-CM6A-LR\n",
      "Writing files: var_id: areacella, year: 2008, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: IPSL-CM6A-LR\n",
      "no files found for cli in IPSL-CM5A2-INCA\n",
      "no files found for pfull in IPSL-CM5A2-INCA\n",
      "no files found for phalf in IPSL-CM5A2-INCA\n",
      "Writing files: var_id: areacella, year: 2008, model: IPSL-CM5A2-INCA\n",
      "Writing regrid files: var_id: areacella, year: 2008, model: IPSL-CM5A2-INCA\n",
      "no files found for clivi in MIROC6\n",
      "no files found for pfull in MIROC6\n",
      "no files found for phalf in MIROC6\n",
      "Writing files: var_id: areacella, year: 2009, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: MIROC6\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: MIROC6\n",
      "no files found for pfull in CanESM5\n",
      "no files found for phalf in CanESM5\n",
      "Writing files: var_id: areacella, year: 2009, model: CanESM5\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: CanESM5\n",
      "no files found for cli in AWI-ESM-1-1-LR\n",
      "no files found for pfull in AWI-ESM-1-1-LR\n",
      "no files found for phalf in AWI-ESM-1-1-LR\n",
      "Writing files: var_id: areacella, year: 2009, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: AWI-ESM-1-1-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: AWI-ESM-1-1-LR\n",
      "no files found for cli in MPI-ESM1-2-LR\n",
      "no files found for pfull in MPI-ESM1-2-LR\n",
      "no files found for phalf in MPI-ESM1-2-LR\n",
      "Writing files: var_id: areacella, year: 2009, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: MPI-ESM1-2-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: MPI-ESM1-2-LR\n",
      "no files found for cli in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "areacella does not exist in UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: UKESM1-0-LL\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: UKESM1-0-LL\n",
      "no files found for cli in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "areacella does not exist in HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: HadGEM3-GC31-LL\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: HadGEM3-GC31-LL\n",
      "no files found for cli in CNRM-CM6-1\n",
      "no files found for pfull in CNRM-CM6-1\n",
      "no files found for phalf in CNRM-CM6-1\n",
      "Writing files: var_id: areacella, year: 2009, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: CNRM-CM6-1\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: CNRM-CM6-1\n",
      "no files found for cli in CNRM-ESM2-1\n",
      "no files found for pfull in CNRM-ESM2-1\n",
      "no files found for phalf in CNRM-ESM2-1\n",
      "Writing files: var_id: areacella, year: 2009, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: CNRM-ESM2-1\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: CNRM-ESM2-1\n",
      "no files found for cli in IPSL-CM6A-LR\n",
      "no files found for pfull in IPSL-CM6A-LR\n",
      "no files found for phalf in IPSL-CM6A-LR\n",
      "Writing files: var_id: areacella, year: 2009, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: IPSL-CM6A-LR\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: IPSL-CM6A-LR\n",
      "no files found for cli in IPSL-CM5A2-INCA\n",
      "no files found for pfull in IPSL-CM5A2-INCA\n",
      "no files found for phalf in IPSL-CM5A2-INCA\n",
      "Writing files: var_id: areacella, year: 2009, model: IPSL-CM5A2-INCA\n",
      "Writing regrid files: var_id: areacella, year: 2009, model: IPSL-CM5A2-INCA\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "for year in [2006, 2007, 2008, 2009]:\n",
    "    # This will run the process_year function for each year in parallel, using all available cores (n_jobs=-1).\n",
    "    # Parallel(n_jobs=-1)(delayed(process_year)(year, list_models, t_res, experiment_id,variable_id))# for year in [2006, 2007, 2008, 2009])\n",
    "    process_year(year, list_models,cmip_in, t_res, experiment_id,variable_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b20d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2006, 2007, 2008, 2009]:\n",
    "#     for model in list_models:\n",
    "#         for var_id in ['clivi', 'lwp', 'pr', 'prsn', 'tas', 'areacella']:\n",
    "#             for grid_model in ['IPSL-CM6A-LR', 'IPSL-CM5A2-INCA']:\n",
    "#                 file_list = sorted(glob(f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_40_90*_{year}0101-{year+1}1231.nc'))\n",
    "#                 if len(file_list) > 0:\n",
    "#                     old_name = file_list[0]\n",
    "#                     variant_label = old_name.split('_')[-2]\n",
    "#                     print(old_name)\n",
    "#                     new_name = f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_40_90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "#                     print(new_name)\n",
    "#                     os.rename(old_name, new_name)\n",
    "                    \n",
    "#                 file_list = sorted(glob(f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_-40_-90*_{year}0101-{year+1}1231.nc'))\n",
    "#                 if len(file_list) > 0:\n",
    "#                     old_name = file_list[0]\n",
    "#                     variant_label = old_name.split('_')[-2]\n",
    "#                     # print(old_name)\n",
    "#                     new_name = f'{cmip_in}/common_grid/{model}/{var_id}_{grid_model}_{model}_-40_-90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "#                     # print(new_name)\n",
    "#                     os.rename(old_name, new_name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2475052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2006, 2007, 2008, 2009]:\n",
    "#     for model in list_models:\n",
    "#         for var_id in ['clivi', 'lwp', 'pr', 'prsn', 'tas', 'areacella']:\n",
    "#             file_list = sorted(glob(f'{cmip_in}/single_model/{model}/{var_id}_{model}_40_90*_{year}0101-{year+1}1231.nc'))\n",
    "#             if len(file_list) > 0:\n",
    "#                 old_name = file_list[0]\n",
    "#                 print(old_name)\n",
    "#                 variant_label = old_name.split('_')[-2]\n",
    "#                 new_name = f'{cmip_in}/single_model/{model}/{var_id}_{model}_40_90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "#                 print(new_name)\n",
    "#                 os.rename(old_name, new_name)\n",
    "            \n",
    "#             file_list = sorted(glob(f'{cmip_in}/single_model/{model}/{var_id}_{model}_-40_-90*_{year}0101-{year+1}1231.nc'))\n",
    "#             if len(file_list) > 0:\n",
    "#                 old_name = file_list[0]\n",
    "#                 print(old_name)\n",
    "#                 variant_label = old_name.split('_')[-2]\n",
    "#                 new_name = f'{cmip_in}/single_model/{model}/{var_id}_{model}_-40_-90_{experiment_id[0]}_{variant_label}_{year}0101-{year}1231.nc'\n",
    "#                 print(new_name)\n",
    "#                 os.rename(old_name, new_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e15a6d5",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9188a63c",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1zb0LHvipx8JOXLLrCxzYToJM7eNK4eaw\"  height=\"100\" />\n",
    "<img src=\"https://reliance.rohub.org/static/media/Reliance-logo.433dc2e9.png\"  height=\"100\" />\n",
    "\n",
    "<img src=\"https://www.uio.no/vrtx/decorating/resources/dist/src2/images/footer/uio-logo-en.svg\"  height=\"100\" />\n",
    "<img src=\"https://erc.europa.eu/sites/default/files/logo_0.png\"  height=\"100\" />\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ecfbcf9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('globalsnow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
