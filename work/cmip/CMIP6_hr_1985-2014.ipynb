{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709c8e52",
   "metadata": {},
   "source": [
    "# Example with high-resolution CMIP6 models (~100 km) using Pangeo catalog \n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f77edda",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>\n",
    "Cloud feedbacks are a major contributor to the spread of climate sensitivity in global climate models (GCMs) [Zelinka et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019GL085782). Among the most poorly understood cloud feedbacks is the one associated with the cloud phase, which is expected to be modified with climate change [Bjordal et al. (2020)](https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1). Cloud phase bias, in addition, has significant implications for the simulation of radiative properties and glacier and ice sheet mass balances in climate models. \n",
    "\n",
    "In this context, this work aims to expand our knowledge on how the representation of the cloud phase affects snow formation in GCMs. Better understanding this aspect is necessary to develop climate models further and improve future climate predictions. \n",
    "\n",
    "* Retrieve CMIP6 data through [Pangeo](https://pangeo-data.github.io/pangeo-cmip6-cloud/)\n",
    "* Hybrid sigma-pressure coordinates to isobaric pressure levels of the European Centre for Medium-Range Weather Forecast Re-Analysis 5 (ERA5) with [GeoCAT-comb](https://geocat-comp.readthedocs.io/en/latest/index.html)\n",
    "* Regridd the CMIP6 variables to the exact horizontal resolution with [`xesmf`](https://xesmf.readthedocs.io/en/latest/)\n",
    "* Calculate an ensemble mean of all used models\n",
    "* Calculate and plot the seasonal mean of the ensemble mean\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall varying between 1985 and 2014?\n",
    "\n",
    "> **_NOTE:_** We answer questions related to the comparison of CMIP models to ERA5 in another [Jupyter Notebook](../CMIP6_ERA5_CloudSat/plt_seasonal_mean.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f939501",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "This study will compare surface snowfall, ice, and liquid water content from the Coupled Model Intercomparison Project Phase 6 ([CMIP6](https://esgf-node.llnl.gov/projects/cmip6/)) climate models (accessed through [Pangeo](https://pangeo.io/)) to the European Centre for Medium-Range Weather Forecast Re-Analysis 5 ([ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)) data from **1985 to 2014**. We conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models and their potential connection between them. \n",
    "\n",
    "- Time period: 1985 to 2014\n",
    "- horizonal resolution: ~100km\n",
    "- time resolution: monthly atmospheric data (Amon, AERmon)\n",
    "- Variables:\n",
    "  \n",
    "| shortname     |             Long name                   |      Units    |  levels |\n",
    "| ------------- |:---------------------------------------:| -------------:|--------:|\n",
    "|  prsn         |    Snowfall Flux                        | [kg m-2 s-1]  | surface |\n",
    "| clw           |    Mass Fraction of Cloud Liquid Water  |  [kg kg-1]    |    ml   |\n",
    "| cli           |    Mass Fraction of Cloud Ice           | [kg kg-1]     |    ml   |\n",
    "| tas           |    Near-Surface Air Temperature         |   [K]         | surface |\n",
    "| ta            |    Air Temperature                      |  [K]          |    ml   |\n",
    "| clivi         |    Ice Water Path                       | [kg m-2]      |         |\n",
    "| lwp           |    Liquid Water Path                    | [kg m-2]      |         |\n",
    "| pr            |    Precipitation                        | [kg m-2 s-1]  | surface |\n",
    "\n",
    "- CMIP6 models:\n",
    "\n",
    "| Institution                                            |     Model name    | Reference                                                     |\n",
    "| ------------------------------------------------------ |:-----------------:|--------------------------------------------------------------:|\n",
    "| [AS-RCEC](https://www.rcec.sinica.edu.tw/index_en.php) | TaiESM1           | [Lee et al. (2020)](https://doi.org/10.5194/gmd-13-3887-2020) |\n",
    "| [BCC](http://bcc.ncc-cma.net/)                         | BCC-CSM2-M        | [Wu et al. (2019)](https://doi.org/10.5194/gmd-12-1573-2019)  |\n",
    "| [CAMS](http://www.cma.gov.cn/en2014/)                  | CAMS-CSM1-0       |                                                               |\n",
    "| [CAS](http://english.iap.cas.cn/)                      | FGOALS-f3-L       | [Bian et al. (2020)](https://doi-org.ezproxy.uio.no/10.1080/16742834.2020.1778419) |\n",
    "| [CMCC](https://www.cmcc.it/)                           | CMCC-CM2-SR5      | [Cherchi et al. (2019)](https://doi-org.ezproxy.uio.no/10.1029/2018MS001369)|\n",
    "|                                                        | CMCC-CM2-HR4      | [Cherchi et al. (2019)](https://doi-org.ezproxy.uio.no/10.1029/2018MS001369)|\n",
    "|                                                        | CMCC-ESM2         | [CMCC website](https://www.cmcc.it/models/cmcc-esm-earth-system-model)    |\n",
    "| [EC-Earth-Consortium](http://www.ec-earth.org/)        | EC-Earth3-AerChem | [van Noije et al. (2021)](https://doi.org/10.5194/gmd-14-5637-2021)  |\n",
    "| [E3SM-Project](https://e3sm.org/)                      | E3SM-1-1          | [Golaz et al. (2019)](https://doi-org.ezproxy.uio.no/10.1029/2018MS001603); [Burrows et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019MS001766) Text S8|\n",
    "|                                                        | E3SM-1-1-ECA      | |\n",
    "| [MPI-M](https://mpimet.mpg.de/en/homepage)             | MPI-ESM1-2-HR     | [Müller et al. (2018)](https://doi-org.ezproxy.uio.no/10.1029/2017MS001217)|\n",
    "| [MRI](https://www.mri-jma.go.jp/index_en.html)         | MRI-ESM2-0        | [Yukimoto et al. (2019)](https://doi.org/10.2151/jmsj.2019-051) |\n",
    "| [NCC](https://folk.uib.no/ngfhd/EarthClim/index.htm)   | NorESM2-MM        | [Seland et al. (2020)](https://doi.org/10.5194/gmd-13-6165-2020)|\n",
    "| [NOAA-GFDL](https://www.gfdl.noaa.gov/)                | GFDL-CM4          | [Held et al. (2019)](https://doi-org.ezproxy.uio.no/10.1029/2019MS001829) |\n",
    "|                                                        | GFDL-ESM4         | [Dunne et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019MS002015) |\n",
    "| [SNU](https://en.snu.ac.kr/index.html)                 | SAM0-UNICON       | [Park et al. (2019)](https://doi-org.ezproxy.uio.no/10.1175/JCLI-D-18-0796.1) |\n",
    "| [THU](https://www.tsinghua.edu.cn/en/)                 | CIESM             | [Lin et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019MS002036) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c652dc0b",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [globalsnow.yml](../globalsnow.yml) \n",
    "- load `python` packages from [imports.py](../utils/imports.py)\n",
    "- load `functions` from [functions.py](../utils/functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4caa42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "import sys\n",
    "sys.path.append('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils')\n",
    "from imports import (xr, intake, cftime, xe, glob, np, cm, pd, fct,ccrs, cy, plt, da, gc)\n",
    "\n",
    "xr.set_options(display_style=\"html\")\n",
    "\n",
    "\n",
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900635d",
   "metadata": {},
   "source": [
    "## Open CMIP6 online catalog\n",
    "... by using `intake` from [pangeo.io](https://gallery.pangeo.io/repos/pangeo-data/pangeo-tutorial-gallery/intake.html), specifically `intake-esm`.\n",
    "\n",
    "An example on [Loading an ESM collection](https://pangeo-data.github.io/pangeo-cmip6-cloud/accessing_data.html#loading-an-esm-collection) and [searching for datasets](https://pangeo-data.github.io/pangeo-cmip6-cloud/accessing_data.html#searching-for-datasets) can also be found on the [Pangeo / ESGF Cloud Data Working Group documentation](https://pangeo-data.github.io/pangeo-cmip6-cloud/accessing_data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69b9422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>pangeo-cmip6 catalog with 7782 dataset(s) from 523774 asset(s)</strong>:</p> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>activity_id</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution_id</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_id</th>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table_id</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable_id</th>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grid_label</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zstore</th>\n",
       "      <td>523774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>version</th>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\"\n",
    "col = intake.open_esm_datastore(cat_url)\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320dc599",
   "metadata": {},
   "source": [
    "## Search corresponding data\n",
    "Get the data required for the analysis. Define variables, models, experiment, and time resolution as defined in <a href=\"#data_wrangling\">2. Data Wrangling</a>\n",
    ". \n",
    "\n",
    "* use member_id = 'r1i1p1f1'.\n",
    "* using intake-esm’s `search()` function:\n",
    "  * `col.search(variable_id, source_id, experiment_id, table_id, member_id, institution_id, grid_label)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15a84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "variable_id=[\n",
    "            'cli',\n",
    "            # 'clivi',\n",
    "            'clw',\n",
    "            # 'lwp',\n",
    "            'pr',\n",
    "            'prsn',\n",
    "            'ta', \n",
    "            # 'tas'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b7a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models\n",
    "list_models = [\n",
    "    'NorESM2-MM',\n",
    "    'TaiESM1',\n",
    "    'EC-Earth3-AerChem',\n",
    "    'GFDL-ESM4',\n",
    "    'SAM0-UNICON',\n",
    "    'CAMS-CSM1-0',\n",
    "    'CMCC-CM2-HR4',\n",
    "    'MPI-ESM1-2-HR',\n",
    "    'BCC-CSM2-MR',\n",
    "    'E3SM-1-1',\n",
    "    'CMCC-CM2-SR5',\n",
    "    'CMCC-ESM2',\n",
    "    'FGOALS-f3-L',\n",
    "    'E3SM-1-1-ECA',\n",
    "    'CIESM',\n",
    "    'GFDL-CM4',\n",
    "    'MRI-ESM2-0']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b62978",
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment\n",
    "experiment_id = ['historical']\n",
    "\n",
    "## time resolution\n",
    "t_res = ['Amon', 'AERmon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "540777e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GFDL-CM4', 'BCC-CSM2-MR', 'MRI-ESM2-0', 'SAM0-UNICON',\n",
       "       'CAMS-CSM1-0', 'MPI-ESM1-2-HR', 'GFDL-ESM4', 'FGOALS-f3-L',\n",
       "       'NorESM2-MM', 'E3SM-1-1', 'E3SM-1-1-ECA', 'CIESM', 'CMCC-CM2-SR5',\n",
       "       'TaiESM1', 'EC-Earth3-AerChem', 'CMCC-CM2-HR4', 'CMCC-ESM2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## search for variables, models, ...\n",
    "cat = col.search(variable_id=variable_id, source_id=list_models, experiment_id=experiment_id, table_id = t_res, member_id=['r1i1p1f1'])\n",
    "# cat.df\n",
    "## show the CMIP6 models found in pandas Dataframe \n",
    "cat.df['source_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c4b0a",
   "metadata": {},
   "source": [
    "## Create dictionary from the list of datasets we found\n",
    "Load the found datasets into xarray dataset containers using intake-esm’s `to_dataset_dict()` function, which yields a Python dictionary.\n",
    "\n",
    "> **_NOTE:_** This step may take several minutes so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550968bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [17/17 01:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset_dict = cat.to_dataset_dict(zarr_kwargs={'use_cftime':True,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febae699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMIP.NOAA-GFDL.GFDL-ESM4.historical.Amon.gr1: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.THU.CIESM.historical.Amon.gr: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.NCC.NorESM2-MM.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.CAMS.CAMS-CSM1-0.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.NOAA-GFDL.GFDL-CM4.historical.Amon.gr1: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.MPI-M.MPI-ESM1-2-HR.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.CMCC.CMCC-ESM2.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.CMCC.CMCC-CM2-HR4.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.SNU.SAM0-UNICON.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.MRI.MRI-ESM2-0.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.CMCC.CMCC-CM2-SR5.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.CAS.FGOALS-f3-L.historical.Amon.gr: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.AS-RCEC.TaiESM1.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.BCC.BCC-CSM2-MR.historical.Amon.gn: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.E3SM-Project.E3SM-1-1-ECA.historical.Amon.gr: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.E3SM-Project.E3SM-1-1.historical.Amon.gr: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n",
      "CMIP.EC-Earth-Consortium.EC-Earth3-AerChem.historical.Amon.gr: ['lev', 'bnds', 'member_id', 'time', 'lat', 'lon', 'plev']\n"
     ]
    }
   ],
   "source": [
    "# list all merged datasets and show coordinates\n",
    "for keys, ds in dset_dict.items():\n",
    "    print('{}: {}'.format(keys, list(ds.dims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cced3",
   "metadata": {},
   "source": [
    "## Calendar\n",
    "Not all models in CMIP6 use the same calendar. Hence we double check the time axis. Later, when we regrid to the same horizontal resolution (<a href=\"#regrid_hz\">Regrid CMIP6 data</a>) we will assign the same calendars for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e425fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>calendar</th>\n",
       "      <th>branch_time_in_parent</th>\n",
       "      <th>parent_time_units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GFDL-ESM4</th>\n",
       "      <td>noleap</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>days since 0001-1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIESM</th>\n",
       "      <td>noleap</td>\n",
       "      <td>182500.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <td>noleap</td>\n",
       "      <td>438000.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAMS-CSM1-0</th>\n",
       "      <td>noleap</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-CM4</th>\n",
       "      <td>noleap</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>days since 0001-1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <td>proleptic_gregorian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-1-1 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <td>noleap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-CM2-HR4</th>\n",
       "      <td>noleap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAM0-UNICON</th>\n",
       "      <td>noleap</td>\n",
       "      <td>99645.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <td>proleptic_gregorian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <td>noleap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGOALS-f3-L</th>\n",
       "      <td>noleap</td>\n",
       "      <td>12345.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TaiESM1</th>\n",
       "      <td>noleap</td>\n",
       "      <td>171550.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <td>noleap</td>\n",
       "      <td>2289.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1-ECA</th>\n",
       "      <td>noleap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1</th>\n",
       "      <td>noleap</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 0001-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC-Earth3-AerChem</th>\n",
       "      <td>proleptic_gregorian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>days since 1850-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "index                         calendar branch_time_in_parent  \\\n",
       "parent_source_id                                               \n",
       "GFDL-ESM4                       noleap               36500.0   \n",
       "CIESM                           noleap              182500.0   \n",
       "NorESM2-MM                      noleap              438000.0   \n",
       "CAMS-CSM1-0                     noleap                3025.0   \n",
       "GFDL-CM4                        noleap               36500.0   \n",
       "MPI-ESM1-2-HR      proleptic_gregorian                   0.0   \n",
       "CMCC-ESM2                       noleap                   0.0   \n",
       "CMCC-CM2-HR4                    noleap                   0.0   \n",
       "SAM0-UNICON                     noleap               99645.0   \n",
       "MRI-ESM2-0         proleptic_gregorian                   0.0   \n",
       "CMCC-CM2-SR5                    noleap                   0.0   \n",
       "FGOALS-f3-L                     noleap               12345.0   \n",
       "TaiESM1                         noleap              171550.0   \n",
       "BCC-CSM2-MR                     noleap                2289.0   \n",
       "E3SM-1-1-ECA                    noleap                   0.0   \n",
       "E3SM-1-1                        noleap                   0.0   \n",
       "EC-Earth3-AerChem  proleptic_gregorian                   0.0   \n",
       "\n",
       "index                         parent_time_units  \n",
       "parent_source_id                                 \n",
       "GFDL-ESM4                   days since 0001-1-1  \n",
       "CIESM                     days since 0001-01-01  \n",
       "NorESM2-MM                days since 0001-01-01  \n",
       "CAMS-CSM1-0               days since 1850-01-01  \n",
       "GFDL-CM4                    days since 0001-1-1  \n",
       "MPI-ESM1-2-HR      days since 1850-1-1 00:00:00  \n",
       "CMCC-ESM2                 days since 1850-01-01  \n",
       "CMCC-CM2-HR4              days since 1850-01-01  \n",
       "SAM0-UNICON               days since 0001-01-01  \n",
       "MRI-ESM2-0                days since 1850-01-01  \n",
       "CMCC-CM2-SR5              days since 1850-01-01  \n",
       "FGOALS-f3-L               days since 0001-01-01  \n",
       "TaiESM1                   days since 1850-01-01  \n",
       "BCC-CSM2-MR               days since 1850-01-01  \n",
       "E3SM-1-1-ECA              days since 0001-01-01  \n",
       "E3SM-1-1                  days since 0001-01-01  \n",
       "EC-Earth3-AerChem         days since 1850-01-01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata of the historical run:\n",
    "_d2 = pd.Series([\"calendar\",\n",
    "                 \"branch_time_in_parent\", #\"parent_activity_id\", \"parent_experiment_id\",\t\"parent_mip_era\",\n",
    "                 \"parent_source_id\",#\"parent_sub_experiment_id\", \n",
    "                 \"parent_time_units\",# \"parent_variant_label\"\n",
    "                  ])\n",
    "_d2 = pd.DataFrame(_d2).rename(columns={0:'index'})\n",
    "for i in dset_dict.keys():\n",
    "    _data = []\n",
    "    _names =[]\n",
    "    _data.append(dset_dict[i].time.to_index().calendar)\n",
    "    for k, v in dset_dict[i].attrs.items():\n",
    "        \n",
    "        if 'parent_time_units' in k or 'branch_time_in_parent' in k or 'parent_source_id' in k:\n",
    "            _data.append(v)\n",
    "            _names.append(k)\n",
    "    _d2 = pd.concat([_d2,   pd.Series(_data)], axis=1)\n",
    "\n",
    "_d2.dropna(how='all', axis=1, inplace=True)\n",
    "_d2 = _d2.set_index('index')\n",
    "_d2.columns = _d2.loc['parent_source_id']\n",
    "_d2.drop('parent_source_id').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde1726",
   "metadata": {},
   "source": [
    "## Show attributes and individual identifier\n",
    "NorESM2-MM is going to be the reference model for the horizontal grid. The `xarray` datasets inside `dset_dict` can be extracted as any value in a Python dictionary.\n",
    "\n",
    "The dictonary key for NorESM2-MM is: **CMIP.NCC.NorESM2-MM.historical.Amon.gn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e045126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cell_measures': 'area: areacella',\n",
       "  'cell_methods': 'area: time: mean',\n",
       "  'comment': 'Includes both large-scale and convective cloud. This is calculated as the mass of cloud ice in the grid cell divided by the mass of air (including the water in all phases) in the grid cell. It includes precipitating hydrometeors ONLY if the precipitating hydrometeors affect the calculation of radiative transfer in model.',\n",
       "  'history': \"2019-11-25T21:51:40Z altered by CMOR: Converted units from '1' to 'kg kg-1'. 2019-11-25T21:51:41Z altered by CMOR: Converted type from 'd' to 'f'. 2019-11-25T21:51:41Z altered by CMOR: Inverted axis: lev.\",\n",
       "  'long_name': 'Mass Fraction of Cloud Ice',\n",
       "  'original_name': 'CLDICE',\n",
       "  'original_units': '1',\n",
       "  'standard_name': 'mass_fraction_of_cloud_ice_in_air',\n",
       "  'units': 'kg kg-1'},\n",
       " 'hdl:21.14100/bdfd7dd4-b7a4-4c0e-b79c-28a1dfcf57dd\\nhdl:21.14100/ee267138-b752-4170-b1b5-216449dd1268\\nhdl:21.14100/313c20af-b8bd-437f-ba76-e341512e01cb\\nhdl:21.14100/a6d7cb7a-0775-4ed4-8ec1-ba3e504ff8bc\\nhdl:21.14100/cf13a474-dd65-4ac9-85d8-a4e91453c2a5\\nhdl:21.14100/d1e77260-e1b3-4f69-8a55-7b7b08268f92\\nhdl:21.14100/7d2f9ff6-5dba-486b-b26c-83449441be37\\nhdl:21.14100/4bd7e622-d889-4148-8fd2-c51503df6210\\nhdl:21.14100/ec908d5b-4bfd-456f-ab91-d7ca825b71e6\\nhdl:21.14100/39275014-6e35-4859-b2d1-cbfd2fefeaab\\nhdl:21.14100/02eb7701-6c97-4349-acf6-85a6e5b2e4b3\\nhdl:21.14100/24665b73-7508-4647-93c0-be93d452554b\\nhdl:21.14100/74b3476f-b4db-4006-9577-dac4c0fc4ba0\\nhdl:21.14100/c3fab37d-21d7-470c-9f4d-f480bdffc64d\\nhdl:21.14100/6946c90a-b26b-4d75-969a-e7659c2877b8\\nhdl:21.14100/20dc7a63-02bc-4d1e-a2ac-9f23b707a2ec\\nhdl:21.14100/3d7be3a4-c1e2-4657-9d09-68349f58159d\\nhdl:21.14100/1c8e58a1-c250-4120-9fb6-159885cd5a96\\nhdl:21.14100/c1340042-4644-4d38-9270-d000d8d14b19\\nhdl:21.14100/c7f9967e-a7a9-44ae-bbb5-4b5a02c5a7b3\\nhdl:21.14100/34449e11-fad2-4fea-82c8-19e194f8d7f5\\nhdl:21.14100/fd79dd4c-b2aa-4290-83a2-07dce463a1c0\\nhdl:21.14100/b548a684-f49f-4dac-b1a9-acc24a8ff750\\nhdl:21.14100/66f04c76-793d-4a11-bed4-040d3b0b7de5\\nhdl:21.14100/8e53004f-a51b-4fcb-b4db-cafd3cb33de3\\nhdl:21.14100/c0b36dc0-7408-462a-a3da-849bda149260\\nhdl:21.14100/5410d0a1-9def-42b7-91a0-d959a6650d4a\\nhdl:21.14100/23e3e9fd-2131-4952-b5eb-36f058178ab2\\nhdl:21.14100/e2948317-3a1d-4627-822c-03ed8097c2ed\\nhdl:21.14100/be8f947a-bf1e-4a2f-9320-e33d65ef2b6c\\nhdl:21.14100/8c2c2821-597e-45f9-8990-ba520145b33c\\nhdl:21.14100/1c1b0353-cd70-47e6-8c17-676783f1a93b\\nhdl:21.14100/214acf85-5eb2-4924-b063-adc28c657692\\nhdl:21.14100/11406d14-0f70-44f6-ae0d-6c246f1305e3\\nhdl:21.14100/240f3d7a-faa9-4e7a-aeab-7a842635dcc3\\nhdl:21.14100/554fb9db-fdc0-425c-ac68-146cba77f8cb\\nhdl:21.14100/7235eb45-2da1-4bb8-bd16-467256066116\\nhdl:21.14100/f2188a57-eff0-4ab9-8263-a6654349ee18\\nhdl:21.14100/3fdefb99-9db8-44c1-9a51-885f6db62cfa\\nhdl:21.14100/f50ff646-df59-4eac-8080-e5da16e5d778\\nhdl:21.14100/2fde10fe-1e37-4a93-ac9c-a34b8de5a606\\nhdl:21.14100/25d85a61-ac30-49cd-985b-66d121e4d388\\nhdl:21.14100/a83c191a-d59b-4079-87f3-8caa874fce06\\nhdl:21.14100/23263a30-65b9-4887-b46c-253af00861e6\\nhdl:21.14100/cbea6d5b-68dd-4db8-9500-8e2d1bcf11be\\nhdl:21.14100/457e8153-b9e8-4e0a-a339-4b0f37c2992d\\nhdl:21.14100/28e89d10-aa46-4629-9f96-07eb18d42bcc\\nhdl:21.14100/4fe3cdb8-8434-497d-88b3-9eff0eab6264\\nhdl:21.14100/4b34d44c-c673-419e-b5bb-cd01c5f382d6\\nhdl:21.14100/20b0215a-3e8e-474b-9513-a80f45805ad2\\nhdl:21.14100/e484b416-c59c-4ac2-bd9a-9ba2a3047d6a\\nhdl:21.14100/befe4a85-4c28-4df7-9efe-0232a75ad2bc\\nhdl:21.14100/9be130fb-934e-429b-84f1-77bee253059b\\nhdl:21.14100/45a7fb91-c21b-42aa-8b7b-ca4fccee3d82\\nhdl:21.14100/550cfa82-7d5f-484d-bcd8-375b6bf9cd28\\nhdl:21.14100/809d1eee-9b32-4314-9c47-570edddcde9d\\nhdl:21.14100/b5a65d62-f8fc-4b13-8a36-8a6a0fc8f64c\\nhdl:21.14100/f1ba6e0d-af4f-419d-a762-d4ca5b3e0fd8\\nhdl:21.14100/2492e2d8-23ed-4ddf-9a89-2e48df0d5933\\nhdl:21.14100/1bda4adf-11a3-4b39-9a30-808ac443c79e\\nhdl:21.14100/f2889793-851e-4ccd-b303-4d03e27ba56b\\nhdl:21.14100/49e57aae-a8c0-426d-abd9-ffe68548a7b4\\nhdl:21.14100/d2082e93-5bbe-4737-801f-c5d289f2c656\\nhdl:21.14100/058f0e3d-126b-402c-8c57-26d915d617c6\\nhdl:21.14100/d6659ea1-7c7d-49cb-b399-08d5541b6423\\nhdl:21.14100/eda3b060-ad9f-4ea8-834c-850d811cd41d\\nhdl:21.14100/d5c82405-0ebc-42bb-82ac-2202181bbd35\\nhdl:21.14100/a408357d-ef9b-40a8-9b59-89c3a5d4958e\\nhdl:21.14100/164a18b5-95a5-498f-89ad-f3cfa8dbb9ae')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if variable_id[0] == 'lwp':\n",
    "    ds = dset_dict['CMIP.NCC.NorESM2-MM.historical.AERmon.gn']\n",
    "else:\n",
    "    ds = dset_dict['CMIP.NCC.NorESM2-MM.historical.Amon.gn']\n",
    "    \n",
    "\n",
    "## attributes of the xarray dataset \n",
    "ds[variable_id[0]].attrs, ds.attrs['tracking_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a37c88",
   "metadata": {},
   "source": [
    "## Assign attributes to the variables\n",
    "\n",
    "We will assign the attributes to the variables as in ERA5 to make CMIP6 and ERA5 variables comperable.\n",
    "\n",
    "* [`cli`](http://clipc-services.ceda.ac.uk/dreq/u/dd916e3e2eca18cda5d9f81749d0c91c.html) and [`clw`](http://clipc-services.ceda.ac.uk/dreq/u/86b2b3318a73839edfafa9d46864aadc.html) in **kg kg-1** $\\rightarrow$ Multiply by **1000** to get **g kg-1**\n",
    "* [`clivi`](http://clipc-services.ceda.ac.uk/dreq/u/73c496f5669cc122cf1cddfe4df2a27a.html) and [`lwp`](http://clipc-services.ceda.ac.uk/dreq/u/e6b31a1928879fcd3c92fe7b592f070e.html) in **kg m-2** $\\rightarrow$ Multiply by **1000** to get **g m-2**\n",
    "* [`pr`](http://clipc-services.ceda.ac.uk/dreq/u/62f26742cf240c1b5169a5cd511196b6.html) and [`prsn`](http://clipc-services.ceda.ac.uk/dreq/u/051919eddec810e292c883205c944ceb.html) in **kg m-2 s-1** $\\rightarrow$ Multiply by **86400** to get **mm day-1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670a98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_id in variable_id:\n",
    "    for keys in dset_dict.keys():\n",
    "        if var_id == 'cli' or var_id == 'clw' or var_id  == 'clivi' or var_id == 'lwp':\n",
    "            dset_dict[keys][var_id] = dset_dict[keys][var_id]*1000\n",
    "            if var_id == 'cli':\n",
    "                dset_dict[keys][var_id].attrs = {'units': 'g kg-1', 'long_name': 'Mass Fraction of Cloud Ice', 'standard_name': 'mass_fraction_of_cloud_ice_in_air', 'comment': 'Includes both large-scale and convective cloud. This is calculated as the mass of cloud ice in the grid cell divided by the mass of air (including the water in all phases) in the grid cell. It includes precipitating hydrometeors ONLY if the precipitating hydrometeors affect the calculation of radiative transfer in model.', 'cell_methods': 'area: time: mean (interval: 5 minutes)', 'cell_measures': 'area: areacella',}\n",
    "            if var_id == 'clw':\n",
    "                dset_dict[keys][var_id].attrs = {'units': 'g kg-1', 'long_name': 'Mass Fraction of Cloud Liquid Water', 'standard_name': 'mass_fraction_of_cloud_liquid_water_in_air', 'comment': 'Includes both large-scale and convective cloud. Calculate as the mass of cloud liquid water in the grid cell divided by the mass of air (including the water in all phases) in the grid cells. Precipitating hydrometeors are included ONLY if the precipitating hydrometeors affect the calculation of radiative transfer in model.', 'cell_methods': 'area: time: mean', 'cell_measures': 'area: areacella'}\n",
    "            if var_id == 'clivi':\n",
    "                dset_dict[keys][var_id].attrs = {'units': 'g m-2', 'long_name': 'Ice Water Path', 'comment': 'mass of ice water in the column divided by the area of the column (not just the area of the cloudy portion of the column). Includes precipitating frozen hydrometeors ONLY if the precipitating hydrometeor affects the calculation of radiative transfer in model.', 'cell_methods': 'area: time: mean', 'cell_measures': 'area: areacella'} \n",
    "            if var_id == 'lwp':\n",
    "                dset_dict[keys][var_id].attrs = {'units': 'g m-2', 'long_name': 'Liquid Water Path', 'comment': 'The total mass of liquid water in cloud per unit area.', 'cell_methods': 'area: time: mean', 'cell_measures': 'area: areacella'}\n",
    "\n",
    "        if var_id == 'pr' or var_id == 'prsn':\n",
    "            try: \n",
    "                dset_dict[keys][var_id] = dset_dict[keys][var_id]*86400\n",
    "                if var_id == 'pr':\n",
    "                    dset_dict[keys][var_id].attrs = {'units': 'mm day-1', 'long_name': 'Precipitation', 'comment': 'includes both liquid and solid phases','cell_methods': 'area: time: mean', 'cell_measures': 'area: areacella'}\n",
    "                if var_id == 'prsn':\n",
    "                    dset_dict[keys][var_id].attrs = {'units': 'mm day-1', 'long_name': 'Snowfall', 'comment': 'At surface; includes precipitation of all forms of water in the solid phase', 'cell_methods': 'area: time: mean', 'cell_measures': 'area: areacella'}\n",
    "            except KeyError:\n",
    "                continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d8d63",
   "metadata": {},
   "source": [
    " ## Interpolate from CMIP6 hybrid sigma-pressure levels to ERA5 isobaric pressure levels\n",
    "\n",
    "The vertical variables in the CMIP6 models are in hybrid sigma-pressure levels. Hence the vertical variable in the xarray datasets in `dset_dict` will be calculated by using the [GeoCAT-comb](https://geocat-comp.readthedocs.io/en/latest/index.html#) function to [interpolate data from hybrid-sigma levels to isobaric levels](https://geocat-comp.readthedocs.io/en/latest/user_api/generated/geocat.comp.interpolation.interp_hybrid_to_pressure.html#geocat.comp.interpolation.interp_hybrid_to_pressure).\n",
    "\n",
    "The GeoCAT-comb function takes the following input:\n",
    "* `data`:   Multidimensional data array, which holds hybrid-sigma levels and has a lev_dim coordinate.\n",
    "* `ps`:     A multi-dimensional array of surface pressures (Pa), same time/space shape as data. Not all variables include the surface pressure, hence we will search the `Pangeo.io` catalog to find the surface pressure associated with the model. \n",
    "* `hyam`:     One-dimensional arrays containing the hybrid A coefficients. Must have the same dimension size as the lev_dim dimension of data.\n",
    "* `hybm`:     One-dimensional arrays containing the hybrid B coefficients. Must have the same dimension size as the lev_dim dimension of data.\n",
    "* `p0`:       Scalar numeric value equal to surface reference pressure (Pa). Defaults to 100000 Pa.\n",
    "* `new_levels`: A one-dimensional array of output pressure levels (Pa). We will use the ERA5 37 pressure levels.\n",
    "\n",
    "\n",
    "$$ P(i,j,k) = hyam(k) p0 + hybm(k) ps(i,j)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0fbe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the levels from the ERA5 file and transfer to Pa\n",
    "era_level = (xr.open_dataset('/scratch/franzihe/input/ERA5/monthly_means/0.25deg/clwc_Amon_ERA5_198501_198912.nc')['level'])*100\n",
    "\n",
    "if (('clw' or 'cli' or 'ta') in variable_id) == True:\n",
    "    # if var_id == 'clw' or var_id == 'cli':\n",
    "    for keys in dset_dict.keys():\n",
    "        # rename cmip pressure level for atmospheric temperature\n",
    "        dset_dict[keys] = dset_dict[keys].rename({'plev':'clev'})\n",
    "        # interpolate from hybrid to pressure levels for clw and cli\n",
    "        for var_id in [variable_id[variable_id.index('clw')], variable_id[variable_id.index('cli')]]:\n",
    "\n",
    "            if ('ps' in list(dset_dict[keys].keys())) == False:     # valid for models which don't provide ps in the clw or cli dataset\n",
    "                model = keys.split('.')[2]\n",
    "                ds_ps = col.search(source_id=model, table_id = ['Amon', ], experiment_id=['historical'], variable_id=['ps','p0', ], member_id=['r1i1p1f1']).to_dataset_dict(zarr_kwargs={'use_cftime':True,}, )\n",
    "                dset_dict[keys].update(ds_ps[keys], )\n",
    "                dset_dict[keys]['ps'] = dset_dict[keys]['ps'].isel(member_id = 0)\n",
    "                \n",
    "                \n",
    "            # Rename datasets with different naming convention for constant A\n",
    "            if ('a' in list(dset_dict[keys].keys())) == False:\n",
    "                dset_dict[keys] = dset_dict[keys].rename({'ap':'a', 'ap_bnds': 'a_bnds'})\n",
    "                    \n",
    "                    \n",
    "            # Convert the model level to isobaric levels\n",
    "            #### a, b, ps, p0\n",
    "            if ('a' in list(dset_dict[keys].keys())) == True and ('b' in list(dset_dict[keys].keys())) == True and ('p0' in list(dset_dict[keys].keys())) == True and ('ps' in list(dset_dict[keys].keys())) == True:\n",
    "                dset_dict[keys]['{}_interp'.format(var_id)] = gc.interpolation.interp_hybrid_to_pressure(data=dset_dict[keys][var_id].isel(member_id = 0), \n",
    "                                                                                                                ps=dset_dict[keys]['ps'],hyam=dset_dict[keys]['a'],\n",
    "                                                                                                                hybm=dset_dict[keys]['b'],\n",
    "                                                                                                                p0=dset_dict[keys]['p0'].values, \n",
    "                                                                                                                new_levels=(era_level).values, )\n",
    "                # # remove the variables needed for the calculation of the isobaric levels. If this step is not performed, \n",
    "                # # the horizontal regridding will not be possible.\n",
    "                # dset_dict[keys] = dset_dict[keys].drop(('a', 'p0', 'b', 'ps', 'a_bnds', 'b_bnds', var_id))\n",
    "                dset_dict[keys] = dset_dict[keys].drop((var_id))\n",
    "                dset_dict[keys] = dset_dict[keys].rename({'{}_interp'.format(var_id):var_id})\n",
    "\n",
    "            #### a, b, ps\n",
    "            elif ('a' in list(dset_dict[keys].keys())) == True and ('b' in list(dset_dict[keys].keys())) == True and ('ps' in list(dset_dict[keys].keys())) == True and ('p0' in list(dset_dict[keys].keys())) == False:\n",
    "                dset_dict[keys]['{}_interp'.format(var_id)] = gc.interpolation.interp_hybrid_to_pressure(data=dset_dict[keys][var_id].isel(member_id=0), \n",
    "                                                                                                                ps=dset_dict[keys]['ps'],\n",
    "                                                                                                                hyam=dset_dict[keys]['a'], \n",
    "                                                                                                                hybm=dset_dict[keys]['b'],\n",
    "                                                                                                                p0=100000.0,\n",
    "                                                                                                                new_levels=(era_level).values, )\n",
    "                # dset_dict[keys] = dset_dict[keys].drop(('a', 'b', 'ps', 'a_bnds', 'b_bnds', var_id))\n",
    "                dset_dict[keys] = dset_dict[keys].drop((var_id))\n",
    "                dset_dict[keys] = dset_dict[keys].rename({'{}_interp'.format(var_id):var_id})\n",
    "        \n",
    "        # remove the variables needed for the calculation of the isobaric levels. If this step is not performed, \n",
    "        # the horizontal regridding will not be possible.\n",
    "        if ('p0' in list(dset_dict[keys].keys())) == True:\n",
    "            dset_dict[keys] = dset_dict[keys].drop(('a', 'p0', 'b', 'ps', 'a_bnds', 'b_bnds',))\n",
    "        elif ('p0' in list(dset_dict[keys].keys())) == False:\n",
    "            dset_dict[keys] = dset_dict[keys].drop(('a', 'b', 'ps', 'a_bnds', 'b_bnds',))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66e138",
   "metadata": {},
   "source": [
    "## Regrid CMIP6 data to NorESM2-MM grid <a id='regrid_hz'></a>\n",
    "\n",
    "We want to conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models. At the moment we have all historical data from the CMIP6 models. For this, we will have to extract the 30-year period between 1985 and 2014.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year.\n",
    "\n",
    "The CMIP6 high resolution models have approximately a nominal resolution of 100km. But not all have identical grid spacing. Hence we will make use of the python package `xesmf` and the documentation on [decreasing resolution](https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html#Decreasing-resolution), [Limitations and warnings](https://xesmf.readthedocs.io/en/latest/notebooks/Masking.html?highlight=conservative#Limitations-and-warnings). \n",
    "\n",
    "NorESM2-MM will be the reference grid since we want to compare the models to the ERA5 data. The ERA5 data has a nominal resolution of 0.25deg and has been regridded to the same horizontal resolution as the NorESM2-MM in [the ERA5 Jupyter Notebook](../ERA5/ERA5_1985-2014.ipynb). \n",
    "\n",
    "$\\rightarrow$ Define NorESM2-MM as the reference grid `ds_out`.\n",
    "\n",
    "Create a new Python dictionary (`ds_gridded_dict`) with the regridded CMIP6 `xarray` datasets between 1985 an 2014. Save each regridded model to a `netcdf`, locally. \n",
    "\n",
    "> **_NOTE:_** This step may take several minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13589926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/GFDL-ESM4/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/CIESM/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/NorESM2-MM/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/CAMS-CSM1-0/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/GFDL-CM4/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/MPI-ESM1-2-HR/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/CMCC-ESM2/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/CMCC-CM2-HR4/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/SAM0-UNICON/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/MRI-ESM2-0/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/CMCC-CM2-SR5/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/FGOALS-f3-L/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/TaiESM1/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/BCC-CSM2-MR/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/E3SM-1-1-ECA/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/E3SM-1-1/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n",
      "pr True\n",
      "prsn True\n",
      "ta True\n",
      "clw True\n",
      "cli True\n",
      "file written: /scratch/franzihe/output/CMIP6_hist/1deg/EC-Earth3-AerChem/['cli', 'clw', 'pr', 'prsn', 'ta']_Amon_1deg_198501_201412.nc\n"
     ]
    }
   ],
   "source": [
    "starty = 1985; endy = 2014\n",
    "year_range = range(starty, endy+1)\n",
    "\n",
    "# create dictionary for reggridded data\n",
    "ds_gridded_dict = dict()\n",
    "\n",
    "# Read in the output grid from NorESM\n",
    "if variable_id[0] == 'lwp':\n",
    "    ds_out = dset_dict['CMIP.NCC.NorESM2-MM.historical.AERmon.gn'].isel(member_id = 0)\n",
    "else:\n",
    "    ds_out = dset_dict['CMIP.NCC.NorESM2-MM.historical.Amon.gn'].isel(member_id = 0)\n",
    "ds_out = ds_out.sel(time = ds_out.time.dt.year.isin(year_range)).squeeze()\n",
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for keys in dset_dict.keys():\n",
    "    # select only models which have atmospheric monthly values\n",
    "    amon = keys.split('.')[-2]\n",
    "    if amon == 'Amon' or amon == 'AERmon': \n",
    "        # select model name \n",
    "        model = keys.split('.')[2]\n",
    "        \n",
    "        # select where data should be saved\n",
    "        if len(variable_id) > 1:\n",
    "            filename = '{}_Amon_1deg_{}01_{}12.nc'.format(variable_id, starty, endy)\n",
    "        elif len([variable_id]) == 1:\n",
    "            filename = '{}_Amon_1deg_{}01_{}12.nc'.format(variable_id[0], starty, endy)\n",
    "        # filename = '{}_Amon_1deg_{}01_{}12.nc'.format(variable_id[0], starty, endy)\n",
    "        savepath = '/scratch/franzihe/output/CMIP6_hist/1deg/{}/'.format(model)\n",
    "        nc_out = savepath + filename\n",
    "        files = glob(nc_out)\n",
    "        \n",
    "        # Input data from CMIP6 model to be regridded\n",
    "        ds_in = dset_dict[keys].isel(member_id = 0)\n",
    "        ds_in = ds_in.sel(time = ds_in.time.dt.year.isin(year_range)).squeeze()\n",
    "            \n",
    "        # common time grid\n",
    "        ds_in['time'] = ds_out['time']\n",
    "            \n",
    "\n",
    "        # Regrid data\n",
    "        ds_in_regrid = fct.regrid_data(ds_in, ds_out)\n",
    "\n",
    "\n",
    "        # Shift the longitude from 0-->360 to -180-->180 and sort by longitude and time\n",
    "        ds_in_regrid = ds_in_regrid.assign_coords(lon=(((ds_in_regrid.lon + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "        ds_in_regrid = ds_in_regrid.reset_coords(names=['time_bnds', ], drop=True)\n",
    "            \n",
    "            \n",
    "        # create dataset with all models\n",
    "        ds_gridded_dict[model] = ds_in_regrid\n",
    "\n",
    "        # if nc_out in files:\n",
    "        #     print('{} is downloaded'.format(nc_out))\n",
    "        #     counter += 1\n",
    "        #     print('Have regridded in total: {:} files'.format(str(counter)))\n",
    "        # else:    \n",
    "            # Save to netcdf file\n",
    "        ds_in_regrid.to_netcdf(nc_out)\n",
    "        print('file written: {}'.format(nc_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3e3d0",
   "metadata": {},
   "source": [
    "## Connect all models into one Dataset with new coordinate 'model'\n",
    "\n",
    "We will create a `xarray.Dataset` with all CMIP6 models, after the interpolation to the same horizonal (and vertical) resolution. This step will make the next steps easier, as we will not need the the full dictonary key and can just use the model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa03d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in ds_gridded_dict.keys():\n",
    "#     ds_gridded_dict[model] = xr.open_dataset('/scratch/franzihe/output/CMIP6_hist/1deg/{}/{}_Amon_1deg_198501_201412.nc'.format(model,variable_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88c2aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the model with nan array where missing variables\n",
    "for model in ds_gridded_dict.keys():\n",
    "    for var in variable_id:\n",
    "        # print(var, model)\n",
    "        if (var in ds_gridded_dict[model].variables) == False:\n",
    "            print(model, var)\n",
    "            if var == 'pr' or var == 'prsn':\n",
    "                ds_gridded_dict[model][var] = xr.DataArray(data=da.full(shape = (ds_gridded_dict[model]['time'].shape[0], \n",
    "                                                                                 ds_gridded_dict[model]['lat'].shape[0], \n",
    "                                                                                 ds_gridded_dict[model]['lon'].shape[0]), \n",
    "                                                            fill_value=np.nan, \n",
    "                                                            chunks=(120, 721, 1440/2)), dims = [ds_gridded_dict[model].time.dims[0], ds_gridded_dict[model].lat.dims[0], ds_gridded_dict[model].lon.dims[0]], coords=[ds_gridded_dict[model].time.values, ds_gridded_dict[model].lat.values, ds_gridded_dict[model].lon.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f01e6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds = list(ds_gridded_dict.values())\n",
    "_coord = list(ds_gridded_dict.keys())\n",
    "ds_cmip = xr.concat(objs=_ds, dim=_coord, coords=\"all\").rename({'concat_dim':'model'})\n",
    "ds_cmip = ds_cmip.drop('bnds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec6513",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis <a id='exploratory'></a>\n",
    "\n",
    "## Find mixed-phase clouds\n",
    "\n",
    "To get a relationship between cloud phase and snowfall amount we find mixed-phase clouds and associated precipitation in each grid cell. $\\rightarrow$ \n",
    "\n",
    "1. loop through each latitude\n",
    "2. loop through each longitude\n",
    "3. calculate percentages in each level\n",
    "   1. IWC + LWC = 100%\n",
    "   2. IWC/(IWC + LWC) * 100 = percent_iwc %\n",
    "   3. LWC/(IWC + LWC) * 100 = percent_lwc %\n",
    "4. level where percent_iwc == 50% and percent_lwc == 50%\n",
    "   1. P(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   2. T(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   3. IWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   4. LWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   5. SWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   6. sf(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   7. tp(percent_iwc == 50% and percent_lwc == 50%)\n",
    "\n",
    "1. find, where precipitation is >= 0.25 mm day-1 and IWC+LWC >= 0.01 g kg-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "231a2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. calculate percentages in each level \n",
    "# 3.1. IWC + LWC = 100%\n",
    "# 3.3. LWC/(IWC + LWC)  = percent_lwc \n",
    "ds_cmip['cli_clw'] = ds_cmip['cli'] + ds_cmip['clw']\n",
    "ds_cmip['clw_percent'] = ds_cmip['clw']/ds_cmip['cli_clw']\n",
    "ds_cmip['cli_percent'] = ds_cmip['cli']/ds_cmip['cli_clw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "265aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find nearest\n",
    "def find_nearest(array, value):\n",
    "    # idx = (abs(array-value)).argmin()\n",
    "    idx = array == abs(array-value).min()\n",
    "    return(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed8af4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_clw = find_nearest(ds_cmip['clw_percent'], 0.5)\n",
    "idx_cli = find_nearest(ds_cmip['cli_percent'], 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf039794",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_filter = idx_clw & idx_clw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c3bb3d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/cmip/CMIP6_hr_1985-2014.ipynb Cell 35'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/cmip/CMIP6_hr_1985-2014.ipynb#ch0000101vscode-remote?line=0'>1</a>\u001b[0m ds_cmip[\u001b[39m'\u001b[39;49m\u001b[39mprsn\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mwhere(idx_filter)\u001b[39m.\u001b[39;49misel(plev \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, model \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mmean(\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m, keep_attrs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39;49mplot()\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py:862\u001b[0m, in \u001b[0;36m_PlotMethods.__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=860'>861</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m plot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_da, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py:293\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(darray, row, col, col_wrap, ax, hue, rtol, subplot_kws, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=241'>242</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=242'>243</a>\u001b[0m     darray,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=243'>244</a>\u001b[0m     row\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=250'>251</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=251'>252</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=252'>253</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=253'>254</a>\u001b[0m \u001b[39m    Default plot of DataArray using :py:mod:`matplotlib:matplotlib.pyplot`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=254'>255</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=290'>291</a>\u001b[0m \u001b[39m    xarray.DataArray.squeeze\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=291'>292</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=292'>293</a>\u001b[0m     darray \u001b[39m=\u001b[39m darray\u001b[39m.\u001b[39;49msqueeze()\u001b[39m.\u001b[39;49mcompute()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=294'>295</a>\u001b[0m     plot_dims \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(darray\u001b[39m.\u001b[39mdims)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/plot/plot.py?line=295'>296</a>\u001b[0m     plot_dims\u001b[39m.\u001b[39mdiscard(row)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py:951\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=931'>932</a>\u001b[0m \u001b[39m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=932'>933</a>\u001b[0m \u001b[39mremote source into memory and return a new array. The original is\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=933'>934</a>\u001b[0m \u001b[39mleft unaltered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=947'>948</a>\u001b[0m \u001b[39mdask.compute\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=948'>949</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=949'>950</a>\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=950'>951</a>\u001b[0m \u001b[39mreturn\u001b[39;00m new\u001b[39m.\u001b[39;49mload(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py:925\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=906'>907</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataArray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=907'>908</a>\u001b[0m     \u001b[39m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=908'>909</a>\u001b[0m \u001b[39m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=909'>910</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=922'>923</a>\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=923'>924</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=924'>925</a>\u001b[0m     ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_to_temp_dataset()\u001b[39m.\u001b[39;49mload(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=925'>926</a>\u001b[0m     new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataarray.py?line=926'>927</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable \u001b[39m=\u001b[39m new\u001b[39m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py:862\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py?line=858'>859</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mda\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py?line=860'>861</a>\u001b[0m \u001b[39m# evaluate all the dask arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py?line=861'>862</a>\u001b[0m evaluated_data \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39;49mcompute(\u001b[39m*\u001b[39;49mlazy_data\u001b[39m.\u001b[39;49mvalues(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py?line=863'>864</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/xarray/core/dataset.py?line=864'>865</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[k]\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py:571\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=567'>568</a>\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=568'>569</a>\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=570'>571</a>\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/base.py?line=571'>572</a>\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py:79\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=75'>76</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=76'>77</a>\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=78'>79</a>\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=79'>80</a>\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=80'>81</a>\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=81'>82</a>\u001b[0m     dsk,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=82'>83</a>\u001b[0m     result,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=83'>84</a>\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=84'>85</a>\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=85'>86</a>\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=86'>87</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=87'>88</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=89'>90</a>\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m     <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/threaded.py?line=90'>91</a>\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py:496\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=493'>494</a>\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=494'>495</a>\u001b[0m     fire_tasks(chunksize)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=495'>496</a>\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=496'>497</a>\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=497'>498</a>\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py:134\u001b[0m, in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=132'>133</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mqueue_get\u001b[39m(q):\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/site-packages/dask/local.py?line=133'>134</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=168'>169</a>\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=169'>170</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=170'>171</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=171'>172</a>\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/queue.py?line=172'>173</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be a non-negative number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/geocat/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/geocat/lib/python3.9/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_cmip['prsn'].where(idx_filter).isel(plev = 0, model = 0).mean('time', keep_attrs=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "439be147",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmip['clw_50_50'] = ds_cmip['clw'].where(idx_filter)\n",
    "ds_cmip['cli_50_50'] = ds_cmip['cli'].where(idx_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07569b8",
   "metadata": {},
   "source": [
    "## Create seasonal mean of all regridded models\n",
    "...and plot seasonal mean of each individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmip[variable_id[0]+'_season_mean'] = ds_cmip[variable_id[0]].groupby('time.season').mean('time', keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the variable name similar to ERA5 for plotting\n",
    "var = fct.to_era_variable[variable_id[0]]\n",
    "\n",
    "for model in ds_cmip.model.values:\n",
    "    fct.plt_spatial_seasonal_mean(ds_cmip[variable_id[0]+'_season_mean'].sel(model=model), var, title='{} MEAN ({} - {})'.format(model,starty, endy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13221e8b",
   "metadata": {},
   "source": [
    "## Create model mean/spread of seasonal mean of all regridded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f08410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmip[variable_id[0]+'_season_model_mean'] = ds_cmip[variable_id[0]+'_season_mean'].mean('model', keep_attrs=True, skipna = True)\n",
    "ds_cmip[variable_id[0]+'_season_model_std']  = ds_cmip[variable_id[0]+'_season_mean'].std('model', keep_attrs=True, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e90a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, im = fct.plt_spatial_seasonal_mean(ds_cmip[variable_id[0]+'_season_model_mean'], var, add_colorbar=False, title='CMIP6 - high resolution (1985 - 2014)')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')]), weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "axs[2].text(1,-0.12, ds_cmip.model.values.tolist()[0:5], size=12, ha=\"center\", \n",
    "         transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                'alpha':0.6,\n",
    "                'pad':5})\n",
    "if len(ds_cmip.model.values.tolist()) > 4:\n",
    "    axs[2].text(1,-0.25, ds_cmip.model.values.tolist()[5:10], size=12, ha=\"center\", \n",
    "            transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                    'alpha':0.6,\n",
    "                    'pad':5})\n",
    "if len(ds_cmip.model.values.tolist()) > 10:\n",
    "    axs[2].text(1,-0.38, ds_cmip.model.values.tolist()[10:-1], size=12, ha=\"center\", \n",
    "            transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                    'alpha':0.6,\n",
    "                    'pad':5})\n",
    "    \n",
    "\n",
    "# save figure to png\n",
    "figdir = '/uio/kant/geo-metos-u1/franzihe/Documents/Figures/CMIP6/'\n",
    "figname = '{}_season_mean_1deg_{}_{}.png'.format(variable_id[0], starty, endy)\n",
    "plt.savefig(figdir + figname, format = 'png', bbox_inches = 'tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e8da5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, im = fct.plt_spatial_seasonal_mean(ds_cmip[variable_id[0]+'_season_model_mean'], var, add_colorbar=False, title='CMIP6 - high resolution (1985 - 2014)')\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')]), weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "for ax, i in zip(axs, ds_cmip[variable_id[0]+'_season_model_std'].season):\n",
    "    sm = ds_cmip[variable_id[0]+'_season_model_std'].sel(season=i).plot.contour(ax=ax, transform=ccrs.PlateCarree(), \n",
    "                                                                      robust=True,\n",
    "                                                                      vmin = fct.plt_dict[var][fct.plt_dict['header'].index('vmin_std')], \n",
    "                                                                      vmax = fct.plt_dict[var][fct.plt_dict['header'].index('vmax_std')],\n",
    "                                                                       levels = 6,\n",
    "                                                                      cmap=cm.lajolla,\n",
    "                                                                      add_colorbar=False)\n",
    "    \n",
    "cbar_ax = fig.add_axes([1.10, 0.15, 0.025, 0.7])\n",
    "sb = fig.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "sb.set_label(label='STD - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')]), weight='bold')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "axs[2].text(1,-0.12, ds_cmip.model.values.tolist()[0:5], size=12, ha=\"center\", \n",
    "         transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                'alpha':0.6,\n",
    "                'pad':5})\n",
    "if len(ds_cmip.model.values.tolist()) > 4:\n",
    "    axs[2].text(1,-0.25, ds_cmip.model.values.tolist()[5:10], size=12, ha=\"center\", \n",
    "            transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                    'alpha':0.6,\n",
    "                    'pad':5})\n",
    "if len(ds_cmip.model.values.tolist()) > 10:\n",
    "    axs[2].text(1,-0.38, ds_cmip.model.values.tolist()[10:-1], size=12, ha=\"center\", \n",
    "            transform=axs[2].transAxes, bbox ={'facecolor':'green',\n",
    "                    'alpha':0.6,\n",
    "                    'pad':5})\n",
    "# save figure to png\n",
    "figdir = '/uio/kant/geo-metos-u1/franzihe/Documents/Figures/CMIP6/'\n",
    "figname = '{}_season_mean_std_1deg_{}_{}.png'.format(variable_id[0], starty, endy)\n",
    "plt.savefig(figdir + figname, format = 'png', bbox_inches = 'tight', transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to netcdf\n",
    "filename = '{}_1deg_{}01_{}12.nc'.format(variable_id[0], starty, endy)\n",
    "savepath = '/scratch/franzihe/output/CMIP6_hist/1deg/'\n",
    "nc_out = savepath + filename\n",
    "files = glob(nc_out)\n",
    "\n",
    "counter = 0 \n",
    "# Save to netcdf file\n",
    "if nc_out in files:\n",
    "#     print('{} is downloaded'.format(nc_out))\n",
    "#     counter += 1\n",
    "#     print('Have saved in total: {:} files'.format(str(counter)))\n",
    "# else:\n",
    "    ds_cmip.to_netcdf(nc_out)\n",
    "    print('file written: .{}'.format(nc_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c2396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b488e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e272af4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3add6210",
   "metadata": {},
   "source": [
    "# References <a id='references'></a>\n",
    "\n",
    "\n",
    "[1] Zelinka, M. D., Myers, T. A., McCoy, D. T., Po-Chedley, S., Caldwell, P. M., Ceppi, P., et al. (2020). Causes of higher climate sensitivity in CMIP6 models. Geophysical Research Letters, 47, e2019GL085782. https://doi-org.ezproxy.uio.no/10.1029/2019GL085782 \n",
    "\n",
    "[2] Bjordal, J., Storelvmo, T., Alterskjær, K. et al. Equilibrium climate sensitivity above 5 °C plausible due to state-dependent cloud feedback. Nat. Geosci. 13, 718–721 (2020). https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1 \n",
    "\n",
    "[3] Wu, T., Lu, Y., Fang, Y., Xin, X., Li, L., Li, W., Jie, W., Zhang, J., Liu, Y., Zhang, L., Zhang, F., Zhang, Y., Wu, F., Li, J., Chu, M., Wang, Z., Shi, X., Liu, X., Wei, M., Huang, A., Zhang, Y., and Liu, X.: The Beijing Climate Center Climate System Model (BCC-CSM): the main progress from CMIP5 to CMIP6 , Geosci. Model Dev., 12, 1573–1600, https://doi.org/10.5194/gmd-12-1573-2019, 2019. \n",
    "\n",
    "[4] Lee, W.-L., Wang, Y.-C., Shiu, C.-J., Tsai, I., Tu, C.-Y., Lan, Y.-Y., Chen, J.-P., Pan, H.-L., and Hsu, H.-H.: Taiwan Earth System Model Version 1: description and evaluation of mean state, Geosci. Model Dev., 13, 3887–3904, https://doi.org/10.5194/gmd-13-3887-2020, 2020. \n",
    "\n",
    "[5] Bian HE, Yongqiang YU, Qing BAO, Pengfei LIN, Hailong LIU, Jinxiao LI, Lei WANG, Yimin LIU, Guoxiong WU, Kangjun CHEN, Yuyang GUO, Shuwen ZHAO, Xiaoqi ZHANG, Mirong SONG & Jinbo XIE (2020) CAS FGOALS-f3-L model dataset descriptions for CMIP6 DECK experiments, Atmospheric and Oceanic Science Letters, 13:6, 582-588, DOI: 10.1080/16742834.2020.1778419 \n",
    "\n",
    "[6] Cherchi, A., Fogli, P. G., Lovato, T., Peano, D., Iovino, D., Gualdi, S., et al. (2019). Global mean climate and main patterns of variability in the CMCC-CM2 coupled model. Journal of Advances in Modeling Earth Systems, 11, 185– 209. https://doi-org.ezproxy.uio.no/10.1029/2018MS001369 \n",
    "\n",
    "[7] van Noije, T., Bergman, T., Le Sager, P., O'Donnell, D., Makkonen, R., Gonçalves-Ageitos, M., Döscher, R., Fladrich, U., von Hardenberg, J., Keskinen, J.-P., Korhonen, H., Laakso, A., Myriokefalitakis, S., Ollinaho, P., Pérez García-Pando, C., Reerink, T., Schrödner, R., Wyser, K., and Yang, S.: EC-Earth3-AerChem: a global climate model with interactive aerosols and atmospheric chemistry participating in CMIP6 , Geosci. Model Dev., 14, 5637–5668, https://doi.org/10.5194/gmd-14-5637-2021, 2021. \n",
    "\n",
    "[8] Golaz, J.-C., Caldwell, P. M., Van Roekel, L. P., Petersen, M. R., Tang, Q., Wolfe, J. D., et al. (2019). The DOE E3SM coupled model version 1: Overview and evaluation at standard resolution. Journal of Advances in Modeling Earth Systems, 11, 2089– 2129. https://doi-org.ezproxy.uio.no/10.1029/2018MS001603 \n",
    "\n",
    "[9] Burrows, S. M., Maltrud, M., Yang, X., Zhu, Q., Jeffery, N., Shi, X., et al. (2020). The DOE E3SM v1.1 biogeochemistry configuration: Description and simulated ecosystem-climate responses to historical changes in forcing. Journal of Advances in Modeling Earth Systems, 12, e2019MS001766. https://doi-org.ezproxy.uio.no/10.1029/2019MS001766 \n",
    "\n",
    "[10] Müller, W. A., Jungclaus, J. H., Mauritsen, T., Baehr, J., Bittner, M., Budich, R., et al. (2018). A higher-resolution version of the Max Planck Institute Earth System Model (MPI-ESM1.2-HR). Journal of Advances in Modeling Earth Systems, 10, 1383– 1413. https://doi-org.ezproxy.uio.no/10.1029/2017MS001217 \n",
    "\n",
    "[11] Yukimoto, S., H. Kawai, T. Koshiro, N. Oshima, K. Yoshida, S. Urakawa, H. Tsujino, M. Deushi, T. Tanaka, M. Hosaka, S. Yabu, H. Yoshimura, E. Shindo, R. Mizuta, A. Obata, Y. Adachi, and M. Ishii, 2019: The Meteorological Research Institute Earth System Model version 2.0, MRI-ESM2.0: Description and basic evaluation of the physical component. J. Meteor. Soc. Japan, 97, 931–965, doi:10.2151/jmsj.2019-051.\n",
    "\n",
    "[12] Seland, Ø., Bentsen, M., Olivié, D., Toniazzo, T., Gjermundsen, A., Graff, L. S., Debernard, J. B., Gupta, A. K., He, Y.-C., Kirkevåg, A., Schwinger, J., Tjiputra, J., Aas, K. S., Bethke, I., Fan, Y., Griesfeller, J., Grini, A., Guo, C., Ilicak, M., Karset, I. H. H., Landgren, O., Liakka, J., Moseid, K. O., Nummelin, A., Spensberger, C., Tang, H., Zhang, Z., Heinze, C., Iversen, T., and Schulz, M.: Overview of the Norwegian Earth System Model (NorESM2) and key climate response of CMIP6 DECK, historical, and scenario simulations, Geosci. Model Dev., 13, 6165–6200, https://doi.org/10.5194/gmd-13-6165-2020, 2020. \n",
    "\n",
    "[13] Held, I. M., Guo, H., Adcroft, A., Dunne, J. P., Horowitz, L. W., Krasting, J., et al. (2019). Structure and performance of GFDL's CM4.0 climate model. Journal of Advances in Modeling Earth Systems, 11, 3691– 3727. https://doi-org.ezproxy.uio.no/10.1029/2019MS001829 \n",
    "\n",
    "[14] Dunne, J. P., Horowitz, L. W., Adcroft, A. J., Ginoux, P., Held, I. M., John, J. G., et al. (2020). The GFDL Earth System Model Version 4.1 (GFDL-ESM 4.1): Overall coupled model description and simulation characteristics. Journal of Advances in Modeling Earth Systems, 12, e2019MS002015. https://doi-org.ezproxy.uio.no/10.1029/2019MS002015 \n",
    "\n",
    "[15] Park, S., Shin, J., Kim, S., Oh, E., & Kim, Y. (2019). Global Climate Simulated by the Seoul National University Atmosphere Model Version 0 with a Unified Convection Scheme (SAM0-UNICON), Journal of Climate, 32(10), 2917-2949. Retrieved Jan 12, 2022, from https://journals-ametsoc-org.ezproxy.uio.no/view/journals/clim/32/10/jcli-d-18-0796.1.xml\n",
    "\n",
    "[16] Lin, Y., Huang, X., Liang, Y., Qin, Y., Xu, S., & Huang, W., et al. (2020). Community Integrated Earth System Model (CIESM): Description and evaluation. Journal of Advances in Modeling Earth Systems, 12, e2019MS002036. https://doi-org.ezproxy.uio.no/10.1029/2019MS002036 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e80205",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('globalsnow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
