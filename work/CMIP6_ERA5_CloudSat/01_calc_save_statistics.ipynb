{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PYTHONPATH=\"${PYTHONPATH}:/uio/kant/geo-geofag-u1/franzihe/Documents/Python/globalsnow/CloudSat_ERA5_CMIP6_analysis/utils/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of CMIP6, ERA5, and CloudSat\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>\n",
    "\n",
    "# 1. Introduction <a id='introduction'></a>\n",
    "\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall \n",
    "\n",
    "\n",
    "> **_NOTE:_** .\n",
    "\n",
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "\n",
    "## Organize my data\n",
    "\n",
    "- Define a prefix for my project (you may need to adjust it for your own usage on your infrastructure).\n",
    "    - input folder where all the data used as input to my Jupyter Notebook is stored (and eventually shared)\n",
    "    - output folder where all the results to keep are stored\n",
    "    - tool folder where all the tools\n",
    "\n",
    "The ERA5 0.25deg data is located in the folder `\\scratch\\franzihe\\`, CloudSat at ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimi.uio.no\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "abs_path = str(pathlib.Path(hostname).parent.absolute())\n",
    "WORKDIR = abs_path[:- (len(abs_path.split('/')[-2] + abs_path.split('/')[-1])+1)]\n",
    "\n",
    "\n",
    "if \"mimi\" in hostname:\n",
    "    print(hostname)\n",
    "    DATA_DIR = \"/mn/vann/franzihe/\"\n",
    "    # FIG_DIR = \"/uio/kant/geo-geofag-u1/franzihe/Documents/Figures/ERA5/\"\n",
    "    FIG_DIR = \"/uio/kant/geo-geofag-u1/franzihe/Documents/Python/globalsnow/CloudSat_ERA5_CMIP6_analysis/Figures/CS_ERA5_CMIP6/\"\n",
    "elif \"glefsekaldt\" in hostname: \n",
    "    DATA_DIR = \"/home/franzihe/Data/\"\n",
    "    FIG_DIR = \"/home/franzihe/Documents/Figures/ERA5/\"\n",
    "\n",
    "INPUT_DATA_DIR = os.path.join(DATA_DIR, 'input')\n",
    "OUTPUT_DATA_DIR = os.path.join(DATA_DIR, 'output')\n",
    "UTILS_DIR = os.path.join(WORKDIR, 'utils')\n",
    "\n",
    "sys.path.append(UTILS_DIR)\n",
    "# make figure directory\n",
    "try:\n",
    "    os.mkdir(FIG_DIR)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [requirements_globalsnow.txt](../../requirements_globalsnow.txt) \n",
    "- load `python` packages from [imports.py](../../utils/imports.py)\n",
    "- load `functions` from [functions.py](../../utils/functions.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f2c854db730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "from imports import(xr, intake, ccrs, cy, plt, glob, cm, fct, np, da, LogNorm, pd)\n",
    "xr.set_options(display_style='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open variables\n",
    "Get the data requried for the analysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_in = os.path.join(INPUT_DATA_DIR, 'ERA5')\n",
    "cmip_in = os.path.join(INPUT_DATA_DIR, 'cmip6_hist')\n",
    "dat_out = os.path.join(OUTPUT_DATA_DIR, 'CS_ERA5_CMIP6')\n",
    "\n",
    "# make output data directory\n",
    "try:\n",
    "    os.mkdir(dat_out)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_id = ['tas', 'prsn', 'pr', 'lwp', 'clivi', 'areacella']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load all available models into one dictonary, which includes an xarray dataset with `xarray.open_mfdataset(file)` and select the time range [by name](https://xarray.pydata.org/en/stable/user-guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models = [\n",
    "               'ERA5',\n",
    "               'MIROC6', \n",
    "               'CanESM5', \n",
    "               'AWI-ESM-1-1-LR', \n",
    "               'MPI-ESM1-2-LR', \n",
    "               'UKESM1-0-LL', \n",
    "               'HadGEM3-GC31-LL',\n",
    "               'CNRM-CM6-1',\n",
    "               'CNRM-ESM2-1',\n",
    "               'IPSL-CM6A-LR',\n",
    "               'IPSL-CM5A2-INCA'\n",
    "            ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_dict = {}\n",
    "\n",
    "era_files = [sorted(glob(f'{era_in}/daily_means/40NS/daily_mean_40*ERA5*.nc'))] + \\\n",
    "        sorted(glob(f'{era_in}/common_grid/40NS/*ERA5_daily_mean*_IPSL-CM6A-LR*.nc')) + \\\n",
    "        sorted(glob(f'{era_in}/common_grid/40NS/*ERA5_daily_mean*_IPSL-CM5A2-INCA*.nc'))\n",
    "\n",
    "\n",
    "for file in era_files:\n",
    "    if 'IPSL-CM6A-LR' in file:\n",
    "        res = 'era_250'\n",
    "    elif 'IPSL-CM5A2-INCA' in file:\n",
    "        res = 'era_500'\n",
    "    else:\n",
    "        res = 'era_30'\n",
    "    # res = '250' if 'IPSL-CM6A-LR' in file else '500'\n",
    "    era_dict[res] = xr.open_mfdataset(file)\n",
    "\n",
    "# Remove leap day for ERA files\n",
    "for res in era_dict.keys():\n",
    "    era_dict[res] = era_dict[res].sel(time=~((era_dict[res].time.dt.month == 2) & (era_dict[res].time.dt.day == 29)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;time&#x27; (time: 1460)&gt;\n",
       "array([&#x27;2007-01-01T00:00:00.000000000&#x27;, &#x27;2007-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2007-01-03T00:00:00.000000000&#x27;, ..., &#x27;2010-12-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2010-12-30T00:00:00.000000000&#x27;, &#x27;2010-12-31T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2007-01-01 2007-01-02 ... 2010-12-31</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'time'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 1460</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-363ba0f5-882d-40ac-8d27-b537d77c5691' class='xr-array-in' type='checkbox' checked><label for='section-363ba0f5-882d-40ac-8d27-b537d77c5691' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>2007-01-01 2007-01-02 2007-01-03 ... 2010-12-29 2010-12-30 2010-12-31</span></div><div class='xr-array-data'><pre>array([&#x27;2007-01-01T00:00:00.000000000&#x27;, &#x27;2007-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2007-01-03T00:00:00.000000000&#x27;, ..., &#x27;2010-12-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2010-12-30T00:00:00.000000000&#x27;, &#x27;2010-12-31T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></div></li><li class='xr-section-item'><input id='section-666a0c57-0bbe-46e7-b6b1-16723776c54f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-666a0c57-0bbe-46e7-b6b1-16723776c54f' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2007-01-01 ... 2010-12-31</div><input id='attrs-fcf91d47-04fe-4f62-aec9-a489c62d51f3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-fcf91d47-04fe-4f62-aec9-a489c62d51f3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a503dd7e-8817-4f2e-ae57-c3ed67e0e061' class='xr-var-data-in' type='checkbox'><label for='data-a503dd7e-8817-4f2e-ae57-c3ed67e0e061' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2007-01-01T00:00:00.000000000&#x27;, &#x27;2007-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2007-01-03T00:00:00.000000000&#x27;, ..., &#x27;2010-12-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2010-12-30T00:00:00.000000000&#x27;, &#x27;2010-12-31T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-31b81dfb-0266-44b7-8729-4a7d05e9a507' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-31b81dfb-0266-44b7-8729-4a7d05e9a507' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'time' (time: 1460)>\n",
       "array(['2007-01-01T00:00:00.000000000', '2007-01-02T00:00:00.000000000',\n",
       "       '2007-01-03T00:00:00.000000000', ..., '2010-12-29T00:00:00.000000000',\n",
       "       '2010-12-30T00:00:00.000000000', '2010-12-31T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2007-01-01 2007-01-02 ... 2010-12-31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "era_dict['era_500'].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip_dict = {}\n",
    "\n",
    "for model in list_models[1:]:\n",
    "    cmip_file_in = sorted(glob(f'{cmip_in}/single_model/{model}/*_{model}_*40*.nc'))\n",
    "    cmip_dict[model] = xr.open_mfdataset(cmip_file_in, decode_times =True, use_cftime=True).rename_vars({'clivi': 'iwp'})\n",
    "    \n",
    "    cmip_dict[model]['twp'] = cmip_dict[model]['lwp'] + cmip_dict[model]['iwp']\n",
    "    cmip_dict[model] = fct.to_ERA5_date(cmip_dict[model], model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip_250 = {}\n",
    "cmip_500 = {}\n",
    "for model in list_models[1:]:\n",
    "    # Read CMIP files\n",
    "    cmip_files_250 = sorted(glob(f'{cmip_in}/common_grid/{model}/*_IPSL-CM6A-LR_{model}*40*.nc'))\n",
    "    cmip_files_500 = sorted(glob(f'{cmip_in}/common_grid/{model}/*_IPSL-CM5A2-INCA_{model}*40*.nc'))\n",
    "    if len(cmip_files_250) != 0:\n",
    "        cmip_250[model] = xr.open_mfdataset(cmip_files_250, decode_times =True, use_cftime=True).rename_vars({'clivi': 'iwp'})\n",
    "    cmip_500[model] = xr.open_mfdataset(cmip_files_500, decode_times =True, use_cftime=True).rename_vars({'clivi': 'iwp'})\n",
    "\n",
    "\n",
    "# Calculate 'twp' variable and convert calendar\n",
    "for cmip in [cmip_250, cmip_500]:\n",
    "    for model in cmip.keys():\n",
    "        cmip[model]['twp'] = cmip[model]['lwp'] + cmip[model]['iwp']\n",
    "        cmip[model] = fct.to_ERA5_date(cmip[model], model)\n",
    "\n",
    "_coord = list(cmip_250.keys())\n",
    "_ds = list(cmip_250.values())\n",
    "cmip_dict['cmip_250'] = xr.concat(objs=_ds, dim=_coord, coords='all').rename({'concat_dim':'model'})\n",
    "\n",
    "_coord = list(cmip_500.keys())\n",
    "_ds = list(cmip_500.values())\n",
    "cmip_dict['cmip_500'] = xr.concat(objs=_ds, dim=_coord, coords='all').rename({'concat_dim':'model'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "For variables:\n",
    "- Snowfall [prsn]\n",
    "- Total column cloud liquid, supercooled liqid, and rain water [twp]\n",
    "- Total column cloud ice, snow water [iwp]\n",
    "- 2m-Temperature [tas]\n",
    "\n",
    "1. Find where liquid water path is $\\ge$ 5 g m-2 \n",
    "2. Find where snowfall is $\\ge$ 0.01mm h-1\n",
    "3. Find where 2m-temperature $\\le$ 0 $^o$ C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# th_lcc = 0.005\n",
    "# th_2t = 273.15\n",
    "# th_frac_days = 0.1\n",
    "# th_tp = 0.01\n",
    "# th_sf = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_days_season(ds):\n",
    "    days_season = xr.DataArray(data = [xr.concat([ds.sel(time=fct.is_season(ds['time.month'], 1, 2)), \n",
    "                                                  ds.sel(time=fct.is_season(ds['time.month'],12,12))], dim='time').sizes['time'],\n",
    "                                       ds.sel(time=fct.is_season(ds['time.month'], 6, 8)).sizes['time'],\n",
    "                                       ds.sel(time=fct.is_season(ds['time.month'], 3, 5)).sizes['time'],\n",
    "                                       ds.sel(time=fct.is_season(ds['time.month'], 9, 11)).sizes['time'],], \n",
    "                                dims={'season'}, \n",
    "                                coords={'season':['DJF', 'JJA', 'MAM', 'SON']})\n",
    "    \n",
    "    _days = []\n",
    "    for month in np.arange(1,13):\n",
    "        _days.append(ds.sel(time=fct.is_season(ds['time.month'], month, month)).sizes['time'])\n",
    "        # print(month, )\n",
    "    days_month = xr.DataArray(data= np.array(_days),\n",
    "                            dims={'month'}, \n",
    "                            coords={'month':np.arange(1,13)} )\n",
    "    \n",
    "    return(days_season, days_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lcc_sf(ds, lwp_threshold):\n",
    "    days_season, days_month = calc_days_season(ds)\n",
    "    \n",
    "    # find where 2m-temperature <= 0C or <= threshold\n",
    "    # This should automatically assume that it is already only snow, but it could include supercooled \n",
    "    # rain in the case of total precipitation\n",
    "    th_2t = 273.15\n",
    "    ds_2t = ds.where(ds['tas'] <= th_2t, other=np.nan)\n",
    "    \n",
    "    # 1. find where liquid water >= 0.005 kgm-2 or >= threshold\n",
    "    th_lcc = 0.001*lwp_threshold\n",
    "    ds_lcc_2t = ds_2t.where(ds_2t['lwp']>=th_lcc, other=np.nan)\n",
    "    ds_lcc = ds.where(ds['lwp']>=th_lcc, other=np.nan)\n",
    "    \n",
    "\n",
    "    # amount of freezing rain\n",
    "    ds_lcc_2t['prfr'] = (ds_lcc_2t['pr'] - ds_lcc_2t['prsn'])\n",
    "    ds_lcc_2t['prfr'].attrs = {'units': 'kg m-2 h-1', 'long_name': 'Mean freezing rain rate'}\n",
    "\n",
    "    # # if we want a precip or snowfall threshold apply here\n",
    "    # # find where total precipitation >0 kgm-2h-1 threshold in these liquid containg clouds\n",
    "    # # th_tp = 0.01\n",
    "    # # ds_lcc_2t = ds_lcc_2t.where(ds['pr']>=th_tp, other=np.nan) \n",
    "    # # 2.1 find where snowfall >= 0.24 mmday-1 or >= threshold in these liquid containing clouds, but not temperature threshold\n",
    "    # # multiply by 24 to make it comparable to McIllhattan et al. As they use 0.01mmh-1 as lower threshold\n",
    "    # # applying snowfall days, based on threshold (th_sf). Gives days where snowfall above th_sf and counts days in season and \n",
    "    # # devides by season days\n",
    "    # th_sf = 0.01\n",
    "    # ds_lcc_2t_sf = ds_lcc_2t.where(ds['prsn']>=th_sf, other=np.nan) \n",
    "    # # th_days = (ds_lcc_2t_sf['twp'].groupby('time.season').count(dim='time',keep_attrs=False))/days_season\n",
    "\n",
    "\n",
    "    # create dataset to use for calculating the precipitation efficency. For the precipitation efficency we want to remove th_frac \n",
    "    # days where liquid water content and temperature requirements are met. \n",
    "    # assign percent of snowfall days, required in a pixle, which should be included in the statistics\n",
    "    th_frac = 0.1\n",
    "    th_days_lcc_2t = (ds_lcc_2t['lwp'].groupby('time.season').count(dim='time',keep_attrs=False))/days_season\n",
    "    th_days_lcc    = (ds_lcc['lwp'].groupby('time.season').count(dim='time',keep_attrs=False))/days_season\n",
    "\n",
    "    ds_lcc_2t_season = ds_lcc_2t.groupby('time.season').mean('time', skipna=True, keep_attrs=True)\n",
    "    ds_lcc_2t_season = ds_lcc_2t_season.where(th_days_lcc_2t>=th_frac, other=np.nan)\n",
    "\n",
    "    ds_lcc_season = ds_lcc.groupby('time.season').mean('time', skipna=True, keep_attrs=True)\n",
    "    ds_lcc_season = ds_lcc_season.where(th_days_lcc >= th_frac, other=np.nan)\n",
    "    \n",
    "    # Now create daily dataset based on seasonal supercooled liquid containing cloud days above th_sf, and th_frac\n",
    "    _mam = ((ds_lcc_2t.sel(time=fct.is_season(ds_lcc_2t['time.month'], 3, 5))).where(th_days_lcc_2t.sel(season='MAM') >=th_frac, other=np.nan)).drop('season')\n",
    "    _jja = ((ds_lcc_2t.sel(time=fct.is_season(ds_lcc_2t['time.month'], 6, 8))).where(th_days_lcc_2t.sel(season='JJA') >=th_frac, other=np.nan)).drop('season')\n",
    "    _son = ((ds_lcc_2t.sel(time=fct.is_season(ds_lcc_2t['time.month'], 9, 11))).where(th_days_lcc_2t.sel(season='SON') >=th_frac, other=np.nan)).drop('season')\n",
    "    _djf = ((xr.concat([ds_lcc_2t.sel(time=fct.is_season(ds_lcc_2t['time.month'], 1, 2)), \n",
    "                    ds_lcc_2t.sel(time=fct.is_season(ds_lcc_2t['time.month'],12,12))], dim='time')).where(th_days_lcc_2t.sel(season='DJF') >=th_frac, other=np.nan)).drop('season')\n",
    "    ds_lcc_2t_days = xr.merge(objects=[_djf, _jja, _mam, _son])\n",
    "\n",
    "    _mam = ((ds_lcc.sel(time=fct.is_season(ds_lcc['time.month'], 3, 5))).where(th_days_lcc_2t.sel(season='MAM') >=th_frac, other=np.nan)).drop('season')\n",
    "    _jja = ((ds_lcc.sel(time=fct.is_season(ds_lcc['time.month'], 6, 8))).where(th_days_lcc_2t.sel(season='JJA') >=th_frac, other=np.nan)).drop('season')\n",
    "    _son = ((ds_lcc.sel(time=fct.is_season(ds_lcc['time.month'], 9, 11))).where(th_days_lcc_2t.sel(season='SON') >=th_frac, other=np.nan)).drop('season')\n",
    "    _djf = ((xr.concat([ds_lcc.sel(time=fct.is_season(ds_lcc['time.month'], 1, 2)), \n",
    "                    ds_lcc.sel(time=fct.is_season(ds_lcc['time.month'],12,12))], dim='time')).where(th_days_lcc_2t.sel(season='DJF') >=th_frac, other=np.nan)).drop('season')\n",
    "    ds_lcc_days = xr.merge(objects=[_djf, _jja, _mam, _son])\n",
    "\n",
    "\n",
    "\n",
    "    # for all the other statistics we want to remove th_frac days where liquid content, temperature, and snowfall requirements are met\n",
    "    # which also means we have to apply the threshold for the total precipitation\n",
    "    # find where total precipitation >= 0.01 kg m-2 h-1 in LCCs with T2<0C\n",
    "    # th_tp = 0.01\n",
    "    # ds_lcc_2t_sf = ds_lcc_2t_days.where(ds_lcc_2t_days['pr'] >=th_tp, other=np.nan)\n",
    "    # find where snowfall >= 0.01 kg m-2 h-1 or >= threshold in these liquid containing clouds. \n",
    "    th_sf = 0.01\n",
    "    # ds_lcc_2t_sf = ds_lcc_2t_sf.where(ds_lcc_2t_sf['prsn'] >= th_sf, other=np.nan)\n",
    "    # ds_lcc_2t_sf = ds_lcc_2t_days.where(ds_lcc_2t_days['prsn'] >= th_sf, other=np.nan)\n",
    "    ds_lcc_2t_sf = ds_lcc_2t.where(ds_lcc_2t['prsn'] >= th_sf, other=np.nan)\n",
    "    # applying snowfall days, based on threshold (th_sf). Gives days where snowfall above th_sf and counts days in season and devides \n",
    "    # by season days\n",
    "    # th_days_sf = (ds_lcc_2t_sf['twp'].groupby('time.season').count(dim='time', keep_attrs=False))/days_season\n",
    "    ds_lcc_2t_sf_season = ds_lcc_2t_sf.groupby('time.season').mean('time', skipna=True, keep_attrs=True)\n",
    "    # ds_lcc_2t_sf_season = ds_lcc_2t_season.where(th_days_sf>=th_frac, other=np.nan)   # not needed for statistic\n",
    "    ds_lcc_2t_sf_season\n",
    "    \n",
    "    ds_lcc_sf = ds_lcc.where(ds_lcc['prsn'] >= th_sf, other=np.nan)\n",
    "    ds_lcc_sf_season = ds_lcc_sf.groupby('time.season').mean('time', skipna=True,keep_attrs=True)\n",
    "    \n",
    "    ds_sf = ds.where(ds['prsn'] >= th_sf, other=np.nan)\n",
    "    \n",
    "    # Now create daily dataset based on seasonal supercooled liquid containing cloud days above th_sf, and th_frac\n",
    "    # _mam = ((ds_lcc_2t_sf.sel(time=fct.is_season(ds_lcc_2t_sf['time.month'], 3, 5))).where(th_days_sf.sel(season='MAM') >=th_frac)).drop('season')\n",
    "    # _jja = ((ds_lcc_2t_sf.sel(time=fct.is_season(ds_lcc_2t_sf['time.month'], 6, 8))).where(th_days_sf.sel(season='JJA') >=th_frac)).drop('season')\n",
    "    # _son = ((ds_lcc_2t_sf.sel(time=fct.is_season(ds_lcc_2t_sf['time.month'], 9, 11))).where(th_days_sf.sel(season='SON') >=th_frac)).drop('season')\n",
    "    # _djf = ((xr.concat([ds_lcc_2t_sf.sel(time=fct.is_season(ds_lcc_2t_sf['time.month'], 1, 2)), \n",
    "    #                 ds_lcc_2t_sf.sel(time=fct.is_season(ds_lcc_2t_sf['time.month'],12,12))], dim='time')).where(th_days_sf.sel(season='DJF') >=th_frac)).drop('season')\n",
    "\n",
    "    # ds_lcc_2t_sf_days = xr.merge(objects=[_djf, _jja, _mam, _son])\n",
    "    \n",
    "    \n",
    "    # ds_lcc, ds_lcc_2t_days, #ds_lcc_2t_sf_days\n",
    "    return(ds_2t, ds_sf,\n",
    "           ds_lcc_2t, ds_lcc_2t_days, ds_lcc_2t_sf,\n",
    "           ds_lcc,    ds_lcc_days, ds_lcc_sf, \n",
    "           days_season, days_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_to_netcdf(dict_ds, statistic, days_season, days_month):\n",
    "    for model in dict_ds.keys():\n",
    "        dict_ds[model]['days_season'] = days_season[model]\n",
    "        dict_ds[model]['days_month']  = days_month[model]\n",
    "        \n",
    "        if 'areacella' not in list(dict_ds[model].keys()):\n",
    "            weights = fct.area_grid(dict_ds[model]['lat'].data, dict_ds[model]['lon'].data)\n",
    "            weights = weights.fillna(0)\n",
    "            dict_ds[model]['areacella'] = weights\n",
    "        if 'areacella' in list(dict_ds[model].keys()):\n",
    "            weights = dict_ds[model]['areacella'].fillna(0)\n",
    "            dict_ds[model]['areacella'] = weights\n",
    "            \n",
    "        if 'time' in dict_ds[model]['areacella'].coords:\n",
    "            dict_ds[model]['areacella'] = dict_ds[model]['areacella'].isel(time=0).squeeze()    \n",
    "        # try:\n",
    "        #     dict_ds[model]['areacella'] = dict_ds[model]['areacella'].isel(time=0).squeeze()\n",
    "        # except ValueError:\n",
    "        #     print('...')\n",
    "            \n",
    "        starty = dict_ds[model].indexes['time'].year.unique()[0]\n",
    "        endy = dict_ds[model].indexes['time'].year.unique()[-1]\n",
    "        out_dir = f'{dat_out}/{statistic}'\n",
    "        try:\n",
    "            os.mkdir(out_dir)\n",
    "        except OSError:\n",
    "            pass\n",
    "        \n",
    "        dict_ds_NH = dict_ds[model].sel(lat=slice(45,90))\n",
    "        dict_ds_SH = dict_ds[model].sel(lat=slice(-90,-45))\n",
    "        \n",
    "        ds_out = xr.concat([dict_ds_SH, dict_ds_NH], dim='lat')\n",
    "        # if 'model' in dict_ds[model].dims:\n",
    "        #     ds_out = ds_out[['time', 'lat', 'lon', 'season', 'month', 'model']]\n",
    "        # else:\n",
    "        #     ds_out = ds_out[['time', 'lat', 'lon', 'season', 'month']]\n",
    "\n",
    "        \n",
    "        file_out = f'{out_dir}/{model}_{statistic}_{starty}0101-{endy}1231.nc'\n",
    "        print(f'writing file ... {file_out}')\n",
    "        if 'model' in dict_ds[model].dims:\n",
    "            (ds_out.transpose('time', 'lat', 'lon', 'season', 'month', 'model')).to_netcdf(file_out)\n",
    "        else:\n",
    "        # ds_out.to_netcdf(file_out)\n",
    "            (ds_out.transpose('time', 'lat', 'lon', 'season', 'month')).to_netcdf(file_out)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['MIROC6', 'CanESM5', 'AWI-ESM-1-1-LR', 'MPI-ESM1-2-LR', 'UKESM1-0-LL', 'HadGEM3-GC31-LL', 'CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR', 'IPSL-CM5A2-INCA', 'cmip_250', 'cmip_500'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmip_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate statistics in ERA5 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate statistics in CMIP6 ...\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t/era_500_3_lcc_2t_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t/cmip_500_3_lcc_2t_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t_days/era_500_3_lcc_2t_days_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t_days/cmip_500_3_lcc_2t_days_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t_sf/era_500_3_lcc_2t_sf_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_2t_sf/cmip_500_3_lcc_2t_sf_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc/era_500_3_lcc_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc/cmip_500_3_lcc_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_days/era_500_3_lcc_days_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_days/cmip_500_3_lcc_days_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_sf/era_500_3_lcc_sf_20070101-20101231.nc\n",
      "writing file ... /mn/vann/franzihe/output/CS_ERA5_CMIP6/3_lcc_sf/cmip_500_3_lcc_sf_20070101-20101231.nc\n"
     ]
    }
   ],
   "source": [
    "for threshold in [3, 5, 10, 15, 20]:\n",
    "    # print(threshold*0.001)\n",
    "    ds_2t      = {}\n",
    "    ds_sf      = {}\n",
    "    ds_lcc_2t   = {}\n",
    "    ds_lcc_2t_days  = {} \n",
    "    ds_lcc_2t_sf = {}\n",
    "\n",
    "    ds_lcc = {}\n",
    "    ds_lcc_days = {}\n",
    "    ds_lcc_sf = {}\n",
    "    days_season = {}\n",
    "    days_month  = {}\n",
    "    print('Calculate statistics in ERA5 ...')\n",
    "    # for model in era_dict.keys():\n",
    "    model = 'era_500'\n",
    "    ds_2t[model], ds_sf[model], ds_lcc_2t[model], ds_lcc_2t_days[model], ds_lcc_2t_sf[model], \\\n",
    "            ds_lcc[model], ds_lcc_days[model], ds_lcc_sf[model], \\\n",
    "                days_season[model], days_month[model] = find_lcc_sf(era_dict[model], threshold)\n",
    "                \n",
    "    print('Calculate statistics in CMIP6 ...')\n",
    "    # for model in cmip_dict.keys():       \n",
    "    model = 'cmip_500' \n",
    "    ds_2t[model], ds_sf[model], ds_lcc_2t[model], ds_lcc_2t_days[model], ds_lcc_2t_sf[model], \\\n",
    "            ds_lcc[model], ds_lcc_days[model], ds_lcc_sf[model], \\\n",
    "                    days_season[model], days_month[model] = find_lcc_sf(cmip_dict[model], threshold)\n",
    "                    \n",
    "    statistic_to_netcdf(era_dict, 'orig', days_season, days_month)\n",
    "    statistic_to_netcdf(cmip_dict, 'orig', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_2t, '2t', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_sf, 'sf', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_lcc_2t, f'{threshold}_lcc_2t', days_season, days_month )\n",
    "    statistic_to_netcdf(ds_lcc_2t_days, f'{threshold}_lcc_2t_days', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_lcc_2t_sf, f'{threshold}_lcc_2t_sf', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_lcc, f'{threshold}_lcc', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_lcc_days, f'{threshold}_lcc_days', days_season, days_month)\n",
    "    statistic_to_netcdf(ds_lcc_sf, f'{threshold}_lcc_sf', days_season, days_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalsnow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01a47c9201b0e71806f8317dc994d10479d7bb1c7bfa2fc7a59a724dd50a1c8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
