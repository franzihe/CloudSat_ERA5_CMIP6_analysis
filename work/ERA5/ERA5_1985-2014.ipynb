{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example with ERA5 high-resolution (~0.25deg) monthly means\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a id='introduction'></a>\n",
    "Cloud feedbacks are a major contributor to the spread of climate sensitivity in global climate models (GCMs) ([Zelinka et al. (2020)](https://doi-org.ezproxy.uio.no/10.1029/2019GL085782)]). Among the most poorly understood cloud feedbacks is the one associated with the cloud phase, which is expected to be modified with climate change ([Bjordal et al. (2020)](https://doi-org.ezproxy.uio.no/10.1038/s41561-020-00649-1)). Cloud phase bias, in addition, has significant implications for the simulation of radiative properties and glacier and ice sheet mass balances in climate models. \n",
    "\n",
    "In this context, this work aims to expand our knowledge on how the representation of the cloud phase affects snow formation in GCMs. Better understanding this aspect is necessary to develop climate models further and improve future climate predictions. \n",
    "\n",
    "* Load ERA5 data previously downloaded locally via [Jupyter Notebook - download ERA5](https://github.com/franzihe/download_ERA5)\n",
    "* find clouds: liquid-only, ice-only, mixed-phase\n",
    "* Regridd the ERA5 variables to the same horizontal resolution as high-resolution CMIP6 models with [`xesmf`](https://xesmf.readthedocs.io/en/latest/)\n",
    "* Calculate and plot the seasonal mean of the variable\n",
    "\n",
    "**Questions**\n",
    "* How is the cloud phase and snowfall varying between 1985 and 2014?\n",
    "\n",
    "\n",
    "> **_NOTE:_** We answer questions related to the comparison of CMIP models to ERA5 in another [Jupyter Notebook](../CMIP6_ERA5_CloudSat/plt_seasonal_mean.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "This study will compare surface snowfall, ice, and liquid water content from the Coupled Model Intercomparison Project Phase 6 ([CMIP6](https://esgf-node.llnl.gov/projects/cmip6/)) climate models (accessed through [Pangeo](https://pangeo.io/)) to the European Centre for Medium-Range Weather Forecast Re-Analysis 5 ([ERA5](https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5)) data from **1985 to 2014**. We conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) in the CMIP6 models and their potential connection between them. The CMIP6 data analysis can be found in the [Jupyter Notebook for CMIP6](../cmip/CMIP6_hr_1985-2014.ipynb).\n",
    "\n",
    "- Time period: 1985 to 2014\n",
    "- horizonal resolution: ~0.25deg\n",
    "- time resolution: monthly atmospheric data \n",
    "- Variables:\n",
    "  \n",
    "| shortname     |             Long name                   |      Units    |  levels |\n",
    "| ------------- |:---------------------------------------:| -------------:|--------:|\n",
    "| sf            |    snowfall                             |[m of water eq]| surface |\n",
    "| msr           |    mean_snowfall_rate                   |[kg m-2 s-1]   | surface |\n",
    "| cswc          |    specific_snow_water_content          | [kg kg-1]     |    pl   |\n",
    "| clwc          |    specific_cloud_liquid_water_content  |   [kg kg-1]   |    pl   |\n",
    "| clic          |    specific_cloud_ice_water_content     | [kg kg-1]     |    pl   |\n",
    "| t             |    temperature                          |  [K]          |    pl   |\n",
    "| 2t            |    2 metre temperature                  |  [K]          | surface |\n",
    "| tclw          |   Total column cloud liquid water       |  [kg m-2]     | single  |\n",
    "| tciw          |   Total column cloud ice water          |  [kg m-2]     | single  |\n",
    "| tp            |   Total precipitation                   |  [m]          | surface |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [globalsnow.yml](../globalsnow.yml) \n",
    "- load `python` packages from [imports.py](../utils/imports.py)\n",
    "- load `functions` from [functions.py](../utils/functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7f80aad7d730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "import sys\n",
    "import os\n",
    "if os.path.isfile('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils/imports.py') == True:\n",
    "    sys.path.append('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils')\n",
    "    \n",
    "elif os.path.isfile('/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/utils/imports.py') == False:\n",
    "    sys.path.append('/home/franzihe/Documents/Python/eosc-nordic-climate-demonstrator/work/utils/')\n",
    "\n",
    "from imports import(xr, intake, ccrs, cy, plt, glob, cm, fct, np, da)\n",
    "xr.set_options(display_style='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open ERA5 variables\n",
    "Get the data requried for the analysis. Beforehand we downloaded the monthly averaged data on single levels and pressure levels via the Climate Data Store (CDS) infrastructure. The github repository [Download ERA5](https://github.com/franzihe/download_ERA5) gives examples on how to download the data from the CDS. We use the Jupyter Notebooks [download_Amon_single_level](https://github.com/franzihe/download_ERA5/blob/main/download_Amon_single_level.ipynb) and [download_Amon_pressure_level](https://github.com/franzihe/download_ERA5/blob/main/download_Amon_pressure_level.ipynb). Both, download the monthly means for the variables mentioned above between 1985 and 2014.\n",
    "\n",
    "> **_NOTE:_** To download from CDS a user has to have a CDS user account, please create the account [here](https://cds.climate.copernicus.eu/user/register).\n",
    "\n",
    "\n",
    "The ERA5 0.25deg data is located in the folder `/input/ERA5/monthly_means/0.25deg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(glob('/scratch/franzihe/input/ERA5/monthly_means/0.25deg/*_Amon_ERA5_*12.nc')) > 0) == True:\n",
    "    input_data = '/scratch/franzihe/input'\n",
    "    output_data = '/scratch/franzihe/output'\n",
    "\n",
    "if (len(glob('/home/franzihe/Data/input/ERA5/monthly_means/0.25deg/*_Amon_ERA5_*12.nc')) > 0) == True:\n",
    "    input_data = '/home/franzihe/Data/input/'\n",
    "    output_data = '/home/franzihe/Data/output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "era_in = '{}/ERA5/monthly_means/0.25deg'.format(input_data)\n",
    "era_out = '{}/ERA5/monthly_means/1deg'.format(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_id=[\n",
    "            '2t',\n",
    "            'clic',\n",
    "            'clwc',\n",
    "            'cswc',\n",
    "            'msr',\n",
    "            'sf',\n",
    "            't', \n",
    "            'tciw',\n",
    "            'tclw',\n",
    "            'tp'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we have downloaded 30 years (1985-2014) for ERA5. We define start and end year to ensure to only extract the 30-year period between 1985 and 2014.\n",
    "\n",
    "$\\rightarrow$ Define a start and end year\n",
    "\n",
    "We will load all available variables into one xarray dataset with `xarray.open_mfdataset(file)` and select the time range [by name](https://xarray.pydata.org/en/stable/user-guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "starty = 1985; endy = 2014\n",
    "year_range = range(starty, endy+1)\n",
    "# Input data from ERA5 with a resolution of 0.25x0.25deg to be regridded\n",
    "era_file_in = glob('{}/*_Amon_ERA5_*12.nc'.format(era_in, ))       # search for data in the local directory \n",
    "ds_era = xr.open_mfdataset(era_file_in)\n",
    "ds_era = ds_era.sel(time = ds_era.time.dt.year.isin(year_range)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pressure array \n",
    "ds_era['pressure'] = xr.DataArray(data=da.ones(shape = ds_era['clwc'].shape, chunks=(120, 37, 721, 1440/2)), \n",
    "                                                               dims=list(ds_era['clwc'].dims), \n",
    "                                                               coords=[ds_era.time.values, ds_era.level.values, ds_era.latitude.values, ds_era.longitude.values])\n",
    "\n",
    "ds_era['pressure'] = ds_era['pressure']*ds_era['level'][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change attributes matching CMIP6 data\n",
    "\n",
    "We will assign the attributes to the variables to make CMIP6 and ERA5 variables comperable.\n",
    "\n",
    "The data [documentation of monthly means](https://confluence.ecmwf.int/pages/viewpage.action?pageId=82870405#ERA5:datadocumentation-Monthlymeans) gives information about the accumulations in monthly means (of daily means, stream=moda/edmo). Hence, the precipitation variables have been scaled to have an \"effective\" processing period of one day, so for accumulations in these streams\n",
    "* [`sf`](https://apps.ecmwf.int/codes/grib/param-db?id=144) is in **m of water per day** $\\rightarrow$  multiply by **1000** to get **kg m-2 day-1** or **mmday-1**.\n",
    "\n",
    "\n",
    "* [`tp`](https://apps.ecmwf.int/codes/grib/param-db?id=228) is in **m** $\\rightarrow$ Multiply by **1000** to get **mm**\n",
    "* [`ciwc`](https://apps.ecmwf.int/codes/grib/param-db?id=247), [`clwc`](https://apps.ecmwf.int/codes/grib/param-db?id=246), and [`cswc`](https://apps.ecmwf.int/codes/grib/param-db?id=76) is in **kg kg-1**    $\\rightarrow$ Multiply by **1000** to get **g kg-1**\n",
    "* [`msr`](https://apps.ecmwf.int/codes/grib/param-db?id=235031) is in **kg m-2 s-1** $\\rightarrow$ Multiply by **86400** to get **mm day-1**\n",
    "* [`tciw`](https://apps.ecmwf.int/codes/grib/param-db?id=79) and [`tclw`](https://apps.ecmwf.int/codes/grib/param-db?id=78) is in **kg m-2** $\\rightarrow$ Multiply by **1000** to get **g m-2**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variable name to variable id\n",
    "variable_id[variable_id.index('2t')] = 't2m'\n",
    "variable_id[variable_id.index('clic')] = 'ciwc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_id in variable_id:\n",
    "    \n",
    "    if var_id == 'ciwc' or var_id == 'clwc' or var_id == 'cswc' or var_id == 'sf' or var_id == 'tciw' or var_id == 'tclw' or var_id == 'tp':\n",
    "        ds_era[var_id] = ds_era[var_id]*1000\n",
    "        \n",
    "        if var_id == 'ciwc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific cloud ice water content'}\n",
    "        if var_id == 'clwc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific cloud liquid water content'}\n",
    "        if var_id == 'cswc':\n",
    "            ds_era[var_id].attrs = {'units': 'g kg-1', 'long_name':'Specific snow water content'}\n",
    "        if var_id == 'sf':\n",
    "            ds_era[var_id].attrs = {'units': 'mm day-1', 'long_name': 'Snowfall',}\n",
    "        if var_id == 'tciw':\n",
    "            ds_era[var_id].attrs = {'units': 'g m-2', 'long_name': 'Total column cloud ice water'}\n",
    "        if var_id == 'tclw':\n",
    "            ds_era[var_id].attrs = {'units': 'g m-2', 'long_name': 'Total column cloud liquid water'}\n",
    "        if var_id == 'tp':\n",
    "            ds_era[var_id].attrs = {'units': 'mm', 'long_name': 'Total precipitation'}\n",
    "        \n",
    "    if var_id == 'msr':\n",
    "        ds_era[var_id] = ds_era[var_id]*86400\n",
    "        ds_era[var_id].attrs = {'units': 'mm day-1', 'long_name': 'Mean snowfall rate'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mixed-phase clouds\n",
    "\n",
    "To get a relationship between cloud phase and snowfall amount we find mixed-phase clouds and associated precipitation in each grid cell. $\\rightarrow$ \n",
    "\n",
    "\n",
    "1. calculate percentages in each level\n",
    "   1. IWC + LWC = 100%\n",
    "   2. IWC/(IWC + LWC) * 100 = percent_iwc %\n",
    "   3. LWC/(IWC + LWC) * 100 = percent_lwc %\n",
    "2. find level where percent_iwc == 50% and percent_lwc == 50%\n",
    "3. get values where level 50/50\n",
    "   1. P(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   2. T(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   3. IWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   4. LWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   5. SWC(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   6. sf(percent_iwc == 50% and percent_lwc == 50%)\n",
    "   7. tp(percent_iwc == 50% and percent_lwc == 50%)\n",
    "\n",
    "3. find, where precipitation is >= 0.25 mm day-1 and IWC+LWC >= 0.01 g kg-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_IWC_LWC_level(ds, var1, var2, value, ds_out):\n",
    "    # 1.1. IWC + LWC = 100%\n",
    "    iwc_lwc = ds[var1] + ds[var2]\n",
    "    # 1.2. IWC/(IWC + LWC)  = fraction_iwc \n",
    "    iwc_fraction = ds[var1]/iwc_lwc\n",
    "    # 2. level where fraction_iwc == 0.5 and fraction_lwc == 0.5 or given value\n",
    "    # use the closest layer as it might not be exactly 0.5\n",
    "    filter = find_nearest(iwc_fraction, value)\n",
    "\n",
    "\n",
    "    # 3. get values where level given value\n",
    "    iwc_val = int(value*100)\n",
    "    lwc_val = int(100-iwc_val)\n",
    "    \n",
    "    ds_out['pressure_{}_{}'.format(iwc_val, lwc_val)] = ds['pressure'].where(filter)\n",
    "\n",
    "    for var_id in list(ds.keys()):\n",
    "        if (var_id == 'pressure_{}_{}'.format(iwc_val, lwc_val)) or (var_id == 'pressure'):\n",
    "            continue\n",
    "        else:\n",
    "            ds_out[var_id + '_{}_{}'.format(iwc_val, lwc_val)] = ds[var_id].where(filter)\n",
    "            if len(ds[var_id].dims) < 4:\n",
    "                filter_pres = ds_out['pressure_{}_{}'.format(iwc_val, lwc_val)] == ds_out['pressure_{}_{}'.format(iwc_val, lwc_val)].max('level')\n",
    "                ds_out[var_id + '_{}_{}'.format(iwc_val, lwc_val)] = (ds_out[var_id + '_{}_{}'.format(iwc_val, lwc_val)].where(filter_pres)).idxmax(dim='level')\n",
    "\n",
    "    return(ds_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    filter1 = (array == abs(array - value).min())\n",
    "    return(filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_era_50=xr.Dataset(); ds_era_30=xr.Dataset(); ds_era_70=xr.Dataset()\n",
    "ds_era_50 = find_IWC_LWC_level(ds_era, var1='ciwc', var2='clwc', value=0.5, ds_out=ds_era_50)\n",
    "ds_era_70 = find_IWC_LWC_level(ds_era, var1='ciwc', var2='clwc', value=0.7, ds_out=ds_era_70)\n",
    "ds_era_30 = find_IWC_LWC_level(ds_era, var1='ciwc', var2='clwc', value=0.3, ds_out=ds_era_30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regrid ERA5 data to common NorESM2-MM grid <a id='regrid_hz'></a>\n",
    "\n",
    "We want to conduct statistical analysis at the annual and seasonal timescales to determine the biases in cloud phase and precipitation (liquid and solid) for the CMIP6 models in comparison to ERA5. \n",
    "\n",
    "The ERA5 data has a nominal resolution of 0.25 deg and has to be regridded to the same horizontal resolution as the NorESM2-MM. Hence we will make use of the python package `xesmf` and [decreasing resolution](https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html#Decreasing-resolution), [Limitations and warnings](https://xesmf.readthedocs.io/en/latest/notebooks/Masking.html?highlight=conservative#Limitations-and-warnings).  \n",
    "\n",
    "$\\rightarrow$ Define NorESM2-MM as the reference grid `ds_out`.\n",
    "\n",
    "Save all variables in one file and each variable to a `netcdf` datasets between 1985 an 2014, locally.\n",
    "\n",
    "> **_NOTE:_** This can take a while, so be patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the output grid from NorESM\n",
    "cmip_file = '/scratch/franzihe/input/cmip6_hist/1deg/grid_NorESM2-MM.nc'\n",
    "ds_out = xr.open_dataset(cmip_file)\n",
    "\n",
    "# select where data should be saved\n",
    "filename = 'all_Amon_1deg_{}01_{}12.nc'.format(starty, endy)\n",
    "era_file_out = era_out + '/Amon/' + filename\n",
    "files = glob(era_file_out)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Regrid data\n",
    "ds_in_regrid = fct.regrid_data(ds_era, ds_out)\n",
    "\n",
    "# Shift the longitude from 0-->360 to -180-->180 and sort by longitude and time\n",
    "ds_in_regrid = ds_in_regrid.assign_coords(lon=(((ds_in_regrid.lon + 180) % 360) - 180)).sortby('lon').sortby('time')\n",
    "\n",
    "if era_file_out in files:\n",
    "    print('{} is downloaded'.format(era_file_out))\n",
    "    counter += 1\n",
    "    print('Have regridded in total: {:} files'.format(str(counter))) \n",
    "else: # Save to netcdf file\n",
    "    ds_in_regrid.to_netcdf(era_file_out)\n",
    "    print('file written: {}'.format(era_file_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for var_id in variable_id:\n",
    "    # select where data should be saved\n",
    "    filename = '{}_Amon_1deg_{}01_{}12.nc'.format(var_id, starty, endy)\n",
    "    era_file_out = era_out + '/Amon/' + filename\n",
    "    files = glob(era_file_out)\n",
    "    \n",
    "    if era_file_out in files:\n",
    "        print('{} is downloaded'.format(era_file_out))\n",
    "        counter += 1\n",
    "        print('Have regridded in total: {:} files'.format(str(counter))) \n",
    "    else: # Save to netcdf file\n",
    "        ds_in_regrid[var_id].to_netcdf(era_file_out)\n",
    "        print('file written: {}'.format(era_file_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create seasonal mean/spread of all regridded ERA5\n",
    "\n",
    "...and plot seasonal mean of each individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_mean_std(ds, var,):\n",
    "    ds[var+'_season_mean'] = ds[var].groupby('time.season').mean('time', keep_attrs = True)\n",
    "    ds[var+'_season_std']  = ds[var].groupby('time.season').std('time', keep_attrs = True)\n",
    "\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seasonal mean of variables\n",
    "for var_id in list(ds_era.keys()):\n",
    "    ds_era = seasonal_mean_std(ds_era, var_id)\n",
    "\n",
    "for var_id in list(ds_era_30.keys()):\n",
    "    ds_era_30 = seasonal_mean_std(ds_era_30, var_id)\n",
    "for var_id in list(ds_era_50.keys()):\n",
    "    ds_era_50 = seasonal_mean_std(ds_era_50, var_id)\n",
    "for var_id in list(ds_era_70.keys()):\n",
    "    ds_era_70 = seasonal_mean_std(ds_era_70, var_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_id in list(ds_era.keys()):\n",
    "\n",
    "\n",
    "    # Plot seasonal mean\n",
    "    fig, axs, im = fct.plt_spatial_seasonal_mean(ds_era[var_id+'_season_mean'], var_id, title='ERA5 MEAN ({} - {})'.format(starty, endy))\n",
    "\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "    cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')], weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save figure to png\n",
    "    figdir = '/uio/kant/geo-metos-u1/franzihe/Documents/Figures/ERA5/'\n",
    "    figname = '{}_season_1deg_{}_{}.png'.format(var_id, starty, endy)\n",
    "    plt.savefig(figdir + figname, format = 'png', bbox_inches = 'tight', transparent = False)\n",
    "\n",
    "    # Plot seasonal mean and std\n",
    "    fig, axs, im = fct.plt_spatial_seasonal_mean(ds_era[var_id+'_season_mean'], var_id, title='ERA5 MEAN ({} - {})'.format(starty, endy))\n",
    "\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([1, 0.15, 0.025, 0.7])\n",
    "    cb = fig.colorbar(im, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    cb.set_label(label='MEAN - {}'.format(fct.plt_dict[var][fct.plt_dict['header'].index('label')], weight='bold')\n",
    "\n",
    "    for ax, i in zip(axs, ds_era[var_id+'_season_std'].season):\n",
    "        sm = ds_era[var_id+'_season_std'].sel(season=i).plot.contour(ax=ax, transform=ccrs.PlateCarree(), \n",
    "                                                                        robust=True,\n",
    "                                                                        vmin = vmin_std, vmax = vmax_std,\n",
    "                                                                        levels = 6,\n",
    "                                                                        cmap=cm.lajolla,\n",
    "                                                                        add_colorbar=False)\n",
    "        \n",
    "    cbar_ax = fig.add_axes([1.10, 0.15, 0.025, 0.7])\n",
    "    sb = fig.colorbar(sm, cax=cbar_ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    sb.set_label(label='STD - {}'.format(label), weight='bold')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find liquid, ice only, mixed phase cloud. Plot histogram of observed snowfall amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FH  11:04 AM\n",
    "Ok. There is something I don't understand.\n",
    "You have this in line 165: P_idx=sum(P>100,1)>0;%find hours where seeder feeder might be happening What is the P>100? Pressure level?\n",
    "RD  11:38 AM\n",
    "hmmm i dont remember. Ill have a look in a bit\n",
    "FH  11:39 AM\n",
    "sure :smile:\n",
    "RD  1:34 PM\n",
    "okay so i just checked\n",
    "1:34\n",
    "that tells me if there is a true difference between cloud layers\n",
    "1:35\n",
    "so basically the T change will go from 0 (where there is no ice cloud) to the T of the cloud\n",
    "FH  1:36 PM\n",
    "true difference between the temperatures in the cloud layers?!\n",
    "RD  1:36 PM\n",
    "so it makes sure that the code is not tricked by local minimums in T but that there is truly an IWC free layer\n",
    "1:37\n",
    "ya so its to avoid situations where you have\n",
    "250|\n",
    "245\n",
    "248\n",
    "1:37\n",
    "showing up as a local minimum and therefore it thinks that is a cloud free layer\n",
    "1:39\n",
    "it was a way to retain the cloud temperatures and find the cloud free situations\n",
    "1:40\n",
    "maybe not the best way but it was an easy way i think\n",
    "FH  1:44 PM\n",
    "Ok. I have to think a little about it. So you find the local minimum of the temperature and check at the same time if there is ice?\n",
    "What I also don't understand is what you do in the next line. P_idx=sum(P>100,1)>0;%find hours where seeder feeder might be happening\n",
    "RD  1:46 PM\n",
    "ya so that just finds the profiles where there is seeder feeder based on the gaps in the iwc\n",
    "1:47\n",
    "so if the T multiplied by whether there is iwc or not (1 or 0)\n",
    "1:47\n",
    "so if the T of this multiplication has points where the change is greater than 100, it identifies it as a profile with seeder feeder\n",
    "1:49\n",
    "because in each .nc file there tons of 3 hourly profiles\n",
    "1:49\n",
    "so this is a quick way to filter out the ones with seeder-feeder and without\n",
    "FH  1:49 PM\n",
    "Got it, I think. I started doing it just with my data. But if everything goes well we can just use the function for the seeder-feeder paper\n",
    "New\n",
    "RD  1:50 PM\n",
    "you cant just use whether there is ice or not (1 or 0) because the diff will mess things up\n",
    "1:50\n",
    "you will go from 0 to 1 when the cloud starts and then back to 0 then back 1 at cloud top\n",
    "1:50\n",
    "so this was a way to work around that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('globalsnow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
