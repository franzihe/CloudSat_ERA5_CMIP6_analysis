{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrid CloudSat data to horizontal grid\n",
    "\n",
    "\n",
    "# Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#introduction\">1. Introduction</a></li>\n",
    "<li><a href=\"#data_wrangling\">2. Data Wrangling</a></li>\n",
    "<li><a href=\"#exploratory\">3. Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusion\">4. Conclusion</a></li>\n",
    "<li><a href=\"#references\">5. References</a></li>\n",
    "</ul>\n",
    "\n",
    "# 1. Introduction <a id='introduction'></a>\n",
    "\n",
    "**Questions**\n",
    "\n",
    "\n",
    "> **_NOTE:_** The pressure grid was created in the  [Jupyter Notebook](./get_pressure_grid.ipynb) to calculate the daily means of CloudSat variables.\n",
    "\n",
    "# 2. Data Wrangling <a id='data_wrangling'></a>\n",
    "\n",
    "\n",
    "\n",
    "- Time period: 2007 - 2010\n",
    "- time resolution: daily atmospheric overpasses \n",
    "- Variables:\n",
    "  \n",
    "|              Long name                   |      Units    |  Dimension |\n",
    "| :---------------------------------------:| -------------:|--------:|\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mimi.uio.no\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "abs_path = str(pathlib.Path(hostname).parent.absolute())\n",
    "WORKDIR = abs_path[:- (len(abs_path.split('/')[-2] + abs_path.split('/')[-1])+1)]\n",
    "\n",
    "\n",
    "if \"mimi\" in hostname:\n",
    "    print(hostname)\n",
    "    DATA_DIR = \"/scratch/franzihe/\"\n",
    "    # FIG_DIR = \"/uio/kant/geo-metos-u1/franzihe/Documents/Figures/ERA5/\"\n",
    "elif \"glefsekaldt\" in hostname: \n",
    "    DATA_DIR = \"/home/franzihe/Data/\"\n",
    "    # FIG_DIR = \"/home/franzihe/Documents/Figures/ERA5/\"\n",
    "\n",
    "INPUT_DATA_DIR = os.path.join(DATA_DIR, 'input')\n",
    "OUTPUT_DATA_DIR = os.path.join(DATA_DIR, 'output')\n",
    "UTILS_DIR = os.path.join(WORKDIR, 'utils')\n",
    "\n",
    "sys.path.append(UTILS_DIR)\n",
    "# make figure directory\n",
    "# try:\n",
    "#     os.mkdir(FIG_DIR)\n",
    "# except OSError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages\n",
    "- `Python` environment requirements: file [globalsnow.yml](../globalsnow.yml) \n",
    "- load `python` packages from [imports.py](../utils/imports.py)\n",
    "- load `functions` from [functions.py](../utils/functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # don't output warnings\n",
    "\n",
    "# import packages\n",
    "from imports import(xr, ccrs, cy, plt, glob, fct, np, datetime, timedelta, h5py, da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open CloudSat variables\n",
    "Get the data requried for the analysis. Beforehand we downloaded the [ECMWF-AUX files](https://www.cloudsat.cira.colostate.edu/data-products/ecmwf-aux) with the script provided on the [CloudSat webpage](https://cswww.cira.colostate.edu/code_library/cloudsat_ftp.plx).\n",
    "\n",
    "\n",
    "\n",
    "The CloudSat data is located in the folder `/input/CloudSat/` and individual folders for the CloudSat product. The 2C-SNOW-PROFILEs are in `/2C-SNOW-PROFILE.P1_R05/` while the ECMWF-AUX files are in `/ECMWF-AUX.P_R05/`. Each year has extra folders for the day of the year, where all CloudSat granules can be found of that specific day. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_in = os.path.join(INPUT_DATA_DIR, 'CloudSat/2C-SNOW-PROFILE.P1_R05')\n",
    "cs_out = os.path.join(OUTPUT_DATA_DIR, 'CloudSat/2C-SNOW-PROFILE.P1_R05')\n",
    "# make output data directory\n",
    "try:\n",
    "    os.mkdir(cs_out)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_cs = sorted(glob(cs_in+'/2007/*/*.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOLOC_VARNAMES = [\"DEM_elevation\",\"Height\", \"Latitude\", \"Longitude\"]\n",
    "DATA_VARNAMES = [\"snow_water_content\", \"snowfall_rate\", \"snowfall_rate_sfc\"]\n",
    "DATA_VARNAMES_EC = [\"Pressure\", \"Temperature\"]\n",
    "_VARNAMES = np.append(DATA_VARNAMES, DATA_VARNAMES_EC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.Dataset()\n",
    "# ds['Pressure_grid'] = xr.open_dataset('{}ECMWF-AUX.P_R05/pressure_grid.nc'.format(cs_out))['Pressure_grid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load era grid\n",
    "# ds_era = xr.open_dataset('{}/clwc_Amon_ERA5_198501_198912.nc'.format(era_in, ))\n",
    "# # ds_era = ds_era.isel(time = month-1).squeeze().drop('clwc')\n",
    "# ds_era = ds_era.drop('clwc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb#ch0000007vscode-remote?line=38'>39</a>\u001b[0m                     \u001b[39mfor\u001b[39;00m nbin \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(ds\u001b[39m.\u001b[39mnbin)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb#ch0000007vscode-remote?line=39'>40</a>\u001b[0m                         dmin\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mabs\u001b[39m(ds[\u001b[39m'\u001b[39m\u001b[39mPressure\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misel(nray \u001b[39m=\u001b[39m nray) \u001b[39m-\u001b[39m ds[\u001b[39m'\u001b[39m\u001b[39mPressure_grid\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misel(nbin \u001b[39m=\u001b[39m nbin))\u001b[39m.\u001b[39midxmin(dim \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnbin\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb#ch0000007vscode-remote?line=40'>41</a>\u001b[0m                         ds[var \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_pregrid\u001b[39m\u001b[39m'\u001b[39m][nray, nbin] \u001b[39m=\u001b[39m  ds[var]\u001b[39m.\u001b[39misel(nray \u001b[39m=\u001b[39m nray, nbin \u001b[39m=\u001b[39m dmin)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb#ch0000007vscode-remote?line=43'>44</a>\u001b[0m         datasets\u001b[39m.\u001b[39mappend(ds)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmimi.uio.no/uio/kant/geo-metos-u1/franzihe/Documents/Python/globalsnow/eosc-nordic-climate-demonstrator/work/CloudSat/read_2C_snow.ipynb#ch0000007vscode-remote?line=47'>48</a>\u001b[0m ds_cs \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mconcat(datasets,dim\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for file in ff_cs[0:1]:\n",
    "    year = int(file.split('/')[-1].split('_')[0][0:4])\n",
    "    doy = int(file.split('/')[-1].split('_')[0][4:7])  # day of the year\n",
    "    tt = datetime(year, 1, 1) + timedelta(doy - 1)\n",
    "    \n",
    "    \n",
    "    file_ec = sorted(glob('{}ECMWF-AUX.P_R05/{}/{}/{}_*.h5'.format(cs_in, year, doy, file.split('/')[-1].split('_')[0])))[0]\n",
    "    for month in range(6, 7):\n",
    "        if tt.month == month:\n",
    "            # ds = xr.Dataset()\n",
    "            ds = xr.Dataset()\n",
    "            ds['Pressure_grid'] = xr.open_dataset('{}ECMWF-AUX.P_R05/pressure_grid.nc'.format(cs_out))['Pressure_grid']\n",
    "\n",
    "            h5file = h5py.File(file, \"r\")   # open h5 file\n",
    "            ds['Profile_time'] = fct.get_profile_times(h5file['2C-SNOW-PROFILE'])\n",
    "\n",
    "            for var in GEOLOC_VARNAMES:\n",
    "                ds[var] = fct.get_geoloc_var(h5file['2C-SNOW-PROFILE'], var )\n",
    "\n",
    "            for var in DATA_VARNAMES:\n",
    "                ds[var] = fct.get_data_var(h5file['2C-SNOW-PROFILE'], var)\n",
    "\n",
    "            # load ECMWF-AUX file\n",
    "            h5file_ec = h5py.File(file_ec, \"r\")\n",
    "            for var in DATA_VARNAMES_EC:\n",
    "                ds[var] = fct.get_data_var(h5file_ec['ECMWF-AUX'], var)\n",
    "\n",
    "                if var == 'Pressure':\n",
    "                    ds[var] = ds[var]/100\n",
    "                    ds[var].attrs = {'units': ds_era['level'].attrs['units'], 'longname':ds_era['level'].attrs['long_name']}\n",
    "\n",
    "            for var in _VARNAMES:\n",
    "                if (len(ds[var].dims)) == 2:\n",
    "                    ds[var +'_pregrid'] = xr.DataArray(data=da.full(shape = (ds[var].shape), fill_value=np.nan, chunks=(len(ds['nray'])/2, len(ds['nbin']))), dims= list(ds[var].dims), coords=[ds[var]['nray'].values, ds[var]['nbin']])\n",
    "                    # Before performing the average within a grid cell we will bring the Profiles on a common pressure grid which we created in get_pressure_grid.py\n",
    "                    for nray in range(len(ds.nray)):\n",
    "                        for nbin in range(len(ds.nbin)):\n",
    "                            dmin= int(abs(ds['Pressure'].isel(nray = nray) - ds['Pressure_grid'].isel(nbin = nbin)).idxmin(dim = 'nbin'))\n",
    "                            ds[var +'_pregrid'][nray, nbin] =  ds[var].isel(nray = nray, nbin = dmin)\n",
    "\n",
    "\n",
    "            datasets.append(ds)\n",
    "\n",
    "            \n",
    "\n",
    "    ds_cs = xr.concat(datasets,dim='nray')\n",
    "\n",
    "# # add common pressure grid to dataset\n",
    "# ds_cs['Pressure_grid'] = xr.open_dataset('{}ECMWF-AUX.P_R05/pressure_grid.nc'.format(cs_out))['Pressure_grid']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert ECMWF pressure to hPa\n",
    "# ds_cs['Pressure'] = ds_cs['Pressure']/100\n",
    "# ds_cs['Pressure'].attrs = {'units': ds_era['level'].attrs['units'], 'longname':ds_era['level'].attrs['long_name']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dataset with same isobaric pressure levels\n",
    "# ds_pres = ds_cs.drop(('DEM_elevation', 'Height', ))\n",
    "# # create array\n",
    "\n",
    "# for var in DATA_VARNAMES:\n",
    "#     if (len(ds_cs[var].dims)) == 2:\n",
    "#         ds_pres[var] = xr.DataArray(data=da.full(shape = (ds_cs[var].shape), fill_value=np.nan, chunks=(len(ds_cs['nray'])/2, len(ds_cs['nbin']))), dims= list(ds_cs[var].dims), coords=list(ds_cs[var].indexes.values()))\n",
    "\n",
    "\n",
    "#         # Before performing the average within a grid cell we will bring the Profiles on a common pressure grid which we created in get_pressure_grid.py\n",
    "#         for nray in range(len(ds_cs.nray)):\n",
    "#             for nbin in range(len(ds_cs.nbin)):\n",
    "                \n",
    "#                 dmin= int(abs(ds_cs['Pressure'].isel(nray = nray) - ds_cs['Pressure_grid'].isel(nbin = nbin)).idxmin(dim = 'nbin'))\n",
    "#                 ds_pres[var][nray, nbin] =  ds_cs[var].isel(nray = nray, nbin = dmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon = xr.Dataset()\n",
    "\n",
    "# create array \n",
    "for var in DATA_VARNAMES:\n",
    "    if len(ds_pres[var].dims) == 1:\n",
    "        lat_lon[var] = xr.DataArray(data=da.full(shape = (ds_era['longitude'].shape[0], ds_era['latitude'].shape[0], ), fill_value=np.nan, chunks=(ds_era['longitude'].shape[0]/2, ds_era['latitude'].shape[0])), \n",
    "                                                               dims=[ds_era['longitude'].dims[0], ds_era['latitude'].dims[0]], \n",
    "                                                               coords=[ds_era['longitude'].values, ds_era['latitude'].values])\n",
    "    if len(ds_pres[var].dims) == 2:\n",
    "        lat_lon[var] = xr.DataArray(data=da.full(shape = (ds_era['longitude'].shape[0], ds_era['latitude'].shape[0], ds_pres['Pressure_grid'].shape[0]), fill_value=np.nan, chunks=(ds_era['longitude'].shape[0]/2, ds_era['latitude'].shape[0], ds_pres['Pressure_grid'].shape[0])), \n",
    "                                                               dims=[ds_era['longitude'].dims[0], ds_era['latitude'].dims[0], ds_pres['Pressure_grid'].dims[0]], \n",
    "                                                               coords=[ds_era['longitude'].values, ds_era['latitude'].values, ds_pres['Pressure_grid'].values])\n",
    "\n",
    "    # Calculate the average value within a grid box\n",
    "    for i in range(len(lat_lon.longitude)+1):\n",
    "        # loop through longitude\n",
    "        if i == len(lat_lon.longitude):\n",
    "            lon1 = 360\n",
    "        else:\n",
    "            lon1 = lat_lon['longitude'].isel(longitude=slice(i, i+2)).mean().values.tolist()\n",
    "        if i == 0:\n",
    "            lon0 = lat_lon['longitude'].isel(longitude=slice(i, i+1)).mean().values.tolist()\n",
    "        else:\n",
    "            lon0 = lat_lon['longitude'].isel(longitude=slice(i-1, i+1)).mean().values.tolist()\n",
    "\n",
    "        # loop through latitude\n",
    "        for k in range( len(lat_lon.latitude)):\n",
    "            lat0 = lat_lon['latitude'].isel(latitude = slice(k, k+2)).mean().values.tolist()\n",
    "            if k == 0:\n",
    "                lat1 = lat_lon['latitude'].isel(latitude = slice(k, k+1)).mean().values.tolist()\n",
    "            else:\n",
    "                lat1 = lat_lon['latitude'].isel(latitude = slice(k-1, k+1)).mean().values.tolist()\n",
    "            \n",
    "            bbox = (lon0, lon1, lat0, lat1)\n",
    "            # print(bbox)\n",
    "\n",
    "            filter = ((ds_pres['Longitude'] > bbox[0]) & (ds_pres['Longitude'] < bbox[1]) & \\\n",
    "                (ds_pres['Latitude'] > bbox[2]) & (ds_pres['Latitude'] < bbox[3]))\n",
    "\n",
    "            if len(ds_pres[var].dims) == 1:\n",
    "                lat_lon[var][i, k] = ds_pres[var].where(filter).mean('nray',skipna=True,keep_attrs=True)\n",
    "            if len(ds_pres[var].dims) == 2:\n",
    "                lat_lon[var][i, k,:] = ds_pres[var].where(filter).mean('nray',skipna=True,keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection=ccrs.Robinson())\n",
    "ax.coastlines()\n",
    "# ax.set_global()\n",
    "# ax.set_extent([-30, 50, 50, 85], crs=ccrs.PlateCarree())\n",
    "ax.set_extent([-10, 30, 25, 85], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.plot(combined['Longitude'].where(filter), combined['Latitude'].where(filter), linewidth=2, transform=ccrs.PlateCarree());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('globalsnow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f24944080b15318569c1ef785be98f8dd5a0531d3a23558ab9e7edab213d92e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
